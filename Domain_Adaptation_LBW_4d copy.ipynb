{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/MMI24limbyungwan/.conda/envs/byungwan_resn/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "#from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# GPU 사용이 가능할 경우, GPU를 사용할 수 있게 함.'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "print(device)\n",
    "\n",
    "print(os.environ.get('CUDA_VISIBLE_DEVICES'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "# 클래스별 IoU를 계산하기 위한 함수\n",
    "def calculate_iou_per_class(y_true, y_pred, class_id):\n",
    "    intersection = np.sum((y_true == class_id) & (y_pred == class_id))\n",
    "    union = np.sum((y_true == class_id) | (y_pred == class_id))\n",
    "    iou = intersection / union if union > 0 else 0\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "def apply_fisheye_distortion(images, masks, label):\n",
    "    # 이미지 크기 가져오기\n",
    "    batch, channel, height, width = images.shape\n",
    "\n",
    "    # 카메라 매트릭스 생성\n",
    "    focal_length = width / 4\n",
    "    center_x = width / 2\n",
    "    center_y = height / 2\n",
    "    camera_matrix = np.array([[focal_length, 0, center_x],\n",
    "                              [0, focal_length, center_y],\n",
    "                              [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "    # 왜곡 계수 생성\n",
    "    dist_coeffs = np.array([0, 0.7 * label, 0, 0], dtype=np.float32)\n",
    "\n",
    "    # 왜곡 보정\n",
    "    undistorted_images = []\n",
    "    undistorted_masks = []\n",
    "\n",
    "    for i in range(batch):\n",
    "        image = images[i].permute(1, 2, 0).cpu().numpy()  # 텐서를 NumPy 배열로 변환\n",
    "        mask = masks[i].cpu().numpy()\n",
    "        undistorted_image = cv2.undistort(image, camera_matrix, dist_coeffs)\n",
    "        undistorted_mask = cv2.undistort(mask, camera_matrix, dist_coeffs)\n",
    "        undistorted_mask = np.round(undistorted_mask).astype(np.uint8)\n",
    "        undistorted_mask[undistorted_mask > 12] = 12\n",
    "\n",
    "        # 다시 텐서로 변환\n",
    "        undistorted_image = torch.from_numpy(undistorted_image).permute(2, 0, 1).float().to(device)\n",
    "        undistorted_mask = torch.from_numpy(undistorted_mask).long().to(device)\n",
    "\n",
    "        undistorted_images.append(undistorted_image)\n",
    "        undistorted_masks.append(undistorted_mask)\n",
    "\n",
    "    undistorted_images = torch.stack(undistorted_images, dim=0)\n",
    "    undistorted_masks = torch.stack(undistorted_masks, dim=0)\n",
    "\n",
    "    return undistorted_images, undistorted_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #directory_path = \"/mnt/nas27/Dataset/Samsung_DM\"\n",
    "        directory_path = './data/224'\n",
    "        img_path = self.data.iloc[idx, 1]\n",
    "        img_path = os.path.join(directory_path, img_path)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "        \n",
    "        mask_path = self.data.iloc[idx, 2]\n",
    "        mask_path = os.path.join(directory_path, mask_path)\n",
    "        mask = cv2.imread(mask_path)\n",
    "        #mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        mask = np.round(mask).astype(np.uint8)\n",
    "        mask[mask > 12] = 12 #배경을 픽셀값 12로 간주\n",
    "        mask += 1\n",
    "        mask[mask == 13] = 0\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "transform = A.Compose(\n",
    "    [   \n",
    "        A.Normalize(),\n",
    "        \n",
    "        # 변형\n",
    "        # A.VerticalFlip(p=0.5),\n",
    "        # A.RandomRotate90(p=0.5),\n",
    "        # A.HueSaturationValue(p=0.2),\n",
    "        \n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradReverse(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(self, x):\n",
    "        return x.view_as(x)\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output): # 역전파 시에 gradient에 음수를 취함\n",
    "        return grad_output * (-1)\n",
    "\n",
    "class domain_classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(domain_classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(224*224*64, 10)\n",
    "        self.fc2 = nn.Linear(10, 4) # source = 0, target = 1 회귀 가정\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 224*224*64)\n",
    "        x = GradReverse.apply(x) # gradient reverse\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        #return torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "class domain_linear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(domain_linear, self).__init__()\n",
    "        self.fc1 = nn.Linear(224*224*64, 10)\n",
    "        self.fc2 = nn.Linear(10, 1) # source = 0, target = 1 회귀 가정\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 224*224*64)\n",
    "        x = GradReverse.apply(x) # gradient reverse\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        #return torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "class IdentityBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(IdentityBlock, self).__init__()\n",
    "        \n",
    "        # 3x3 convolution\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # 3x3 convolution\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # Skip connection\n",
    "        self.skip = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        # Adding the skip connection\n",
    "        out += self.skip(identity)\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "#인코더 블럭\n",
    "class Conv2(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels):\n",
    "        super(Conv2,self).__init__() \n",
    "        self.identityblock1 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock2 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock3 = IdentityBlock(in_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
    "    def forward(self,x):\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        x = self.identityblock3(x)\n",
    "        p = self.maxpool(x)\n",
    "        \n",
    "        return x , p\n",
    "class Conv3(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels):\n",
    "        super(Conv3,self).__init__()         \n",
    "        self.identityblock1 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock2 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock3 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock4 = IdentityBlock(in_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
    "    def forward(self,x):\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        x = self.identityblock3(x)\n",
    "        x = self.identityblock4(x)\n",
    "        p = self.maxpool(x)\n",
    "        \n",
    "        return x , p\n",
    "class Conv4(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels):\n",
    "        super(Conv4,self).__init__()         \n",
    "        self.identityblock1 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock2 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock3 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock4 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock5 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock6 = IdentityBlock(in_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
    "    def forward(self,x):\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        x = self.identityblock3(x)\n",
    "        x = self.identityblock4(x)\n",
    "        x = self.identityblock5(x)\n",
    "        x = self.identityblock6(x)\n",
    "        p = self.maxpool(x)\n",
    "        \n",
    "        return x , p\n",
    "class Conv5(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels):\n",
    "        super(Conv5,self).__init__() \n",
    "        self.identityblock1 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock2 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock3 = IdentityBlock(in_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        x = self.identityblock3(x)\n",
    "        p = self.maxpool(x)\n",
    "        \n",
    "        return x , p\n",
    "#디코더 블럭\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.upsample = nn.ConvTranspose2d(channels*2, channels, kernel_size=4, stride=2, padding=1) # output_padding 추가\n",
    "        self.convblock1 = IdentityBlock(channels*2, channels)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = self.upsample(x)\n",
    "        if x.size(2) != skip.size(2) or x.size(3) != skip.size(3):\n",
    "            x = F.interpolate(x, size=(skip.size(2), skip.size(3)))\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.convblock1(x)\n",
    "        #print(\"x\",x.shape,\"skip: \",skip.shape)\n",
    "        return x\n",
    "\n",
    "#Unet구조 middle의 xm값의 움직임에 주의\n",
    "class Resnet34_Unet(nn.Module):\n",
    "    def __init__(self,n_classes):\n",
    "        super(Resnet34_Unet,self).__init__()\n",
    "        self.fconv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.fbn1 = nn.BatchNorm2d(64)\n",
    "        self.frelu1 = nn.ReLU()\n",
    "        self.fmaxpooling = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "        \n",
    "        self.conv2 = Conv2(64,128)\n",
    "        self.conv3 = Conv3(128,256)\n",
    "        self.conv4 = Conv4(256,512)\n",
    "        self.conv5 = Conv5(512,1024)\n",
    "        \n",
    "        self.middleconv = IdentityBlock(1024,2048)\n",
    "        self.dropout = nn.Dropout2d(0.1) #\n",
    "           \n",
    "        self.decoder5 = DecoderBlock(1024)\n",
    "        self.decoder4 = DecoderBlock(512)\n",
    "        self.decoder3 = DecoderBlock(256)\n",
    "        self.decoder2 = DecoderBlock(128)\n",
    "        self.decoder1 = DecoderBlock(64)\n",
    "        self.transpose = nn.ConvTranspose2d(64, 64, kernel_size=4, stride=2, padding=1) # output_padding 추가\n",
    "        \n",
    "        self.segmap = nn.Conv2d(64,n_classes, kernel_size=1)\n",
    "        self.domain_classifier = domain_classifier()\n",
    "        self.domain_linear = domain_linear()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fconv1(x)#3->64\n",
    "        x0 = self.fbn1(x)\n",
    "        x1 = self.frelu1(x)\n",
    "        p = self.fmaxpooling(x1)#첫 conv: x0([8, 64, 109, 109]) p([8, 64, 54, 54])\n",
    "        #print(\"conv1: \",x1.shape, \"maxpooling: \",p.shape)\n",
    "        x2,p = self.conv2(p)\n",
    "        #print(\"conv2: \",x2.shape, \"maxpooling: \",p.shape)\n",
    "        x3,p = self.conv3(p)\n",
    "        #print(\"conv3: \",x3.shape, \"maxpooling: \",p.shape)\n",
    "        x4,p = self.conv4(p)\n",
    "        #print(\"conv4: \",x4.shape, \"maxpooling: \",p.shape)\n",
    "        x5,p = self.conv5(p)\n",
    "        #print(\"conv5: \",x5.shape, \"maxpooling: \",p.shape)\n",
    "        \n",
    "        xm = self.middleconv(p)#xm([8, 4096, 2, 2])\n",
    "        #print(\"xm: \",xm.shape, \"maxpooling: \",p.shape)\n",
    "        xm = self.dropout(xm)\n",
    "        \n",
    "        x = self.decoder5(xm,x5)#뉴런:2048*2->2048 1\n",
    "        x = self.decoder4(x,x4)#뉴런:1024*2->1024 \n",
    "        x = self.decoder3(x,x3) #14\n",
    "        x = self.decoder2(x,x2)#28\n",
    "        x = self.decoder1(x,x1)#55\n",
    "        x = self.transpose(x)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        #x = F.interpolate(x, size=(224, 224))\n",
    "        x_c = self.segmap(x)\n",
    "        x_d = self.domain_classifier(x)\n",
    "        \n",
    "        return x_c,x_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # 저장된 class_weights를 불러옵니다.\n",
    "# class_weights_path = 'CLASS_WEIGHTS.pkl'\n",
    "\n",
    "# with open(class_weights_path, 'rb') as file:\n",
    "#     CLASS_WEIGHTS = pickle.load(file)\n",
    "\n",
    "# print(CLASS_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function과 optimizer 정의\n",
    "\n",
    "class DANN_Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DANN_Loss, self).__init__()\n",
    "\n",
    "        #self.CE = nn.CrossEntropyLoss(weight=CLASS_WEIGHTS) # 0~9 class 분류용\n",
    "        self.CE = nn.CrossEntropyLoss()\n",
    "        \n",
    "        \n",
    "    # result : DANN_CNN에서 반환된 값\n",
    "    # label : 숫자 0 ~ 9에 대한 라벨\n",
    "    # domain_num : 0(source) or 1(target)\n",
    "    def forward(self, result, label, domain_num, alpha = 1):\n",
    "        label_logits, domain_logits = result # DANN_CNN의 결과\n",
    "\n",
    "        batch_size = domain_logits.shape[0]\n",
    "\n",
    "        segment_loss = self.CE(label_logits, label) # class 분류 loss\n",
    "        \n",
    "        domain_target = torch.FloatTensor([domain_num] * batch_size).to(device)\n",
    "\n",
    "        domain_loss = self.CE(domain_logits, domain_target) # domain 분류 loss\n",
    "        \n",
    "        #domain_target = torch.FloatTensor([domain_num] * batch_size).unsqueeze(1).to(device)\n",
    "        #domain_loss = self.BCE(domain_logits, domain_target) # domain 분류 loss\n",
    "        \n",
    "        loss = segment_loss + alpha * domain_loss\n",
    "        # print(\"segment_mask : \", label.shape)\n",
    "        # print(\"domain_answer : \", domain_target.shape)\n",
    "        return loss ,segment_loss, domain_loss\n",
    "    \n",
    "class DANN_Loss_mse(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DANN_Loss_mse, self).__init__()\n",
    "        self.CE = nn.CrossEntropyLoss()\n",
    "        self.MSE = nn.MSELoss()\n",
    "\n",
    "    def forward(self, result, label, domain_num, alpha = 1):\n",
    "        label_logits, domain_logits = result # DANN_CNN의 결과\n",
    "\n",
    "        batch_size = domain_logits.shape[0]\n",
    "\n",
    "        segment_loss = self.CE(label_logits, label) # class 분류 loss\n",
    "        \n",
    "        domain_target = torch.LongTensor([domain_num] * batch_size).unsqueeze(1).to(device).float()      \n",
    "        domain_loss = self.MSE(domain_logits, domain_target) # domain 분류 loss\n",
    "        domain_loss = torch.sqrt(domain_loss)\n",
    "        loss = segment_loss + alpha * domain_loss\n",
    "        # print(\"segment_mask : \", label.shape)\n",
    "        # print(\"domain_answer : \", domain_target.shape)\n",
    "        return loss ,segment_loss, domain_loss\n",
    "    \n",
    "\n",
    "loss_fn = DANN_Loss().to(device)\n",
    "#loss_fn = DANN_Loss_mse().to(device)\n",
    "\n",
    "#criterion =nn.CrossEntropyLoss()\n",
    "#domain_criterion = nn.BCELoss()\n",
    "#criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "EP = 15\n",
    "BATCH_SIZE = 16\n",
    "ACCMULATION_STEP = 1 \n",
    "N_CLASSES = 13 #IoU 점수측정하기 위한 클래스의 개수\n",
    "alpha = 1e-7\n",
    "# model 초기화\n",
    "model = Resnet34_Unet(n_classes = N_CLASSES).to(device)\n",
    "#model = Unet(n_classes = N_CLASSES).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "optimizer.zero_grad() \n",
    "\n",
    "source_dataset = CustomDataset(csv_file='./data/896_csv/train_source.csv', transform=transform)\n",
    "source_dataloader = DataLoader(source_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_target_dataset = CustomDataset(csv_file='./data/896_csv/val_source.csv', transform=transform)\n",
    "val_target_dataloader = DataLoader(val_target_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [02:21<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________Epoch1_______________________________________\n",
      "--IoU Scores Train--\n",
      "Class0: 0.0119 Class1: 0.0191 Class2: 0.0240 Class3: 0.0334 Class4: 0.0397 Class5: 0.0443 Class6: 0.0504 \n",
      "Class7: 0.0528 Class8: 0.0538 Class9: 0.0577 Class10: 0.0562 Class11: 0.0585 Class12: 0.0585 \n",
      "Train seg Loss: 10.217356319552746\n",
      "Train dom Loss: 8.989931896598875\n",
      "Train Loss: 10.217357106398845\n",
      "Train mIoU: 0.04309858236240013\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.2494 Class1: 0.2005 Class2: 0.2162 Class3: 0.2581 Class4: 0.2144 Class5: 0.2357 Class6: 0.2797 \n",
      "Class7: 0.2010 Class8: 0.2201 Class9: 0.2473 Class10: 0.2277 Class11: 0.2308 Class12: 0.2290 \n",
      "Epoch1\n",
      "Valid_Seg Loss: 0.28237005074818927 Valid_dom Loss: 4.779534514745077\n",
      "Valid Loss: 0.2823705275853475\n",
      "Valid mIoU: 0.2315339537936499\n",
      "___________________________________________________________________________________________\n",
      "\n",
      "0.06666676666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [02:22<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________Epoch2_______________________________________\n",
      "--IoU Scores Train--\n",
      "Class0: 0.0405 Class1: 0.0383 Class2: 0.0371 Class3: 0.0327 Class4: 0.0288 Class5: 0.0170 Class6: 0.0212 \n",
      "Class7: 0.0177 Class8: 0.0204 Class9: 0.0176 Class10: 0.0115 Class11: 0.0105 Class12: 0.0128 \n",
      "Train seg Loss: 16.678303213331148\n",
      "Train dom Loss: 3828.065991418949\n",
      "Train Loss: 271.88308601642865\n",
      "Train mIoU: 0.023554406677231597\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:09<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.0837 Class1: 0.0558 Class2: 0.0558 Class3: 0.0838 Class4: 0.0558 Class5: 0.0559 Class6: 0.0837 \n",
      "Class7: 0.0558 Class8: 0.0558 Class9: 0.0837 Class10: 0.0558 Class11: 0.0558 Class12: 0.0558 \n",
      "Epoch2\n",
      "Valid_Seg Loss: 8.863444662094116 Valid_dom Loss: 34878.86608072917\n",
      "Valid Loss: 2334.1246948242188\n",
      "Valid mIoU: 0.06441174346152533\n",
      "___________________________________________________________________________________________\n",
      "\n",
      "0.20000010000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [02:21<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________Epoch3_______________________________________\n",
      "--IoU Scores Train--\n",
      "Class0: 0.0127 Class1: 0.0147 Class2: 0.0145 Class3: 0.0200 Class4: 0.0216 Class5: 0.0190 Class6: 0.0203 \n",
      "Class7: 0.0177 Class8: 0.0178 Class9: 0.0165 Class10: 0.0153 Class11: 0.0130 Class12: 0.0115 \n",
      "Train seg Loss: 13.163391089525776\n",
      "Train dom Loss: 17503.168626647064\n",
      "Train Loss: 3513.7990070840588\n",
      "Train mIoU: 0.016493430941168653\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.0919 Class1: 0.0650 Class2: 0.0669 Class3: 0.0920 Class4: 0.0637 Class5: 0.0687 Class6: 0.0917 \n",
      "Class7: 0.0655 Class8: 0.0681 Class9: 0.0910 Class10: 0.0633 Class11: 0.0648 Class12: 0.0672 \n",
      "Epoch3\n",
      "Valid_Seg Loss: 1.6458939075469972 Valid_dom Loss: 1879.8141235351563\n",
      "Valid Loss: 377.6089213053385\n",
      "Valid mIoU: 0.07384103308946707\n",
      "___________________________________________________________________________________________\n",
      "\n",
      "0.4000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [02:20<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________Epoch4_______________________________________\n",
      "--IoU Scores Train--\n",
      "Class0: 0.0135 Class1: 0.0127 Class2: 0.0107 Class3: 0.0100 Class4: 0.0105 Class5: 0.0095 Class6: 0.0089 \n",
      "Class7: 0.0086 Class8: 0.0075 Class9: 0.0070 Class10: 0.0072 Class11: 0.0006 Class12: 0.0007 \n",
      "Train seg Loss: 20.10415329190268\n",
      "Train dom Loss: 399123.8302395586\n",
      "Train Loss: 159669.67423016092\n",
      "Train mIoU: 0.00825800221700478\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.0125 Class1: 0.0084 Class2: 0.0083 Class3: 0.0124 Class4: 0.0083 Class5: 0.0083 Class6: 0.0125 \n",
      "Class7: 0.0082 Class8: 0.0083 Class9: 0.0124 Class10: 0.0083 Class11: 0.0084 Class12: 0.0082 \n",
      "Epoch4\n",
      "Valid_Seg Loss: 4.643918291727702 Valid_dom Loss: 23018.7400390625\n",
      "Valid Loss: 9212.142171223959\n",
      "Valid mIoU: 0.009585422794933109\n",
      "___________________________________________________________________________________________\n",
      "\n",
      "0.6666667666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [02:21<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________Epoch5_______________________________________\n",
      "--IoU Scores Train--\n",
      "Class0: 0.0040 Class1: 0.0109 Class2: 0.0089 Class3: 0.0060 Class4: 0.0043 Class5: 0.0026 Class6: 0.0012 \n",
      "Class7: 0.0002 Class8: 0.0002 Class9: 0.0008 Class10: 0.0008 Class11: 0.0015 Class12: 0.0019 \n",
      "Train seg Loss: 33.425695201625\n",
      "Train dom Loss: 173701.46996229974\n",
      "Train Loss: 115834.41909425156\n",
      "Train mIoU: 0.0033332668298865437\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.0037 Class1: 0.0031 Class2: 0.0020 Class3: 0.0052 Class4: 0.0015 Class5: 0.0025 Class6: 0.0042 \n",
      "Class7: 0.0021 Class8: 0.0023 Class9: 0.0058 Class10: 0.0039 Class11: 0.0026 Class12: 0.0025 \n",
      "Epoch5\n",
      "Valid_Seg Loss: 4.113878711064657 Valid_dom Loss: 342.9411549886068\n",
      "Valid Loss: 232.74134368896483\n",
      "Valid mIoU: 0.0031957470999018278\n",
      "___________________________________________________________________________________________\n",
      "\n",
      "1.0000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 9/138 [00:09<02:12,  1.03s/it]"
     ]
    }
   ],
   "source": [
    "import random\n",
    "#torch.cuda.empty_cache()\n",
    "# import wandb\n",
    "\n",
    "\n",
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"practice_10_27_4d_res18\",\n",
    "    \n",
    "#     # track hyperparameters and run metadata\n",
    "#     config={\n",
    "#     \"learning_rate\": LR,\n",
    "#     \"architecture\": \"CNN\",\n",
    "#     \"dataset\": \"Samsung\",\n",
    "#     \"epochs\": EP,\n",
    "#     }\n",
    "# )\n",
    "for epoch in range(EP):\n",
    "    # 클래스별 IoU를 누적할 리스트 초기화\n",
    "    train_class_ious = []\n",
    "    fish_train_class_ious = []\n",
    "    # 학습\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    seg_losses = 0\n",
    "    domain_losses = 0\n",
    "    if alpha < 1:\n",
    "        alpha += epoch/EP\n",
    "    print(alpha)\n",
    "    \n",
    "    for source_images, source_masks in tqdm(source_dataloader):\n",
    "        #label = random.randint(0,3)\n",
    "        \n",
    "        for label in range(0,4): \n",
    "            source_image, source_mask = apply_fisheye_distortion(source_images, source_masks, label)\n",
    "            source_image = source_image.float().to(device)\n",
    "            source_mask = source_mask.long().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            source_outputs = model(source_image)\n",
    "\n",
    "            source_loss, seg_loss, domain_loss = loss_fn(source_outputs, source_mask, label, alpha = alpha)\n",
    "\n",
    "            seg_losses +=  seg_loss.item()\n",
    "            domain_losses += domain_loss.item()\n",
    "            \n",
    "            loss = source_loss\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "                # train 클래스별 IoU 계산\n",
    "        source_outputs = torch.softmax(source_outputs[0], dim=1).cpu()\n",
    "        source_outputs = torch.argmax(source_outputs, dim=1).numpy()\n",
    "\n",
    "        for class_id in range(N_CLASSES):\n",
    "            iou = calculate_iou_per_class(np.array(source_masks.cpu()), np.array(source_outputs), class_id)\n",
    "            train_class_ious.append(iou)\n",
    "\n",
    "    train_class_ious = np.array(train_class_ious).reshape(N_CLASSES, -1)\n",
    "    train_class_ious = np.mean(train_class_ious, axis=1)\n",
    "    print(f\"_______________________________________Epoch{epoch+1}_______________________________________\")\n",
    "    print(\"--IoU Scores Train--\")\n",
    "    for class_id, iou in enumerate(train_class_ious):\n",
    "        print(f'Class{class_id}: {iou:.4f}', end=\" \")\n",
    "        if (class_id+1) % 7 == 0:\n",
    "            print()\n",
    "    print()\n",
    "    # mIoU 계산\n",
    "    train_mIoU = np.mean(train_class_ious)\n",
    "\n",
    "    # 에폭마다 결과 출력 \n",
    "    \n",
    "    \n",
    "    print(f\"Train seg Loss: {(seg_losses/len(source_dataloader))}\")\n",
    "    print(f\"Train dom Loss: {(domain_losses/len(source_dataloader))}\")\n",
    "    print(f\"Train Loss: {(epoch_loss/len(source_dataloader))}\")\n",
    "    print(f\"Train mIoU: {train_mIoU}\" )\n",
    "    print(\"___________________________________________________________________________________________\\n\")\n",
    "\n",
    "\n",
    "    ################################################################\n",
    "    # 클래스별 IoU를 누적할 리스트 초기화\n",
    "    val_class_ious = []\n",
    "    fish_val_class_ious = []\n",
    "    val_epoch_loss = 0\n",
    "    val_seg_loss = 0\n",
    "    val_domain_loss = 0\n",
    "    # 학습\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        for target_images, target_masks in tqdm(val_target_dataloader):\n",
    "            label = 2.5\n",
    "            target_images, target_masks = apply_fisheye_distortion(target_images, target_masks, label)\n",
    "            target_images = target_images.float().to(device)\n",
    "            target_masks = target_masks.long().to(device)\n",
    "\n",
    "            target_outputs = model(target_images)\n",
    "\n",
    "            target_loss, target_seg_loss, target_domain_loss = loss_fn(target_outputs, target_masks, 0, alpha = alpha)\n",
    "\n",
    "            val_seg_loss +=  target_seg_loss.item()\n",
    "            val_domain_loss += target_domain_loss.item()\n",
    "            \n",
    "            loss = target_loss\n",
    "\n",
    "            val_epoch_loss += loss.item()\n",
    "\n",
    "            # train 클래스별 IoU 계산\n",
    "            target_outputs = torch.softmax(target_outputs[0], dim=1).cpu()\n",
    "            target_outputs = torch.argmax(target_outputs, dim=1).numpy()\n",
    "\n",
    "            for class_id in range(N_CLASSES):\n",
    "                iou = calculate_iou_per_class(np.array(target_masks.cpu()), np.array(target_outputs), class_id)\n",
    "                fish_val_class_ious.append(iou)\n",
    "\n",
    "    fish_val_class_ious = np.array(fish_val_class_ious).reshape(N_CLASSES, -1)\n",
    "    fish_val_class_ious = np.mean(fish_val_class_ious, axis=1)\n",
    "    print()\n",
    "    print(\"--IoU Scores Fish val--\")\n",
    "    for class_id, iou in enumerate(fish_val_class_ious):\n",
    "        print(f'Class{class_id}: {iou:.4f}', end=\" \")\n",
    "        if (class_id+1) % 7 == 0:\n",
    "            print()\n",
    "\n",
    "    # mIoU 계산\n",
    "    fish_val_mIoU = np.mean(fish_val_class_ious)\n",
    "\n",
    "    # 에폭마다 결과 출력 \n",
    "    print(f\"\\nEpoch{epoch+1}\")\n",
    "    print(f\"Valid_Seg Loss: {(val_seg_loss/len(val_target_dataloader))}\",f\"Valid_dom Loss: {(val_domain_loss/len(val_target_dataloader))}\")\n",
    "    print(f\"Valid Loss: {(val_epoch_loss/len(val_target_dataloader))}\")\n",
    "    print(f\"Valid mIoU: {fish_val_mIoU}\" )\n",
    "    print(\"___________________________________________________________________________________________\\n\")\n",
    "\n",
    "#     # log metrics to wandb\n",
    "#     wandb.log({\"train score\": train_mIoU})\n",
    "#     wandb.log({\"val score\": fish_val_mIoU})\n",
    "#     wandb.log({\"train loss\": (epoch_loss/len(source_dataloader))})\n",
    "#     wandb.log({\"val loss\": (val_epoch_loss/len(val_target_dataloader))})\n",
    "    \n",
    "    \n",
    "# # [optional] finish the wandb run, necessary in notebooks\n",
    "# wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './data/resnet34.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byungwan_resn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
