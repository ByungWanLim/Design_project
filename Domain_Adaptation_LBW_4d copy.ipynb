{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/MMI24limbyungwan/.conda/envs/byungwan_resn/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "#from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# GPU 사용이 가능할 경우, GPU를 사용할 수 있게 함.'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "print(device)\n",
    "\n",
    "print(os.environ.get('CUDA_VISIBLE_DEVICES'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "# 클래스별 IoU를 계산하기 위한 함수\n",
    "def calculate_iou_per_class(y_true, y_pred, class_id):\n",
    "    intersection = np.sum((y_true == class_id) & (y_pred == class_id))\n",
    "    union = np.sum((y_true == class_id) | (y_pred == class_id))\n",
    "    iou = intersection / union if union > 0 else 0\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def apply_fisheye_distortion(image, mask, label):\n",
    "\n",
    "#     # 이미지 크기 가져오기\n",
    "#     batch, channel, height, width = image.shape\n",
    "#     image = image.permute(0, 2, 3, 1)\n",
    "#     mask = mask.permute(0, 1, 2)\n",
    "#     images = image.split(1, dim=0)\n",
    "#     masks = mask.split(1, dim=0)\n",
    "\n",
    "#     # 카메라 매트릭스 생성\n",
    "#     focal_length = width / 4\n",
    "#     center_x = width / 2\n",
    "#     center_y = height / 2\n",
    "#     camera_matrix = np.array([[focal_length, 0, center_x],\n",
    "#                               [0, focal_length, center_y],\n",
    "#                               [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "#     # 왜곡 계수 생성\n",
    "#     #dist_coeffs = np.array([0, 0.5, 0, 0], dtype=np.float32)\n",
    "#     dist_coeffs = np.array([0, 0.2*label, 0, 0], dtype=np.float32)\n",
    "\n",
    "#     # 왜곡 보정\n",
    "#     undistorted_images = []\n",
    "#     undistorted_masks = []\n",
    "#     for i in range(batch):\n",
    "#         image = images[i]\n",
    "#         mask = mask[i]\n",
    "#         image = image.cpu().numpy()\n",
    "#         mask = mask.cpu().numpy\n",
    "#         undistorted_image = cv2.undistort(image.squeeze(), camera_matrix, dist_coeffs)\n",
    "#         undistorted_mask = cv2.undistort(mask.squeeze(), camera_matrix, dist_coeffs)\n",
    "#         undistorted_mask = np.round(mask).astype(np.uint8)\n",
    "#         undistorted_mask[undistorted_mask > 12] = 12\n",
    "#         undistorted_image = torch.from_numpy(undistorted_image).to(device)\n",
    "#         undistorted_mask = torch.from_numpy(undistorted_mask).to(device)\n",
    "#         undistorted_images.append(undistorted_image)\n",
    "#         undistorted_masks.append(undistorted_mask)\n",
    "\n",
    "#     undistorted_images = torch.stack(undistorted_images, dim=0)\n",
    "#     undistorted_masks = torch.stack(undistorted_masks, dim=0)\n",
    "\n",
    "#     undistorted_images = undistorted_images.permute(0,3,1,2)\n",
    "#     undistorted_masks = undistorted_masks.permute(0,1,2)\n",
    "    \n",
    "#     return undistorted_images, undistorted_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "def apply_fisheye_distortion(images, masks, label):\n",
    "    # 이미지 크기 가져오기\n",
    "    batch, channel, height, width = images.shape\n",
    "\n",
    "    # 카메라 매트릭스 생성\n",
    "    focal_length = width / 4\n",
    "    center_x = width / 2\n",
    "    center_y = height / 2\n",
    "    camera_matrix = np.array([[focal_length, 0, center_x],\n",
    "                              [0, focal_length, center_y],\n",
    "                              [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "    # 왜곡 계수 생성\n",
    "    dist_coeffs = np.array([0, 0.7 * label, 0, 0], dtype=np.float32)\n",
    "\n",
    "    # 왜곡 보정\n",
    "    undistorted_images = []\n",
    "    undistorted_masks = []\n",
    "\n",
    "    for i in range(batch):\n",
    "        image = images[i].permute(1, 2, 0).cpu().numpy()  # 텐서를 NumPy 배열로 변환\n",
    "        mask = masks[i].cpu().numpy()\n",
    "        undistorted_image = cv2.undistort(image, camera_matrix, dist_coeffs)\n",
    "        undistorted_mask = cv2.undistort(mask, camera_matrix, dist_coeffs)\n",
    "        undistorted_mask = np.round(undistorted_mask).astype(np.uint8)\n",
    "        undistorted_mask[undistorted_mask > 12] = 12\n",
    "\n",
    "        # 다시 텐서로 변환\n",
    "        undistorted_image = torch.from_numpy(undistorted_image).permute(2, 0, 1).float().to(device)\n",
    "        undistorted_mask = torch.from_numpy(undistorted_mask).long().to(device)\n",
    "\n",
    "        undistorted_images.append(undistorted_image)\n",
    "        undistorted_masks.append(undistorted_mask)\n",
    "\n",
    "    undistorted_images = torch.stack(undistorted_images, dim=0)\n",
    "    undistorted_masks = torch.stack(undistorted_masks, dim=0)\n",
    "\n",
    "    return undistorted_images, undistorted_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # 이미지 데이터 (batch, channel, height, width)\n",
    "# image_data = torch.randn(4, 3, 256, 256)\n",
    "\n",
    "# # 이미지 차원 변경 (batch, height, width, channel)\n",
    "# image_data_permuted = image_data.permute(0, 2, 3, 1)\n",
    "\n",
    "# # 이미지 크기 확인\n",
    "# print(image_data_permuted.shape)\n",
    "\n",
    "# # 4개의 이미지로 나누기\n",
    "# images = image_data_permuted.split(1, dim=0)\n",
    "# # 또는 images = torch.split(image_data_permuted, 1, dim=0)\n",
    "# undistorted_images = []\n",
    "# # 4개 이미지의 크기 확인\n",
    "# for i, image in enumerate(images):\n",
    "#     print(f\"Image {i + 1} shape: {image.shape}\")\n",
    "#     undistorted_images.append(images[i].squeeze())\n",
    "\n",
    "# undistorted_images2 = torch.stack(undistorted_images, dim=0)\n",
    "# undistorted_images3 = undistorted_images2.permute(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #directory_path = \"/mnt/nas27/Dataset/Samsung_DM\"\n",
    "        directory_path = './data/224'\n",
    "        img_path = self.data.iloc[idx, 1]\n",
    "        img_path = os.path.join(directory_path, img_path)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "        \n",
    "        mask_path = self.data.iloc[idx, 2]\n",
    "        mask_path = os.path.join(directory_path, mask_path)\n",
    "        mask = cv2.imread(mask_path)\n",
    "        #mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        mask = np.round(mask).astype(np.uint8)\n",
    "        mask[mask > 12] = 12 #배경을 픽셀값 12로 간주\n",
    "        mask += 1\n",
    "        mask[mask == 13] = 0\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# class CustomDataset_target(Dataset):\n",
    "#     def __init__(self, csv_file, transform=None, infer=False):\n",
    "#         self.data = pd.read_csv(csv_file)\n",
    "#         self.transform = transform\n",
    "#         self.infer = infer\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         directory_path = \"/mnt/nas27/Dataset/Samsung_DM\"\n",
    "#         img_path = self.data.iloc[idx, 1]\n",
    "#         img_path = os.path.join(directory_path, img_path[2:])\n",
    "#         image = cv2.imread(img_path)\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "#         if self.infer:\n",
    "#             if self.transform:\n",
    "#                 image = self.transform(image=image)['image']\n",
    "#             return image\n",
    "\n",
    "\n",
    "#         if self.transform:\n",
    "#             augmented = self.transform(image=image)\n",
    "#             image = augmented['image']\n",
    "            \n",
    "\n",
    "#         return image\n",
    "     \n",
    "\n",
    "transform = A.Compose(\n",
    "    [   \n",
    "        #A.Resize(224, 224),\n",
    "        #A.Resize(128, 128),\n",
    "        A.Normalize(),\n",
    "        \n",
    "        # 변형\n",
    "        # A.VerticalFlip(p=0.5),\n",
    "        # A.RandomRotate90(p=0.5),\n",
    "        # A.HueSaturationValue(p=0.2),\n",
    "        \n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Unet의 기본이 되는 conv블럭\n",
    "# class ConvBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(ConvBlock, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "#         self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "        \n",
    "#         self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)  # 여기서 in_channels는 out_channels와 동일해야 합니다.\n",
    "#         self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.relu1(x)\n",
    "        \n",
    "#         x = self.conv2(x)\n",
    "#         x = self.bn2(x)\n",
    "#         x = self.relu2(x)\n",
    "#         return x\n",
    "\n",
    "# #인코더 블럭\n",
    "# class EncoderBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(EncoderBlock,self).__init__()\n",
    "#         self.convblock1 = ConvBlock(in_channels, out_channels)  # 첫 번째 ConvBlock의 in_channels는 입력 이미지의 채널 수와 일치해야 합니다.\n",
    "#         #self.convblock2 = ConvBlock(out_channels, out_channels)  # 두 번째 ConvBlock의 in_channels는 out_channels와 일치해야 합니다.\n",
    "#         self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "#     def forward(self,x):\n",
    "#         x = self.convblock1(x)\n",
    "#         #x = self.convblock2(x)\n",
    "#         p = self.maxpool(x)\n",
    "#         return x , p\n",
    "# #디코더 블럭\n",
    "# #디코더는 업샘플링 이후 스킵연결과 붙어서 convblock을 통과해야함\n",
    "# #skip보다 작은 x x먼저 업샘플링 32 -> 64 , skip과 결합 6464 \n",
    "# class DecoderBlock(nn.Module):\n",
    "#     def __init__(self, channels):\n",
    "#         super(DecoderBlock,self).__init__()\n",
    "#         self.upsample = nn.ConvTranspose2d(channels*2, channels, kernel_size=4, stride=2, padding=1)#x 업샘플링\n",
    "#         self.convblock1 = ConvBlock(channels*2, channels)#차원감소\n",
    "#         #self.convblock2 = ConvBlock(channels, channels)\n",
    "#     def forward(self,x,skip):\n",
    "#         x = self.upsample(x)\n",
    "#         x = torch.cat([x, skip], dim=1)\n",
    "#         x = self.convblock1(x)\n",
    "#         #x = self.convblock2(x)\n",
    "#         return x\n",
    "\n",
    "# ###########################################\n",
    "# class GradReverse(torch.autograd.Function):\n",
    "#     @staticmethod\n",
    "#     def forward(self, x):\n",
    "#         return x.view_as(x)\n",
    "#     @staticmethod\n",
    "#     def backward(self, grad_output): # 역전파 시에 gradient에 음수를 취함\n",
    "#         return (grad_output * -1)\n",
    "\n",
    "# class domain_classifier(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(domain_classifier, self).__init__()\n",
    "#         self.fc1 = nn.Linear(224*224*64, 10)\n",
    "#         self.fc2 = nn.Linear(10, 4) # source = 0, target = 1 회귀 가정\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.view(-1, 224*224*64)\n",
    "#         x = GradReverse.apply(x) # gradient reverse\n",
    "#         x = F.leaky_relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "        \n",
    "#         return x\n",
    "\n",
    "# ###########################################\n",
    "\n",
    "\n",
    "# #Unet구조 middle의 xm값의 움직임에 주의\n",
    "# class Unet(nn.Module):\n",
    "#     def __init__(self,n_classes):\n",
    "#         super(Unet,self).__init__()\n",
    "#         self.encoder1 = EncoderBlock(3,64)\n",
    "#         self.encoder2 = EncoderBlock(64,128)\n",
    "#         self.encoder3 = EncoderBlock(128,256)\n",
    "#         self.encoder4 = EncoderBlock(256,512)\n",
    "        \n",
    "#         self.middleconv = ConvBlock(512,1024)\n",
    "        \n",
    "        \n",
    "#         self.decoder4 = DecoderBlock(512)\n",
    "#         self.decoder3 = DecoderBlock(256)\n",
    "#         self.decoder2 = DecoderBlock(128)\n",
    "#         self.decoder1 = DecoderBlock(64)\n",
    "#         self.segmap = nn.Conv2d(64,n_classes, kernel_size=1)\n",
    "        \n",
    "#         self.domain_classifier = domain_classifier()\n",
    "                                        \n",
    "\n",
    "#     def forward(self,x):\n",
    "#         x1,p = self.encoder1(x)#3->64   #P:256,256 x1 :512,512\n",
    "#         x2,p = self.encoder2(p)#64->128 #P:128,128 x2:256,256\n",
    "#         x3,p = self.encoder3(p)#128->256#p:64,64 x3:128,128\n",
    "#         x4,p = self.encoder4(p)#256->512#p:32,32 x4:64,64\n",
    "        \n",
    "#         xm = self.middleconv(p)#512->1024#32,32\n",
    "        \n",
    "#         x = self.decoder4(xm,x4)#뉴런:1024->512->512 #출력tensor:64,64\n",
    "#         x = self.decoder3(x,x3)#뉴런:512->256->256 #출력tensor:128,128\n",
    "#         x = self.decoder2(x,x2)#뉴런:256->128->128 #출력tensor:256,256\n",
    "#         x = self.decoder1(x,x1)#뉴런:128->64->64 #출력tensor:512,512\n",
    "\n",
    "#         x_c = self.segmap(x)\n",
    "#         x_d = self.domain_classifier(x)\n",
    "#         # print(\"x_c\", x_c.shape)\n",
    "#         # print(\"x_d\", x_d.shape)\n",
    "#         return x_c, x_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradReverse(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(self, x):\n",
    "        return x.view_as(x)\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output): # 역전파 시에 gradient에 음수를 취함\n",
    "        return grad_output * (-1)\n",
    "\n",
    "class domain_classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(domain_classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(224*224*64, 10)\n",
    "        self.fc2 = nn.Linear(10, 4) # source = 0, target = 1 회귀 가정\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 224*224*64)\n",
    "        x = GradReverse.apply(x) # gradient reverse\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        #return torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "class IdentityBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(IdentityBlock, self).__init__()\n",
    "        \n",
    "        # 3x3 convolution\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # 3x3 convolution\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # Skip connection\n",
    "        self.skip = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        # Adding the skip connection\n",
    "        out += self.skip(identity)\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "#인코더 블럭\n",
    "class Conv2(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels):\n",
    "        super(Conv2,self).__init__() \n",
    "        self.identityblock1 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock2 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock3 = IdentityBlock(in_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
    "    def forward(self,x):\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        x = self.identityblock3(x)\n",
    "        p = self.maxpool(x)\n",
    "        \n",
    "        return x , p\n",
    "class Conv3(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels):\n",
    "        super(Conv3,self).__init__()         \n",
    "        self.identityblock1 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock2 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock3 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock4 = IdentityBlock(in_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
    "    def forward(self,x):\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        x = self.identityblock3(x)\n",
    "        x = self.identityblock4(x)\n",
    "        p = self.maxpool(x)\n",
    "        \n",
    "        return x , p\n",
    "class Conv4(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels):\n",
    "        super(Conv4,self).__init__()         \n",
    "        self.identityblock1 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock2 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock3 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock4 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock5 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock6 = IdentityBlock(in_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
    "    def forward(self,x):\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        x = self.identityblock3(x)\n",
    "        x = self.identityblock4(x)\n",
    "        x = self.identityblock5(x)\n",
    "        x = self.identityblock6(x)\n",
    "        p = self.maxpool(x)\n",
    "        \n",
    "        return x , p\n",
    "class Conv5(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels):\n",
    "        super(Conv5,self).__init__() \n",
    "        self.identityblock1 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock2 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock3 = IdentityBlock(in_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        x = self.identityblock3(x)\n",
    "        p = self.maxpool(x)\n",
    "        \n",
    "        return x , p\n",
    "#디코더 블럭\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.upsample = nn.ConvTranspose2d(channels*2, channels, kernel_size=4, stride=2, padding=1) # output_padding 추가\n",
    "        self.convblock1 = IdentityBlock(channels*2, channels)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = self.upsample(x)\n",
    "        if x.size(2) != skip.size(2) or x.size(3) != skip.size(3):\n",
    "            x = F.interpolate(x, size=(skip.size(2), skip.size(3)))\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.convblock1(x)\n",
    "        #print(\"x\",x.shape,\"skip: \",skip.shape)\n",
    "        return x\n",
    "\n",
    "#Unet구조 middle의 xm값의 움직임에 주의\n",
    "class Resnet34_Unet(nn.Module):\n",
    "    def __init__(self,n_classes):\n",
    "        super(Resnet34_Unet,self).__init__()\n",
    "        self.fconv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.fbn1 = nn.BatchNorm2d(64)\n",
    "        self.frelu1 = nn.ReLU()\n",
    "        self.fmaxpooling = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "        \n",
    "        self.conv2 = Conv2(64,128)\n",
    "        self.conv3 = Conv3(128,256)\n",
    "        self.conv4 = Conv4(256,512)\n",
    "        self.conv5 = Conv5(512,1024)\n",
    "        \n",
    "        self.middleconv = IdentityBlock(1024,2048)\n",
    "        self.dropout = nn.Dropout2d(0.1) #\n",
    "           \n",
    "        self.decoder5 = DecoderBlock(1024)\n",
    "        self.decoder4 = DecoderBlock(512)\n",
    "        self.decoder3 = DecoderBlock(256)\n",
    "        self.decoder2 = DecoderBlock(128)\n",
    "        self.decoder1 = DecoderBlock(64)\n",
    "        self.transpose = nn.ConvTranspose2d(64, 64, kernel_size=4, stride=2, padding=1) # output_padding 추가\n",
    "        \n",
    "        self.segmap = nn.Conv2d(64,n_classes, kernel_size=1)\n",
    "        self.domain_classifier = domain_classifier()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fconv1(x)#3->64\n",
    "        x0 = self.fbn1(x)\n",
    "        x1 = self.frelu1(x)\n",
    "        p = self.fmaxpooling(x1)#첫 conv: x0([8, 64, 109, 109]) p([8, 64, 54, 54])\n",
    "        #print(\"conv1: \",x1.shape, \"maxpooling: \",p.shape)\n",
    "        x2,p = self.conv2(p)\n",
    "        #print(\"conv2: \",x2.shape, \"maxpooling: \",p.shape)\n",
    "        x3,p = self.conv3(p)\n",
    "        #print(\"conv3: \",x3.shape, \"maxpooling: \",p.shape)\n",
    "        x4,p = self.conv4(p)\n",
    "        #print(\"conv4: \",x4.shape, \"maxpooling: \",p.shape)\n",
    "        x5,p = self.conv5(p)\n",
    "        #print(\"conv5: \",x5.shape, \"maxpooling: \",p.shape)\n",
    "        \n",
    "        xm = self.middleconv(p)#xm([8, 4096, 2, 2])\n",
    "        #print(\"xm: \",xm.shape, \"maxpooling: \",p.shape)\n",
    "        xm = self.dropout(xm)\n",
    "        \n",
    "        x = self.decoder5(xm,x5)#뉴런:2048*2->2048 1\n",
    "        x = self.decoder4(x,x4)#뉴런:1024*2->1024 \n",
    "        x = self.decoder3(x,x3) #14\n",
    "        x = self.decoder2(x,x2)#28\n",
    "        x = self.decoder1(x,x1)#55\n",
    "        x = self.transpose(x)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        #x = F.interpolate(x, size=(224, 224))\n",
    "        x_c = self.segmap(x)\n",
    "        x_d = self.domain_classifier(x)\n",
    "        \n",
    "        return x_c,x_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # 저장된 class_weights를 불러옵니다.\n",
    "# class_weights_path = 'CLASS_WEIGHTS.pkl'\n",
    "\n",
    "# with open(class_weights_path, 'rb') as file:\n",
    "#     CLASS_WEIGHTS = pickle.load(file)\n",
    "\n",
    "# print(CLASS_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function과 optimizer 정의\n",
    "\n",
    "class DANN_Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DANN_Loss, self).__init__()\n",
    "\n",
    "        #self.CE = nn.CrossEntropyLoss(weight=CLASS_WEIGHTS) # 0~9 class 분류용\n",
    "        self.CE = nn.CrossEntropyLoss()\n",
    "        \n",
    "        \n",
    "    # result : DANN_CNN에서 반환된 값\n",
    "    # label : 숫자 0 ~ 9에 대한 라벨\n",
    "    # domain_num : 0(source) or 1(target)\n",
    "    def forward(self, result, label, domain_num, alpha = 1):\n",
    "        label_logits, domain_logits = result # DANN_CNN의 결과\n",
    "\n",
    "        batch_size = domain_logits.shape[0]\n",
    "\n",
    "        segment_loss = self.CE(label_logits, label) # class 분류 loss\n",
    "        \n",
    "        domain_target = torch.LongTensor([domain_num] * batch_size).to(device)\n",
    "        domain_loss = self.CE(domain_logits, domain_target) # domain 분류 loss\n",
    "        \n",
    "        #domain_target = torch.FloatTensor([domain_num] * batch_size).unsqueeze(1).to(device)\n",
    "        #domain_loss = self.BCE(domain_logits, domain_target) # domain 분류 loss\n",
    "        \n",
    "        loss = segment_loss + alpha * domain_loss\n",
    "        # print(\"segment_mask : \", label.shape)\n",
    "        # print(\"domain_answer : \", domain_target.shape)\n",
    "        return loss ,segment_loss, domain_loss\n",
    "    \n",
    "\n",
    "loss_fn = DANN_Loss().to(device)\n",
    "\n",
    "#criterion =nn.CrossEntropyLoss()\n",
    "#domain_criterion = nn.BCELoss()\n",
    "#criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "EP = 15\n",
    "BATCH_SIZE = 16\n",
    "ACCMULATION_STEP = 1 \n",
    "N_CLASSES = 13 #IoU 점수측정하기 위한 클래스의 개수\n",
    "ALPHA = 0.5\n",
    "# model 초기화\n",
    "model = Resnet34_Unet(n_classes = N_CLASSES).to(device)\n",
    "#model = Unet(n_classes = N_CLASSES).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "optimizer.zero_grad() \n",
    "\n",
    "source_dataset = CustomDataset(csv_file='./data/896_csv/train_source.csv', transform=transform)\n",
    "source_dataloader = DataLoader(source_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_target_dataset = CustomDataset(csv_file='./data/896_csv/val_source.csv', transform=transform)\n",
    "val_target_dataloader = DataLoader(val_target_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [05:26<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________Epoch1_______________________________________\n",
      "--IoU Scores Train--\n",
      "Class0: 0.0155 Class1: 0.0105 Class2: 0.0095 Class3: 0.0145 Class4: 0.0203 Class5: 0.0190 Class6: 0.0207 \n",
      "Class7: 0.0192 Class8: 0.0216 Class9: 0.0264 Class10: 0.0336 Class11: 0.0422 Class12: 0.0384 \n",
      "Train seg Loss: 7.316576304643051\n",
      "Train dom Loss: 26673.07893918217\n",
      "Train Loss: 13343.856054735896\n",
      "Train mIoU: 0.022421155101590304\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:20<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.2261 Class1: 0.1671 Class2: 0.1933 Class3: 0.2236 Class4: 0.1890 Class5: 0.2003 Class6: 0.2202 \n",
      "Class7: 0.1837 Class8: 0.2025 Class9: 0.2044 Class10: 0.1949 Class11: 0.1719 Class12: 0.1953 \n",
      "Epoch1\n",
      "Valid_Seg Loss: 0.29881482223669686 Valid_dom Loss: 15290.69501953125\n",
      "Valid Loss: 7645.646354166666\n",
      "Valid mIoU: 0.1978645436084943\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [04:25<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________Epoch2_______________________________________\n",
      "--IoU Scores Train--\n",
      "Class0: 0.0415 Class1: 0.0478 Class2: 0.0481 Class3: 0.0515 Class4: 0.0543 Class5: 0.0544 Class6: 0.0585 \n",
      "Class7: 0.0576 Class8: 0.0595 Class9: 0.0605 Class10: 0.0602 Class11: 0.0613 Class12: 0.0596 \n",
      "Train seg Loss: 7.10208223204034\n",
      "Train dom Loss: 30165.701914911686\n",
      "Train Loss: 15089.95305303468\n",
      "Train mIoU: 0.05498180751813889\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:37<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.2940 Class1: 0.2288 Class2: 0.2606 Class3: 0.3082 Class4: 0.2507 Class5: 0.2873 Class6: 0.3159 \n",
      "Class7: 0.2421 Class8: 0.2673 Class9: 0.2866 Class10: 0.2659 Class11: 0.2727 Class12: 0.2666 \n",
      "Epoch2\n",
      "Valid_Seg Loss: 0.23273096581300098 Valid_dom Loss: 16234.858072916666\n",
      "Valid Loss: 8117.661767578125\n",
      "Valid mIoU: 0.2728405900854681\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [08:38<00:00,  3.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________Epoch3_______________________________________\n",
      "--IoU Scores Train--\n",
      "Class0: 0.0603 Class1: 0.0627 Class2: 0.0613 Class3: 0.0618 Class4: 0.0624 Class5: 0.0606 Class6: 0.0634 \n",
      "Class7: 0.0605 Class8: 0.0623 Class9: 0.0636 Class10: 0.0614 Class11: 0.0642 Class12: 0.0625 \n",
      "Train seg Loss: 7.140414606023958\n",
      "Train dom Loss: 29939.47521441916\n",
      "Train Loss: 14976.878004063892\n",
      "Train mIoU: 0.06208199457039062\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:33<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.2797 Class1: 0.2285 Class2: 0.2513 Class3: 0.2933 Class4: 0.2485 Class5: 0.2682 Class6: 0.3042 \n",
      "Class7: 0.2298 Class8: 0.2528 Class9: 0.2845 Class10: 0.2577 Class11: 0.2618 Class12: 0.2693 \n",
      "Epoch3\n",
      "Valid_Seg Loss: 0.23142580091953277 Valid_dom Loss: 16947.0349609375\n",
      "Valid Loss: 8473.748958333334\n",
      "Valid mIoU: 0.2638212821605912\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [08:58<00:00,  3.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________Epoch4_______________________________________\n",
      "--IoU Scores Train--\n",
      "Class0: 0.0611 Class1: 0.0637 Class2: 0.0624 Class3: 0.0637 Class4: 0.0628 Class5: 0.0620 Class6: 0.0642 \n",
      "Class7: 0.0606 Class8: 0.0636 Class9: 0.0651 Class10: 0.0627 Class11: 0.0640 Class12: 0.0629 \n",
      "Train seg Loss: 7.184044745737228\n",
      "Train dom Loss: 29674.649661741394\n",
      "Train Loss: 14844.508883164952\n",
      "Train mIoU: 0.06297689135493158\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:35<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.2540 Class1: 0.1968 Class2: 0.2095 Class3: 0.2656 Class4: 0.2126 Class5: 0.2197 Class6: 0.2810 \n",
      "Class7: 0.1978 Class8: 0.2126 Class9: 0.2435 Class10: 0.2326 Class11: 0.2269 Class12: 0.2327 \n",
      "Epoch4\n",
      "Valid_Seg Loss: 0.3146576424439748 Valid_dom Loss: 17100.980598958333\n",
      "Valid Loss: 8550.8048828125\n",
      "Valid mIoU: 0.22963788444062758\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [08:43<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________Epoch5_______________________________________\n",
      "--IoU Scores Train--\n",
      "Class0: 0.0623 Class1: 0.0640 Class2: 0.0630 Class3: 0.0644 Class4: 0.0663 Class5: 0.0651 Class6: 0.0664 \n",
      "Class7: 0.0644 Class8: 0.0648 Class9: 0.0674 Class10: 0.0649 Class11: 0.0656 Class12: 0.0649 \n",
      "Train seg Loss: 7.248759192131136\n",
      "Train dom Loss: 29433.63278065557\n",
      "Train Loss: 14724.06515321465\n",
      "Train mIoU: 0.06487751880605594\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:37<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.3491 Class1: 0.2825 Class2: 0.3297 Class3: 0.3580 Class4: 0.3039 Class5: 0.3392 Class6: 0.3700 \n",
      "Class7: 0.2838 Class8: 0.3267 Class9: 0.3418 Class10: 0.3210 Class11: 0.3130 Class12: 0.3354 \n",
      "Epoch5\n",
      "Valid_Seg Loss: 0.1695392111937205 Valid_dom Loss: 16943.1505859375\n",
      "Valid Loss: 8471.74482421875\n",
      "Valid mIoU: 0.32724816363040765\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [08:40<00:00,  3.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________Epoch6_______________________________________\n",
      "--IoU Scores Train--\n",
      "Class0: 0.0645 Class1: 0.0677 Class2: 0.0666 Class3: 0.0668 Class4: 0.0661 Class5: 0.0664 Class6: 0.0683 \n",
      "Class7: 0.0648 Class8: 0.0679 Class9: 0.0687 Class10: 0.0662 Class11: 0.0683 Class12: 0.0662 \n",
      "Train seg Loss: 7.41865724708507\n",
      "Train dom Loss: 29268.80074232903\n",
      "Train Loss: 14641.81903242336\n",
      "Train mIoU: 0.06679667047412642\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:38<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.3273 Class1: 0.2505 Class2: 0.2884 Class3: 0.3400 Class4: 0.2747 Class5: 0.3060 Class6: 0.3480 \n",
      "Class7: 0.2645 Class8: 0.2944 Class9: 0.3042 Class10: 0.2979 Class11: 0.2955 Class12: 0.3130 \n",
      "Epoch6\n",
      "Valid_Seg Loss: 0.2007597381869952 Valid_dom Loss: 18101.316471354166\n",
      "Valid Loss: 9050.858984375\n",
      "Valid mIoU: 0.3003344344065494\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/138 [00:12<09:09,  4.07s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Adaptation_LBW_4d copy.ipynb 셀 15\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsecond/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Adaptation_LBW_4d%20copy.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mfor\u001b[39;00m source_images, source_masks \u001b[39min\u001b[39;00m tqdm(source_dataloader):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsecond/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Adaptation_LBW_4d%20copy.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39m#label = random.randint(0,3)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsecond/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Adaptation_LBW_4d%20copy.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39m4\u001b[39m): \n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bsecond/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Adaptation_LBW_4d%20copy.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m         source_image, source_mask \u001b[39m=\u001b[39m apply_fisheye_distortion(source_images, source_masks, label)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsecond/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Adaptation_LBW_4d%20copy.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m         source_image \u001b[39m=\u001b[39m source_image\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsecond/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Adaptation_LBW_4d%20copy.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m         source_mask \u001b[39m=\u001b[39m source_mask\u001b[39m.\u001b[39mlong()\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[1;32m/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Adaptation_LBW_4d copy.ipynb 셀 15\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsecond/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Adaptation_LBW_4d%20copy.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m image \u001b[39m=\u001b[39m images[i]\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()  \u001b[39m# 텐서를 NumPy 배열로 변환\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsecond/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Adaptation_LBW_4d%20copy.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m mask \u001b[39m=\u001b[39m masks[i]\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bsecond/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Adaptation_LBW_4d%20copy.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m undistorted_image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mundistort(image, camera_matrix, dist_coeffs)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsecond/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Adaptation_LBW_4d%20copy.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m undistorted_mask \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mundistort(mask, camera_matrix, dist_coeffs)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsecond/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Adaptation_LBW_4d%20copy.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m undistorted_mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mround(undistorted_mask)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39muint8)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "#torch.cuda.empty_cache()\n",
    "# import wandb\n",
    "\n",
    "\n",
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"practice_10_27_4d_res18\",\n",
    "    \n",
    "#     # track hyperparameters and run metadata\n",
    "#     config={\n",
    "#     \"learning_rate\": LR,\n",
    "#     \"architecture\": \"CNN\",\n",
    "#     \"dataset\": \"Samsung\",\n",
    "#     \"epochs\": EP,\n",
    "#     }\n",
    "# )\n",
    "for epoch in range(EP):\n",
    "    # 클래스별 IoU를 누적할 리스트 초기화\n",
    "    train_class_ious = []\n",
    "    fish_train_class_ious = []\n",
    "    # 학습\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    seg_losses = 0\n",
    "    domain_losses = 0\n",
    "    \n",
    "    \n",
    "    for source_images, source_masks in tqdm(source_dataloader):\n",
    "        #label = random.randint(0,3)\n",
    "        \n",
    "        for label in range(0,4): \n",
    "            source_image, source_mask = apply_fisheye_distortion(source_images, source_masks, label)\n",
    "            source_image = source_image.float().to(device)\n",
    "            source_mask = source_mask.long().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            source_outputs = model(source_image)\n",
    "\n",
    "            source_loss, seg_loss, domain_loss = loss_fn(source_outputs, source_mask, label, alpha = ALPHA)\n",
    "\n",
    "            seg_losses +=  seg_loss.item()\n",
    "            domain_losses += domain_loss.item()\n",
    "            \n",
    "            loss = source_loss\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "                # train 클래스별 IoU 계산\n",
    "        source_outputs = torch.softmax(source_outputs[0], dim=1).cpu()\n",
    "        source_outputs = torch.argmax(source_outputs, dim=1).numpy()\n",
    "\n",
    "        for class_id in range(N_CLASSES):\n",
    "            iou = calculate_iou_per_class(np.array(source_masks.cpu()), np.array(source_outputs), class_id)\n",
    "            train_class_ious.append(iou)\n",
    "\n",
    "    train_class_ious = np.array(train_class_ious).reshape(N_CLASSES, -1)\n",
    "    train_class_ious = np.mean(train_class_ious, axis=1)\n",
    "    print(f\"_______________________________________Epoch{epoch+1}_______________________________________\")\n",
    "    print(\"--IoU Scores Train--\")\n",
    "    for class_id, iou in enumerate(train_class_ious):\n",
    "        print(f'Class{class_id}: {iou:.4f}', end=\" \")\n",
    "        if (class_id+1) % 7 == 0:\n",
    "            print()\n",
    "    print()\n",
    "    # mIoU 계산\n",
    "    train_mIoU = np.mean(train_class_ious)\n",
    "\n",
    "    # 에폭마다 결과 출력 \n",
    "    \n",
    "    \n",
    "    print(f\"Train seg Loss: {(seg_losses/len(source_dataloader))}\")\n",
    "    print(f\"Train dom Loss: {(domain_losses/len(source_dataloader))}\")\n",
    "    print(f\"Train Loss: {(epoch_loss/len(source_dataloader))}\")\n",
    "    print(f\"Train mIoU: {train_mIoU}\" )\n",
    "    print(\"___________________________________________________________________________________________\\n\")\n",
    "\n",
    "\n",
    "    ################################################################\n",
    "    # 클래스별 IoU를 누적할 리스트 초기화\n",
    "    val_class_ious = []\n",
    "    fish_val_class_ious = []\n",
    "    val_epoch_loss = 0\n",
    "    val_seg_loss = 0\n",
    "    val_domain_loss = 0\n",
    "    # 학습\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        for target_images, target_masks in tqdm(val_target_dataloader):\n",
    "            label = 2.5\n",
    "            target_images, target_masks = apply_fisheye_distortion(target_images, target_masks, label)\n",
    "            target_images = target_images.float().to(device)\n",
    "            target_masks = target_masks.long().to(device)\n",
    "\n",
    "            target_outputs = model(target_images)\n",
    "\n",
    "            target_loss, target_seg_loss, target_domain_loss = loss_fn(target_outputs, target_masks, 0, alpha = ALPHA)\n",
    "\n",
    "            val_seg_loss +=  target_seg_loss.item()\n",
    "            val_domain_loss += target_domain_loss.item()\n",
    "            \n",
    "            loss = target_loss\n",
    "\n",
    "            val_epoch_loss += loss.item()\n",
    "\n",
    "            # train 클래스별 IoU 계산\n",
    "            target_outputs = torch.softmax(target_outputs[0], dim=1).cpu()\n",
    "            target_outputs = torch.argmax(target_outputs, dim=1).numpy()\n",
    "\n",
    "            for class_id in range(N_CLASSES):\n",
    "                iou = calculate_iou_per_class(np.array(target_masks.cpu()), np.array(target_outputs), class_id)\n",
    "                fish_val_class_ious.append(iou)\n",
    "\n",
    "    fish_val_class_ious = np.array(fish_val_class_ious).reshape(N_CLASSES, -1)\n",
    "    fish_val_class_ious = np.mean(fish_val_class_ious, axis=1)\n",
    "    print()\n",
    "    print(\"--IoU Scores Fish val--\")\n",
    "    for class_id, iou in enumerate(fish_val_class_ious):\n",
    "        print(f'Class{class_id}: {iou:.4f}', end=\" \")\n",
    "        if (class_id+1) % 7 == 0:\n",
    "            print()\n",
    "\n",
    "    # mIoU 계산\n",
    "    fish_val_mIoU = np.mean(fish_val_class_ious)\n",
    "\n",
    "    # 에폭마다 결과 출력 \n",
    "    print(f\"\\nEpoch{epoch+1}\")\n",
    "    print(f\"Valid_Seg Loss: {(val_seg_loss/len(val_target_dataloader))}\",f\"Valid_dom Loss: {(val_domain_loss/len(val_target_dataloader))}\")\n",
    "    print(f\"Valid Loss: {(val_epoch_loss/len(val_target_dataloader))}\")\n",
    "    print(f\"Valid mIoU: {fish_val_mIoU}\" )\n",
    "    print(\"___________________________________________________________________________________________\\n\")\n",
    "\n",
    "#     # log metrics to wandb\n",
    "#     wandb.log({\"train score\": train_mIoU})\n",
    "#     wandb.log({\"val score\": fish_val_mIoU})\n",
    "#     wandb.log({\"train loss\": (epoch_loss/len(source_dataloader))})\n",
    "#     wandb.log({\"val loss\": (val_epoch_loss/len(val_target_dataloader))})\n",
    "    \n",
    "    \n",
    "# # [optional] finish the wandb run, necessary in notebooks\n",
    "# wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './data/resnet34.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byungwan_resn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
