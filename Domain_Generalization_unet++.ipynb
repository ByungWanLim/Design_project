{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/MMI24limbyungwan/.conda/envs/byungwan_resn/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "#from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# GPU 사용이 가능할 경우, GPU를 사용할 수 있게 함.'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "print(device)\n",
    "\n",
    "print(os.environ.get('CUDA_VISIBLE_DEVICES'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "# 클래스별 IoU를 계산하기 위한 함수\n",
    "def calculate_iou_per_class(y_true, y_pred, class_id):\n",
    "    intersection = np.sum((y_true == class_id) & (y_pred == class_id))\n",
    "    union = np.sum((y_true == class_id) | (y_pred == class_id))\n",
    "    iou = intersection / union if union > 0 else 0\n",
    "    return iou\n",
    "\n",
    "def calculate_ious(y_true, y_pred, class_num):\n",
    "    ious = []\n",
    "    for class_id in range(class_num):\n",
    "        intersection = np.sum((y_true == class_id) & (y_pred == class_id))\n",
    "        union = np.sum((y_true == class_id) | (y_pred == class_id))\n",
    "        iou = intersection / union if union > 0 else 0\n",
    "        ious.append(iou)\n",
    "    return ious\n",
    "\n",
    "def apply_fisheye_distortion(images, masks, label):\n",
    "    # 이미지 크기 가져오기\n",
    "    batch, channel, height, width = images.shape\n",
    "\n",
    "    # 카메라 매트릭스 생성\n",
    "    focal_length = width / 4\n",
    "    center_x = width / 2\n",
    "    center_y = height / 2\n",
    "    camera_matrix = np.array([[focal_length, 0, center_x],\n",
    "                              [0, focal_length, center_y],\n",
    "                              [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "    # 왜곡 계수 생성\n",
    "    dist_coeffs = np.array([0, 0.02 * label, 0, 0], dtype=np.float32)\n",
    "\n",
    "    # 왜곡 보정\n",
    "    undistorted_images = []\n",
    "    undistorted_masks = []\n",
    "\n",
    "    for i in range(batch):\n",
    "        image = images[i].permute(1, 2, 0).cpu().numpy()  # 텐서를 NumPy 배열로 변환\n",
    "        mask = masks[i].cpu().numpy()\n",
    "        undistorted_image = cv2.undistort(image, camera_matrix, dist_coeffs)\n",
    "        undistorted_mask = cv2.undistort(mask, camera_matrix, dist_coeffs)\n",
    "        undistorted_mask = np.round(undistorted_mask).astype(np.uint8)\n",
    "        undistorted_mask[undistorted_mask > 12] = 12\n",
    "\n",
    "        # 다시 텐서로 변환\n",
    "        undistorted_image = torch.from_numpy(undistorted_image).permute(2, 0, 1).float().to(device)\n",
    "        undistorted_mask = torch.from_numpy(undistorted_mask).long().to(device)\n",
    "\n",
    "        undistorted_images.append(undistorted_image)\n",
    "        undistorted_masks.append(undistorted_mask)\n",
    "\n",
    "    undistorted_images = torch.stack(undistorted_images, dim=0)\n",
    "    undistorted_masks = torch.stack(undistorted_masks, dim=0)\n",
    "\n",
    "    return undistorted_images, undistorted_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False, CL=0):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "        self.CL = CL\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #directory_path = \"/mnt/nas27/Dataset/Samsung_DM\"\n",
    "        directory_path = './data/224'\n",
    "        img_path = self.data.iloc[idx, 1]\n",
    "        img_path = os.path.join(directory_path, img_path)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "        \n",
    "        mask_path = self.data.iloc[idx, 2]\n",
    "        mask_path = os.path.join(directory_path, mask_path)\n",
    "        mask = cv2.imread(mask_path)\n",
    "        #mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        if self.CL == 0:\n",
    "            mask = np.round(mask).astype(np.uint8)\n",
    "            mask[mask > 12] = 12 #배경을 픽셀값 12로 간주\n",
    "            mask += 1\n",
    "            mask[mask == 13] = 0\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask\n",
    "     \n",
    "\n",
    "transform = A.Compose(\n",
    "    [   \n",
    "        #A.Resize(224, 224),\n",
    "        #A.Resize(128, 128),\n",
    "        #A.Normalize(),\n",
    "        A.GaussNoise(var_limit=(10.0, 30.0), p=0.3),\n",
    "        \n",
    "        # 변형\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        # A.RandomRotate90(p=0.5),\n",
    "        # A.HueSaturationValue(p=0.2),\n",
    "        A.ColorJitter(brightness=0.7, contrast=0.7, saturation=0.7),\n",
    "        \n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "\n",
    "totensor = A.Compose(\n",
    "    [   \n",
    "        #A.Resize(224, 224),\n",
    "        #A.Resize(128, 128),\n",
    "        #A.Normalize(),\n",
    "        #A.GaussNoise(var_limit=(10.0, 30.0), p=0.3),\n",
    "        \n",
    "        # 변형\n",
    "        #A.HorizontalFlip(p=0.5),\n",
    "        # A.RandomRotate90(p=0.5),\n",
    "        # A.HueSaturationValue(p=0.2),\n",
    "        #A.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "        \n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from init_weights import init_weights\n",
    "\n",
    "class GradReverse(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(self, x):\n",
    "        return x.view_as(x)\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output): # 역전파 시에 gradient에 음수를 취함\n",
    "        return grad_output * (-1)\n",
    "\n",
    "class domain_classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(domain_classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(224*224*64, 50)\n",
    "        self.dropout = nn.Dropout2d(0.5) #\n",
    "        self.fc2 = nn.Linear(50, 4) # source = 0, target = 1 회귀 가정\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 224*224*64)\n",
    "        x = self.dropout(x)\n",
    "        x = GradReverse.apply(x) # gradient reverse\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        #return torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Unet_block(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(mid_channels)\n",
    "        self.conv2 = nn.Conv2d(mid_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Nested_UNet(nn.Module):\n",
    "    def __init__(self, num_classes, input_channels=3, deep_supervision=False):\n",
    "        super().__init__()\n",
    "\n",
    "        num_filter = [32, 64, 128, 256, 512]\n",
    "        self.deep_supervision = deep_supervision\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        # DownSampling\n",
    "        self.conv0_0 = Unet_block(input_channels, num_filter[0], num_filter[0])\n",
    "        self.conv1_0 = Unet_block(num_filter[0], num_filter[1], num_filter[1])\n",
    "        self.conv2_0 = Unet_block(num_filter[1], num_filter[2], num_filter[2])\n",
    "        self.conv3_0 = Unet_block(num_filter[2], num_filter[3], num_filter[3])\n",
    "        self.conv4_0 = Unet_block(num_filter[3], num_filter[4], num_filter[4])\n",
    "\n",
    "        # Upsampling & Dense skip\n",
    "        # N to 1 skip\n",
    "        self.conv0_1 = Unet_block(num_filter[0] + num_filter[1], num_filter[0], num_filter[0])\n",
    "        self.conv1_1 = Unet_block(num_filter[1] + num_filter[2], num_filter[1], num_filter[1])\n",
    "        self.conv2_1 = Unet_block(num_filter[2] + num_filter[3], num_filter[2], num_filter[2])\n",
    "        self.conv3_1 = Unet_block(num_filter[3] + num_filter[4], num_filter[3], num_filter[3])\n",
    "       \n",
    "        # N to 2 skip\n",
    "        self.conv0_2 = Unet_block(num_filter[0]*2 + num_filter[1], num_filter[0], num_filter[0])\n",
    "        self.conv1_2 = Unet_block(num_filter[1]*2 + num_filter[2], num_filter[1], num_filter[1])\n",
    "        self.conv2_2 = Unet_block(num_filter[2]*2 + num_filter[3], num_filter[2], num_filter[2])\n",
    "\n",
    "        # N to 3 skip\n",
    "        self.conv0_3 = Unet_block(num_filter[0]*3 + num_filter[1], num_filter[0], num_filter[0])\n",
    "        self.conv1_3 = Unet_block(num_filter[1]*3 + num_filter[2], num_filter[1], num_filter[1])\n",
    "\n",
    "        # N to 4 skip\n",
    "        self.conv0_4 = Unet_block(num_filter[0]*4 + num_filter[1], num_filter[0], num_filter[0])\n",
    "\n",
    "        self.domain_classifier = domain_classifier()\n",
    "        \n",
    "        if self.deep_supervision:\n",
    "            self.output1 = nn.Conv2d(num_filter[0], num_classes, kernel_size=1)\n",
    "            self.output2 = nn.Conv2d(num_filter[0], num_classes, kernel_size=1)\n",
    "            self.output3 = nn.Conv2d(num_filter[0], num_classes, kernel_size=1)\n",
    "            self.output4 = nn.Conv2d(num_filter[0], num_classes, kernel_size=1)\n",
    "\n",
    "        else:\n",
    "            self.output = nn.Conv2d(num_filter[0], num_classes, kernel_size=1)\n",
    "\n",
    "        # initialise weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init_weights(m, init_type='kaiming')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init_weights(m, init_type='kaiming')\n",
    "\n",
    "    def forward(self, x):                    # (Batch, 3, 256, 256)\n",
    "\n",
    "        x0_0 = self.conv0_0(x)               \n",
    "        x1_0 = self.conv1_0(self.pool(x0_0))\n",
    "        x0_1 = self.conv0_1(torch.cat([x0_0, self.up(x1_0)], dim=1))\n",
    "        \n",
    "        x2_0 = self.conv2_0(self.pool(x1_0))\n",
    "        x1_1 = self.conv1_1(torch.cat([x1_0, self.up(x2_0)], dim=1))\n",
    "        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.up(x1_1)], dim=1))\n",
    "\n",
    "        x3_0 = self.conv3_0(self.pool(x2_0))\n",
    "        x2_1 = self.conv2_1(torch.cat([x2_0, self.up(x3_0)], dim=1))\n",
    "        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.up(x2_1)], dim=1))\n",
    "        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.up(x1_2)], dim=1))\n",
    "\n",
    "        x4_0 = self.conv4_0(self.pool(x3_0))\n",
    "        x3_1 = self.conv3_1(torch.cat([x3_0, self.up(x4_0)], dim=1))\n",
    "        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.up(x3_1)], dim=1))\n",
    "        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.up(x2_2)], dim=1))\n",
    "        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.up(x1_3)], dim=1))\n",
    "\n",
    "        if self.deep_supervision:\n",
    "            output1 = self.output1(x0_1)\n",
    "            output2 = self.output2(x0_2)\n",
    "            output3 = self.output3(x0_3)\n",
    "            output4 = self.output4(x0_4)\n",
    "            output = (output1 + output2 + output3 + output4) / 4\n",
    "            x_d = self.domain_classifier(x0_4)\n",
    "        else:\n",
    "            output = self.output(x0_4)\n",
    "            x_d = self.domain_classifier(x0_4)\n",
    "\n",
    "        return output, x_d\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function과 optimizer 정의\n",
    "class DANN_Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DANN_Loss, self).__init__()\n",
    "        self.CE = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, result, label, domain_num, alpha=1):\n",
    "        label_logits, domain_logits = result\n",
    "\n",
    "        batch_size = domain_logits.shape[0]\n",
    "\n",
    "        segment_loss = self.CE(label_logits, label)\n",
    "        \n",
    "        domain_target = torch.LongTensor([domain_num] * batch_size).to(device)\n",
    "        domain_loss = self.CE(domain_logits, domain_target)\n",
    "        \n",
    "        loss = segment_loss + alpha * domain_loss\n",
    "\n",
    "        return loss, segment_loss, domain_loss\n",
    "    \n",
    "    \n",
    "\n",
    "class DANN_Loss_mse(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DANN_Loss_mse, self).__init__()\n",
    "        self.CE = nn.CrossEntropyLoss()\n",
    "        self.MSE = nn.MSELoss()\n",
    "\n",
    "    def forward(self, result, label, domain_num, alpha = 1):\n",
    "        label_logits, domain_logits = result # DANN_CNN의 결과\n",
    "\n",
    "        batch_size = domain_logits.shape[0]\n",
    "\n",
    "        segment_loss = self.CE(label_logits, label) # class 분류 loss\n",
    "        \n",
    "        domain_target = torch.LongTensor([domain_num] * batch_size).unsqueeze(1).to(device).float()      \n",
    "        domain_loss = self.MSE(domain_logits, domain_target) # domain 분류 loss\n",
    "        domain_loss = torch.sqrt(domain_loss)\n",
    "        loss = segment_loss + alpha * domain_loss\n",
    "        # print(\"segment_mask : \", label.shape)\n",
    "        # print(\"domain_answer : \", domain_target.shape)\n",
    "        return loss ,segment_loss, domain_loss\n",
    "\n",
    "\n",
    "loss_fn = DANN_Loss().to(device)\n",
    "#loss_fn = DANN_Loss_mse().to(device)\n",
    "\n",
    "#criterion =nn.CrossEntropyLoss()\n",
    "#domain_criterion = nn.BCELoss()\n",
    "#criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters , Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.0001\n",
    "EP = 30\n",
    "BATCH_SIZE = 16\n",
    "ACCMULATION_STEP = 1 \n",
    "N_CLASSES = 13\n",
    "alpha = 0.01\n",
    "N_LABELS = 4\n",
    "# model 초기화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 파라미터 수: 214684945\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#모델 선언\n",
    "model = Nested_UNet(num_classes = N_CLASSES,input_channels=3, deep_supervision=False).to(device)\n",
    "#model.load_state_dict(torch.load('./data/resnet34_1118_1.pth'), strict=False)\n",
    "#옵티마이저 설정\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "optimizer.zero_grad() \n",
    "#데이터 로더\n",
    "source_dataset = CustomDataset(csv_file='./data/896_csv/train_source.csv', transform=transform)\n",
    "source_dataloader = DataLoader(source_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "#소스변형\n",
    "val_source_dataset = CustomDataset(csv_file=\"./data/896_csv/val_source.csv\", transform=transform)\n",
    "val_source_dataloader = DataLoader(val_source_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "#실제 타겟\n",
    "val_target_dataset = CustomDataset(csv_file=\"./data/896_csv/val_source_CL.csv\", transform=transform)\n",
    "val_target_dataloader = DataLoader(val_target_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "# 모델의 파라미터 수 계산\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"총 파라미터 수: {total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "miou test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1:   0%|          | 0/138 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1:   0%|          | 0/138 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Generalization_unet++.ipynb 셀 16\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhome/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Generalization_unet%2B%2B.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m source_outputs \u001b[39m=\u001b[39m model(source_image)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhome/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Generalization_unet%2B%2B.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m source_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msoftmax(source_outputs[\u001b[39m0\u001b[39m], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcpu()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bhome/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Generalization_unet%2B%2B.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m source_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49margmax(source_outputs, dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhome/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Generalization_unet%2B%2B.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mfor\u001b[39;00m class_id \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N_CLASSES):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhome/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Generalization_unet%2B%2B.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     iou \u001b[39m=\u001b[39m calculate_iou_per_class(np\u001b[39m.\u001b[39marray(source_mask\u001b[39m.\u001b[39mcpu()), np\u001b[39m.\u001b[39marray(source_outputs), class_id)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EP):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    seg_losses = 0\n",
    "    domain_losses = 0\n",
    "    #alpha = 0.0045\n",
    "    train_class_ious = [[],[],[],[]]\n",
    "    \n",
    "    # label_dfs = {label: None for label in range(N_LABELS)}\n",
    "    # print(alpha)\n",
    "    for source_images, source_masks in tqdm(source_dataloader,desc=f\"Epoch: {epoch+1}\"):\n",
    "        for label in range(N_LABELS): \n",
    "            source_image, source_mask = apply_fisheye_distortion(source_images, source_masks, label)\n",
    "            source_image = source_image.float().to(device)\n",
    "            source_mask = source_mask.long().to(device)\n",
    "            source_outputs = model(source_image)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            target_loss, seg_loss, domain_loss = loss_fn(source_outputs, source_mask, label, alpha = alpha)\n",
    "            epoch_loss += target_loss.item()\n",
    "            seg_losses +=  seg_loss.item()\n",
    "            domain_losses += domain_loss.item()\n",
    "            target_loss.backward()\n",
    "            optimizer.step()\n",
    "            # miou측정\n",
    "            source_outputs = model(source_image)\n",
    "            source_outputs = torch.softmax(source_outputs[0], dim=1).cpu()\n",
    "            source_outputs = torch.argmax(source_outputs, dim=1).numpy()\n",
    "            \n",
    "            for class_id in range(N_CLASSES):\n",
    "                iou = calculate_iou_per_class(np.array(source_mask.cpu()), np.array(source_outputs), class_id)\n",
    "                train_class_ious[label].append(iou)\n",
    "            \n",
    "    for i in range(N_LABELS):\n",
    "        buff = np.array(train_class_ious[i]).reshape(-1,N_CLASSES)\n",
    "        buff = np.mean(buff, axis=0)\n",
    "        print(f\"\\nLabel_{i}: IoU Scores Train\")\n",
    "        for class_id, iou in enumerate(buff):\n",
    "            print(f'Class{class_id:02d}: {iou:.4f}', end=\" \")\n",
    "            if (class_id+1) % 7 == 0:\n",
    "                print()   \n",
    "    print()    \n",
    "    print(f\"Train seg Loss: {(seg_losses/(N_LABELS*len(source_dataloader)))}\",f\"Train dom Loss: {(domain_losses/(N_LABELS*len(source_dataloader)))}\")\n",
    "    print(f\"Train Loss: {(epoch_loss/(N_LABELS*len(source_dataloader)))}\")\n",
    "    print(f\"Train mIoU: {np.mean(train_class_ious)}\" )\n",
    "    ################################################################\n",
    "    # 클래스별 IoU를 누적할 리스트 초기화\n",
    "    val_class_ious = []\n",
    "    fish_val_class_ious = []\n",
    "    val_epoch_loss = 0\n",
    "    val_seg_loss = 0\n",
    "    val_domain_loss = 0\n",
    "    # valid\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for target_images, target_masks in tqdm(val_source_dataloader):\n",
    "            label = 2.5\n",
    "            target_images, target_masks = apply_fisheye_distortion(target_images, target_masks, label)\n",
    "            target_images = target_images.float().to(device)\n",
    "            target_masks = target_masks.long().to(device)\n",
    "\n",
    "            target_outputs = model(target_images)\n",
    "\n",
    "            target_loss, target_seg_loss, target_domain_loss = loss_fn(target_outputs, target_masks, label, alpha = alpha)\n",
    "\n",
    "            val_seg_loss +=  target_seg_loss.item()\n",
    "            val_domain_loss += target_domain_loss.item()\n",
    "            \n",
    "            loss = target_loss\n",
    "\n",
    "            val_epoch_loss += loss.item()\n",
    "\n",
    "            # train 클래스별 IoU 계산\n",
    "            target_outputs = torch.softmax(target_outputs[0], dim=1).cpu()\n",
    "            target_outputs = torch.argmax(target_outputs, dim=1).numpy()\n",
    "\n",
    "            for class_id in range(N_CLASSES):\n",
    "                iou = calculate_iou_per_class(np.array(target_masks.cpu()), np.array(target_outputs), class_id)\n",
    "                fish_val_class_ious.append(iou)\n",
    "\n",
    "    fish_val_class_ious = np.array(fish_val_class_ious).reshape(-1,N_CLASSES)\n",
    "    fish_val_class_ious = np.mean(fish_val_class_ious, axis=0)\n",
    "    print()\n",
    "    print(\"--IoU Scores Source val--\")\n",
    "    for class_id, iou in enumerate(fish_val_class_ious):\n",
    "        print(f'Class{class_id}: {iou:.4f}', end=\" \")\n",
    "        if (class_id+1) % 7 == 0:\n",
    "            print()\n",
    "\n",
    "    # mIoU 계산\n",
    "    fish_val_mIoU = np.mean(fish_val_class_ious)\n",
    "\n",
    "    # 에폭마다 결과 출력 \n",
    "    print(f\"\\nEpoch{epoch+1}\")\n",
    "    print(f\"Valid_Seg Loss: {(val_seg_loss/len(val_source_dataloader))}\",f\"Valid_dom Loss: {(val_domain_loss/len(val_source_dataloader))}\")\n",
    "    print(f\"Valid Source Loss: {(val_epoch_loss/len(val_source_dataloader))}\")\n",
    "    print(f\"Valid Source mIoU: {fish_val_mIoU}\" )\n",
    "    print(\"___________________________________________________________________________________________\\n\")\n",
    "    val_class_ious = []\n",
    "    fish_val_class_ious = []\n",
    "    val_epoch_loss = 0\n",
    "    val_seg_loss = 0\n",
    "    val_domain_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for target_images, target_masks in tqdm(val_target_dataloader):\n",
    "            label = 2.5\n",
    "            #target_images, target_masks = apply_fisheye_distortion(target_images, target_masks, label)\n",
    "            target_images = target_images.float().to(device)\n",
    "            target_masks = target_masks.long().to(device)\n",
    "\n",
    "            target_outputs = model(target_images)\n",
    "\n",
    "            target_loss, target_seg_loss, target_domain_loss = loss_fn(target_outputs, target_masks, label, alpha = alpha)\n",
    "\n",
    "            val_seg_loss +=  target_seg_loss.item()\n",
    "            val_domain_loss += target_domain_loss.item()\n",
    "            \n",
    "            loss = target_loss\n",
    "\n",
    "            val_epoch_loss += loss.item()\n",
    "\n",
    "            # train 클래스별 IoU 계산\n",
    "            target_outputs = torch.softmax(target_outputs[0], dim=1).cpu()\n",
    "            target_outputs = torch.argmax(target_outputs, dim=1).numpy()\n",
    "\n",
    "            for class_id in range(N_CLASSES):\n",
    "                iou = calculate_iou_per_class(np.array(target_masks.cpu()), np.array(target_outputs), class_id)\n",
    "                fish_val_class_ious.append(iou)\n",
    "\n",
    "    fish_val_class_ious = np.array(fish_val_class_ious).reshape(-1,N_CLASSES)\n",
    "    fish_val_class_ious = np.mean(fish_val_class_ious, axis=0)\n",
    "    print()\n",
    "    print(\"--IoU Scores Target val--\")\n",
    "    for class_id, iou in enumerate(fish_val_class_ious):\n",
    "        print(f'Class{class_id}: {iou:.4f}', end=\" \")\n",
    "        if (class_id+1) % 7 == 0:\n",
    "            print()\n",
    "\n",
    "    # mIoU 계산\n",
    "    fish_val_mIoU = np.mean(fish_val_class_ious)\n",
    "\n",
    "    # 에폭마다 결과 출력 \n",
    "    print(f\"\\nEpoch{epoch+1}\")\n",
    "    print(f\"Valid_Seg Loss: {(val_seg_loss/len(val_target_dataloader))}\",f\"Valid_dom Loss: {(val_domain_loss/len(val_target_dataloader))}\")\n",
    "    print(f\"Valid Target Loss: {(val_epoch_loss/len(val_target_dataloader))}\")\n",
    "    print(f\"Valid Target mIoU: {fish_val_mIoU}\" )\n",
    "    print(\"___________________________________________________________________________________________\\n\")\n",
    "\n",
    "print(\"Hyperparamerters\")\n",
    "print(f\"LR = {LR} | EP = {EP}, BATCH_SIZE = {BATCH_SIZE}, N_CLASSES = {N_CLASSES}, init_alpha = {alpha}, N_LABELS = {N_LABELS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './data/unet++_1121_1.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byungwan_resn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
