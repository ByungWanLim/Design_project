{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d73d24e3-5c9e-4ade-9e6e-ca6f46a2d914",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad9b681e-370a-4cfa-a452-dd2d7f0cd77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/MMI24leehyunwook/.conda/envs/net_bw/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torchvision import models\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51fb2d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# GPU 사용이 가능할 경우, GPU를 사용할 수 있게 함.'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "print(device)\n",
    "\n",
    "print(os.environ.get('CUDA_VISIBLE_DEVICES'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20ff3de5-0d0e-497b-ac75-d5179a3f65d3",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "838e1d83-8670-407b-82f6-bf9652f58639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be76a29e-e9c2-411a-a569-04166f074184",
   "metadata": {},
   "source": [
    "## Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8496767-2f64-4285-bec4-c6f53a1fd9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        directory_path = \"/mnt/nas27/Dataset/Samsung_DM\"\n",
    "        img_path = self.data.iloc[idx, 1]\n",
    "        img_path = os.path.join(directory_path, img_path[2:])\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "        \n",
    "        mask_path = self.data.iloc[idx, 2]\n",
    "        mask_path = os.path.join(directory_path, mask_path[2:])\n",
    "        mask = cv2.imread(mask_path)\n",
    "        #mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        mask[mask == 255] = 12 #배경을 픽셀값 12로 간주\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc955893-22fd-4320-88be-7aa0d790cbd9",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65dabc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 전처리 클래스\n",
    "class ImageTransform():\n",
    "  \"\"\"\n",
    "  훈련, 검증 동작 다르게 설정\n",
    "  이미지 크기 resize, 색상 표준화\n",
    "  훈련시 RandomResizedCrop, RandomHorizontalFilp으로 데이터 확장\n",
    "  \"\"\"\n",
    "  def __init__(self, resize, mean, std):\n",
    "    self.data_transform = {\n",
    "        'train' : transforms.Compose([\n",
    "            #transforms.RandomResizedCrop(\n",
    "            #    resize, scale = (0.5, 1.0)), # 데이터 확장\n",
    "            transforms.RandomHorizontalFlip(), # 데이터 확장\n",
    "            transforms.ToTensor(), # Tensor로 변환\n",
    "            transforms.Normalize(mean = mean, std = std) #표준화\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            #transforms.Resize(resize), # Resize\n",
    "            #transforms.CenterCrop(resize), # 중앙을 resize*resize로 crop\n",
    "            transforms.ToTensor(), # Tensor로 변환\n",
    "            transforms.Normalize(mean = mean, std = std) # 표준화\n",
    "        ])\n",
    "\n",
    "    }\n",
    "  def __call__(self, img, phase = 'train'):\n",
    "    \"\"\"\n",
    "    phase : 'train' or 'test'\n",
    "    전처리 모드 지정\n",
    "    \"\"\"\n",
    "    return self.data_transform[phase](img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b708503-2ff9-4584-9d73-40990b3572f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose(\n",
    "    [   \n",
    "        #A.Resize(224, 224),\n",
    "        A.Resize(256, 256),\n",
    "        A.Normalize(),\n",
    "        \n",
    "        # 변형\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        # A.RandomRotate90(p=0.5),\n",
    "        A.HueSaturationValue(p=0.2),\n",
    "        \n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1096fe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스별 IoU를 계산하기 위한 함수\n",
    "def calculate_iou_per_class(y_true, y_pred, class_id):\n",
    "    intersection = np.sum((y_true == class_id) & (y_pred == class_id))\n",
    "    union = np.sum((y_true == class_id) | (y_pred == class_id))\n",
    "    iou = intersection / union if union > 0 else 0\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a91d6b1",
   "metadata": {},
   "source": [
    "Warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9e62c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmUpLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, total_iters, last_epoch=-1):\n",
    "        self.total_iters = total_iters\n",
    "        super(WarmUpLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [base_lr * self.last_epoch / self.total_iters for base_lr in self.base_lrs]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f42501fc-b573-4893-a7c4-5e280dfdaf09",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65960bfb-803a-4c40-b713-6f647779e4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channel, mid_channel, out_channel):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channel, mid_channel, kernel_size=3, stride=1, padding=1) #keep ratio\n",
    "        self.conv_trans = nn.ConvTranspose2d(mid_channel, out_channel, kernel_size=4, stride=2, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv(x), inplace=True)\n",
    "        x = F.relu(self.conv_trans(x), inplace=True)\n",
    "        return x\n",
    "    \n",
    "class Unet_resnet18(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(Unet_resnet18, self).__init__()\n",
    "        \n",
    "        #encoder\n",
    "        self.encoder = models.resnet18(pretrained=False)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv1 = nn.Sequential(self.encoder.conv1, self.encoder.bn1,\n",
    "                                  self.encoder.relu, self.pool) #64\n",
    "        self.conv2 = self.encoder.layer1 #64\n",
    "        self.conv3 = self.encoder.layer2 #128\n",
    "        self.conv4 = self.encoder.layer3 #256\n",
    "        self.conv5 = self.encoder.layer4 #depth 512\n",
    "        \n",
    "        #center\n",
    "        self.center = Decoder(512, 312, 256)\n",
    "        \n",
    "        #decoder\n",
    "        self.decoder5 = Decoder(256+512, 256, 256)\n",
    "        self.decoder4 = Decoder(256+256, 128, 128)\n",
    "        self.decoder3 = Decoder(128+128, 64, 64)\n",
    "        self.decoder2 = Decoder(64+64, 32, 32)\n",
    "        self.decoder1 = Decoder(32, 16, 16)\n",
    "        self.decoder0 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "    \n",
    "        self.final = nn.Conv2d(8, n_classes, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #encoder\n",
    "        conv1 = self.conv1(x) #64x64\n",
    "        conv2 = self.conv2(conv1) #32x32\n",
    "        conv3 = self.conv3(conv2) #16x16\n",
    "        conv4 = self.conv4(conv3) #8x8\n",
    "        conv5 = self.conv5(conv4) #4x4\n",
    "        \n",
    "        center = self.center(self.pool(conv5)) #4x4\n",
    "        #decoder\n",
    "        dec5 = self.decoder5(torch.cat([center, conv5], 1)) #8x8\n",
    "        dec4 = self.decoder4(torch.cat([dec5, conv4], 1)) #16x16\n",
    "        dec3 = self.decoder3(torch.cat([dec4, conv3], 1)) #32x32\n",
    "        dec2 = self.decoder2(torch.cat([dec3, conv2], 1)) #64x64\n",
    "        dec1 = self.decoder1(dec2) #128x128\n",
    "        dec0 = F.relu(self.decoder0(dec1))\n",
    "        \n",
    "        final = torch.sigmoid(self.final(dec0))\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baf22f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channel, mid_channel, out_channel):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channel, mid_channel, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_trans = nn.ConvTranspose2d(mid_channel, out_channel, kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv(x), inplace=True)\n",
    "        x = F.relu(self.conv_trans(x), inplace=True)\n",
    "        return x\n",
    "\n",
    "class Unet_resnet50(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(Unet_resnet50, self).__init__()\n",
    "\n",
    "        # Encoder (ResNet-50)\n",
    "        self.encoder = models.resnet50(pretrained=True)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv1 = nn.Sequential(self.encoder.conv1, self.encoder.bn1, self.encoder.relu, self.pool)\n",
    "        self.conv2 = self.encoder.layer1\n",
    "        self.conv3 = self.encoder.layer2\n",
    "        self.conv4 = self.encoder.layer3\n",
    "        self.conv5 = self.encoder.layer4\n",
    "\n",
    "        # Center\n",
    "        self.center = Decoder(2048, 1024, 512)  # Adjusted for ResNet-50\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder5 = Decoder(512 + 2048, 1024, 512)  # Adjusted for ResNet-50\n",
    "        self.decoder4 = Decoder(512 + 1024, 512, 256)  # Adjusted for ResNet-50\n",
    "        self.decoder3 = Decoder(256 + 512, 256, 128)   # Adjusted for ResNet-50\n",
    "        self.decoder2 = Decoder(128 + 256, 128, 64)    # Adjusted for ResNet-50\n",
    "        self.decoder1 = Decoder(64, 32, 32)\n",
    "        self.decoder0 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.final = nn.Conv2d(16, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        conv1 = self.conv1(x)\n",
    "        conv2 = self.conv2(conv1)\n",
    "        conv3 = self.conv3(conv2)\n",
    "        conv4 = self.conv4(conv3)\n",
    "        conv5 = self.conv5(conv4)\n",
    "\n",
    "        center = self.center(self.pool(conv5))\n",
    "\n",
    "        # Decoder\n",
    "        dec5 = self.decoder5(torch.cat([center, conv5], 1))\n",
    "        dec4 = self.decoder4(torch.cat([dec5, conv4], 1))\n",
    "        dec3 = self.decoder3(torch.cat([dec4, conv3], 1))\n",
    "        dec2 = self.decoder2(torch.cat([dec3, conv2], 1))\n",
    "        dec1 = self.decoder1(dec2)\n",
    "        dec0 = F.relu(self.decoder0(dec1))\n",
    "\n",
    "        final = torch.sigmoid(self.final(dec0))\n",
    "\n",
    "        return final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd34483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.0001\n",
    "EP = 5\n",
    "BATCH_SIZE = 152\n",
    "N_CLASSES = 13 #IoU 점수측정하기 위한 클래스의 개수\n",
    "WUP_ITERS = 100  # 웜업을 위한 반복 횟수\n",
    "# model 초기화\n",
    "model = Unet_resnet18(n_classes = N_CLASSES).to(device)\n",
    "#model = Unet_resnet50(n_classes = 13).to(device)\n",
    "\n",
    "# loss function과 optimizer 정의\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# Warmup을 위한 스케줄러 설정\n",
    "\n",
    "scheduler_warmup = WarmUpLR(optimizer, WUP_ITERS)\n",
    "\n",
    "dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./train_source.csv'), transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "valid_dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./val_source.csv'), transform=transform)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0895765-fba0-4fd9-b955-a6c0e43012e9",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dec3e516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:23<00:00,  5.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores--\n",
      "Class0: 0.0001 Class1: 0.0001 Class2: 0.0001 Class3: 0.0001 Class4: 0.0001 Class5: 0.0001 Class6: 0.0001 Class6: 0.0001 Class7: 0.0000 Class7: 0.0000 Class8: 0.0001 Class8: 0.0001 Class9: 0.0001 Class9: 0.0001 Class10: 0.0001 Class10: 0.0001 Class11: 0.0001 Class11: 0.0001 Class12: 0.0001 Class12: 0.0001 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:22<00:00,  5.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores--\n",
      "Class0: 0.0000 \n",
      "\n",
      "Class1: 0.0000 Class2: 0.0001 Class3: 0.0000 \n",
      "\n",
      "Class4: 0.0000 Class5: 0.0000 Class6: 0.0000 \n",
      "\n",
      "Class7: 0.0000 Class8: 0.0000 Class9: 0.0000 \n",
      "\n",
      "Class10: 0.0000 Class11: 0.0000 Class12: 0.0000 \n",
      "\n",
      "\n",
      "Epoch1\n",
      "Train Loss: 2.5395344734191894, Train mIoU Score: 0.0001\n",
      "Validation Loss: 2.5338985323905945, Validation mIoU Score: 0.0000\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:23<00:00,  5.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores--\n",
      "Class0: 0.0001 Class1: 0.0001 Class2: 0.0001 Class3: 0.0000 Class4: 0.0001 Class5: 0.0001 Class6: 0.0001 Class6: 0.0001 Class7: 0.0001 Class7: 0.0001 Class8: 0.0003 Class8: 0.0003 Class9: 0.0003 Class9: 0.0003 Class10: 0.0003 Class10: 0.0003 Class11: 0.0006 Class11: 0.0006 Class12: 0.0009 Class12: 0.0009 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:23<00:00,  5.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores--\n",
      "Class0: 0.0063 \n",
      "\n",
      "Class1: 0.0000 Class2: 0.0001 Class3: 0.0072 \n",
      "\n",
      "Class4: 0.0000 Class5: 0.0001 Class6: 0.0058 \n",
      "\n",
      "Class7: 0.0000 Class8: 0.0001 Class9: 0.0110 \n",
      "\n",
      "Class10: 0.0000 Class11: 0.0000 Class12: 0.0000 \n",
      "\n",
      "\n",
      "Epoch2\n",
      "Train Loss: 2.5388036886850993, Train mIoU Score: 0.0002\n",
      "Validation Loss: 2.5326600670814514, Validation mIoU Score: 0.0024\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:22<00:00,  5.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores--\n",
      "Class0: 0.0030 Class1: 0.0030 Class2: 0.0054 Class3: 0.0082 Class4: 0.0208 Class5: 0.0146 Class6: 0.0226 Class6: 0.0226 Class7: 0.0212 Class7: 0.0212 Class8: 0.0254 Class8: 0.0254 Class9: 0.0284 Class9: 0.0284 Class10: 0.0333 Class10: 0.0333 Class11: 0.0191 Class11: 0.0191 Class12: 0.0187 Class12: 0.0187 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/MMI24leehyunwook/Design_project/U-net_Resnet_LBW.ipynb 셀 19\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24leehyunwook/Design_project/U-net_Resnet_LBW.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24leehyunwook/Design_project/U-net_Resnet_LBW.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m     model\u001b[39m.\u001b[39meval()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24leehyunwook/Design_project/U-net_Resnet_LBW.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m     \u001b[39mfor\u001b[39;00m images, masks \u001b[39min\u001b[39;00m tqdm(valid_dataloader):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24leehyunwook/Design_project/U-net_Resnet_LBW.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m         images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24leehyunwook/Design_project/U-net_Resnet_LBW.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m         masks \u001b[39m=\u001b[39m masks\u001b[39m.\u001b[39mlong()\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.conda/envs/net_bw/lib/python3.8/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/net_bw/lib/python3.8/site-packages/torch/utils/data/dataloader.py:517\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    516\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 517\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    518\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    519\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    520\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    521\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/net_bw/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1182\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1181\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1182\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1183\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1184\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1185\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/net_bw/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1148\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1147\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1148\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1149\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1150\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.conda/envs/net_bw/lib/python3.8/site-packages/torch/utils/data/dataloader.py:986\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m    974\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m    975\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m    984\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 986\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    987\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m    988\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    989\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/net_bw/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    106\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 107\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    108\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    109\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/.conda/envs/net_bw/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m~/.conda/envs/net_bw/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    425\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/.conda/envs/net_bw/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/.conda/envs/net_bw/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for epoch in range(EP):\n",
    "    # 클래스별 IoU를 누적할 리스트 초기화\n",
    "    train_class_ious = []\n",
    "    # 학습\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for images, masks in tqdm(dataloader):\n",
    "        images = images.float().to(device)\n",
    "        masks = masks.long().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks.squeeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "         # Warmup 스케줄러 업데이트\n",
    "        if epoch < WUP_ITERS:\n",
    "            scheduler_warmup.step()\n",
    "            \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # train 클래스별 IoU 계산\n",
    "        outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "        outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "\n",
    "        for class_id in range(N_CLASSES):\n",
    "            iou = calculate_iou_per_class(np.array(masks.cpu()), np.array(outputs), class_id)\n",
    "            train_class_ious.append(iou)\n",
    "            \n",
    "    train_class_ious = np.array(train_class_ious).reshape(N_CLASSES, -1)\n",
    "    #print(np.shape(train_class_ious))\n",
    "    train_class_ious = np.mean(train_class_ious, axis=1)\n",
    "    #print(train_class_ious)\n",
    "    print(\"--IoU Scores--\")\n",
    "    for class_id, iou in enumerate(train_class_ious):\n",
    "        print(f'Class{class_id}: {iou:.4f}',end=\" \")       \n",
    "        if class_id > 5:\n",
    "            print(\"\\n\")       \n",
    "     \n",
    "        \n",
    "    # mIoU 계산\n",
    "    train_mIoU = np.mean(train_class_ious)\n",
    "    \n",
    "\n",
    "    # validation\n",
    "    val_loss = 0\n",
    "    val_class_ious = []  # 클래스별 IoU를 누적할 리스트 초기화\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for images, masks in tqdm(valid_dataloader):\n",
    "            images = images.float().to(device)\n",
    "            masks = masks.long().to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            # validation loss 계산\n",
    "            val_loss += criterion(outputs, masks.squeeze(1)).item()\n",
    "\n",
    "            # validation 클래스별 IoU 계산\n",
    "            outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "            outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "\n",
    "            for class_id in range(N_CLASSES):\n",
    "                iou = calculate_iou_per_class(np.array(masks.cpu()), np.array(outputs), class_id)\n",
    "                val_class_ious.append(iou)\n",
    "                \n",
    "    val_class_ious = np.array(val_class_ious).reshape(N_CLASSES, -1)\n",
    "    val_class_ious = np.mean(val_class_ious, axis=1)\n",
    "    print(\"--IoU Scores--\")\n",
    "    for class_id, iou in enumerate(val_class_ious):\n",
    "        print(f'Class{class_id}: {iou:.4f}',end=\" \")\n",
    "        if class_id % 3==0:\n",
    "            print(\"\\n\")       \n",
    "   \n",
    "    # mIoU 계산\n",
    "    val_mIoU = np.mean(val_class_ious)\n",
    "    \n",
    "    # 에폭마다 결과 출력 \n",
    "    print(f\"\\nEpoch{epoch+1}\")\n",
    "    print(f\"Train Loss: {(epoch_loss/len(dataloader))}, Train mIoU Score: {train_mIoU:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss/len(valid_dataloader)}, Validation mIoU Score: {val_mIoU:.4f}\")\n",
    "    print(\"___________________________________________________________________________________________\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c32eb51c-a3fe-4e11-a616-3a717ba16f7e",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12371c8b-0c78-47df-89ec-2d8b55c8ea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = CustomDataset(csv_file='./test.csv', transform=transform, infer=True)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b431c-ac8e-4c40-9046-4d53e4bab14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     result = []\n",
    "#     for images in tqdm(test_dataloader):\n",
    "#         images = images.float().to(device)\n",
    "#         outputs = model(images)\n",
    "#         outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "#         outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "#         # batch에 존재하는 각 이미지에 대해서 반복\n",
    "#         for pred in outputs:\n",
    "#             pred = pred.astype(np.uint8)\n",
    "#             pred = Image.fromarray(pred) # 이미지로 변환\n",
    "#             pred = pred.resize((960, 540), Image.NEAREST) # 960 x 540 사이즈로 변환\n",
    "#             pred = np.array(pred) # 다시 수치로 변환\n",
    "#             # class 0 ~ 11에 해당하는 경우에 마스크 형성 / 12(배경)는 제외하고 진행\n",
    "#             for class_id in range(12):\n",
    "#                 class_mask = (pred == class_id).astype(np.uint8)\n",
    "#                 if np.sum(class_mask) > 0: # 마스크가 존재하는 경우 encode\n",
    "#                     mask_rle = rle_encode(class_mask)\n",
    "#                     result.append(mask_rle)\n",
    "#                 else: # 마스크가 존재하지 않는 경우 -1\n",
    "#                     result.append(-1)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36c2cbbb-04f1-4f9c-b4df-4b744dfce046",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac2a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit = pd.read_csv('./sample_submission.csv')\n",
    "# submit['mask_rle'] = result\n",
    "# submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da10cb6f-0826-4755-a376-97b695ae8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit.to_csv('./baseline_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seungyoon2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
