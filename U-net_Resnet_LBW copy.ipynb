{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d73d24e3-5c9e-4ade-9e6e-ca6f46a2d914",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad9b681e-370a-4cfa-a452-dd2d7f0cd77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "# GPU 사용이 가능할 경우, GPU를 사용할 수 있게 함.'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "print(device)\n",
    "\n",
    "print(os.environ.get('CUDA_VISIBLE_DEVICES'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20ff3de5-0d0e-497b-ac75-d5179a3f65d3",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "838e1d83-8670-407b-82f6-bf9652f58639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "# 클래스별 IoU를 계산하기 위한 함수\n",
    "def calculate_iou_per_class(y_true, y_pred, class_id):\n",
    "    intersection = np.sum((y_true == class_id) & (y_pred == class_id))\n",
    "    union = np.sum((y_true == class_id) | (y_pred == class_id))\n",
    "    iou = intersection / union if union > 0 else 0\n",
    "    return iou"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be76a29e-e9c2-411a-a569-04166f074184",
   "metadata": {},
   "source": [
    "## Dataset, Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5acf65a",
   "metadata": {},
   "source": [
    "출력이미지 크기 키우기->ex) resnet 2048->1024->512->256 conv 256->512->1024->2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8496767-2f64-4285-bec4-c6f53a1fd9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        directory_path = \"/mnt/nas27/Dataset/Samsung_DM\"\n",
    "        img_path = self.data.iloc[idx, 1]\n",
    "        img_path = os.path.join(directory_path, img_path[2:])\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Failed to load image at {img_path}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "        \n",
    "        mask_path = self.data.iloc[idx, 2]\n",
    "        mask_path = os.path.join(directory_path, mask_path[2:])\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            raise ValueError(f\"Failed to load mask at {mask_path}\")\n",
    "        mask[mask == 255] = 12\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    \n",
    "    # 이미지 전처리 클래스\n",
    "class ImageTransform():\n",
    "  \"\"\"\n",
    "  훈련, 검증 동작 다르게 설정\n",
    "  이미지 크기 resize, 색상 표준화\n",
    "  훈련시 RandomResizedCrop, RandomHorizontalFilp으로 데이터 확장\n",
    "  \"\"\"\n",
    "  def __init__(self, resize, mean, std):\n",
    "    self.data_transform = {\n",
    "        'train' : transforms.Compose([\n",
    "            #transforms.RandomResizedCrop(\n",
    "            #    resize, scale = (0.5, 1.0)), # 데이터 확장\n",
    "            transforms.RandomHorizontalFlip(), # 데이터 확장\n",
    "            transforms.ToTensor(), # Tensor로 변환\n",
    "            transforms.Normalize(mean = mean, std = std) #표준화\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            #transforms.Resize(resize), # Resize\n",
    "            #transforms.CenterCrop(resize), # 중앙을 resize*resize로 crop\n",
    "            transforms.ToTensor(), # Tensor로 변환\n",
    "            transforms.Normalize(mean = mean, std = std) # 표준화\n",
    "        ])\n",
    "\n",
    "    }\n",
    "  def __call__(self, img, phase = 'train'):\n",
    "    \"\"\"\n",
    "    phase : 'train' or 'test'\n",
    "    전처리 모드 지정\n",
    "    \"\"\"\n",
    "    return self.data_transform[phase](img)\n",
    "\n",
    "\n",
    "transform = A.Compose(\n",
    "    [   \n",
    "        A.Resize(224, 224),\n",
    "        #A.Resize(128, 128),\n",
    "        A.Normalize(),\n",
    "        \n",
    "        # 변형\n",
    "        #A.VerticalFlip(p=0.5),\n",
    "        # A.RandomRotate90(p=0.5),\n",
    "        #A.HueSaturationValue(p=0.2),\n",
    "        \n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a644a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function CustomDataset.__len__ at 0x7f8e17ca2280>\n"
     ]
    }
   ],
   "source": [
    "print(CustomDataset.__len__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a91d6b1",
   "metadata": {},
   "source": [
    "Warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9e62c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmUpLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, total_iters, last_epoch=-1):\n",
    "        self.total_iters = total_iters\n",
    "        super(WarmUpLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [base_lr * self.last_epoch / self.total_iters for base_lr in self.base_lrs]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f42501fc-b573-4893-a7c4-5e280dfdaf09",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "867c4b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadBlock(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channels,channels, stride=1):\n",
    "        super(HeadBlock, self).__init__()\n",
    "\n",
    "        # 1x1 convolution\n",
    "        self.conv1 = nn.Conv2d(in_channels, channels, kernel_size=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        # 3x3 convolution\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        # 1x1 convolution\n",
    "        self.conv3 = nn.Conv2d(channels, channels * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(channels * self.expansion)\n",
    "\n",
    "\n",
    "        self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(channels, channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(channels * self.expansion)\n",
    "            )\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "         \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        \n",
    "        \n",
    "        # Check the size of identity and out\n",
    "        if identity.size() != out.size():\n",
    "            identity = F.interpolate(identity, size=out.size()[2:])\n",
    "        identity = self.shortcut(identity)\n",
    "        out += identity\n",
    "        out = self.relu3(out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3574888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unet의 기본이 되는 conv블럭\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,kernel_size = 3):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, padding=1)  # 여기서 in_channels는 out_channels와 동일해야 합니다.\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        return x\n",
    "\n",
    "class IdentityBlock(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, stride=1):\n",
    "        super(IdentityBlock, self).__init__()\n",
    "        \n",
    "        # 1x1 convolution\n",
    "        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(mid_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # 3x3 convolution\n",
    "        self.conv2 = nn.Conv2d(mid_channels, mid_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(mid_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # 1x1 convolution\n",
    "        self.conv3 = nn.Conv2d(mid_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "         \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.relu3(out)\n",
    "        \n",
    "        return out\n",
    "class HeadBlock(IdentityBlock):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, stride=1):\n",
    "        super(HeadBlock, self).__init__(in_channels, mid_channels, out_channels, stride)\n",
    "        \n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = super().forward(x)\n",
    "        \n",
    "        if identity.size() != out.size():\n",
    "            identity = F.interpolate(identity, size=out.size()[2:])\n",
    "        identity = self.shortcut(identity)\n",
    "        \n",
    "        out += identity\n",
    "        out = self.relu3(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "#인코더 블럭\n",
    "class Conv2(nn.Module):\n",
    "    def __init__(self,in_channels, mid_channels, out_channels):\n",
    "        super(Conv2,self).__init__() \n",
    "        self.headblock = HeadBlock(in_channels,mid_channels,out_channels)\n",
    "        self.identityblock1 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.identityblock2 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "    def forward(self,x):\n",
    "        x = self.headblock(x)\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        p = self.maxpool(x)\n",
    "        return x , p\n",
    "class Conv3(nn.Module):\n",
    "    def __init__(self,in_channels, mid_channels, out_channels):\n",
    "        super(Conv3,self).__init__() \n",
    "        self.headblock = HeadBlock(in_channels,mid_channels,out_channels)\n",
    "        self.identityblock1 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.identityblock2 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.identityblock3 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "    def forward(self,x):\n",
    "        x = self.headblock(x)\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        x = self.identityblock3(x)\n",
    "        p = self.maxpool(x)\n",
    "        return x , p\n",
    "class Conv4(nn.Module):\n",
    "    def __init__(self,in_channels, mid_channels, out_channels):\n",
    "        super(Conv4,self).__init__() \n",
    "        self.headblock = HeadBlock(in_channels,mid_channels,out_channels)\n",
    "        self.identityblock1 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.identityblock2 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.identityblock3 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.identityblock4 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.identityblock5 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "    def forward(self,x):\n",
    "        x = self.headblock(x)\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        x = self.identityblock3(x)\n",
    "        x = self.identityblock4(x)\n",
    "        x = self.identityblock5(x)\n",
    "        p = self.maxpool(x)\n",
    "        return x , p\n",
    "class Conv5(nn.Module):\n",
    "    def __init__(self,in_channels, mid_channels, out_channels):\n",
    "        super(Conv5,self).__init__() \n",
    "        self.headblock = HeadBlock(in_channels,mid_channels,out_channels)\n",
    "        self.identityblock1 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.identityblock2 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "    def forward(self,x):\n",
    "        x = self.headblock(x)\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        p = self.maxpool(x)\n",
    "        return x , p\n",
    "#디코더 블럭\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.upsample = nn.ConvTranspose2d(channels*2, channels, kernel_size=4, stride=2, padding=1, output_padding=1) # output_padding 추가\n",
    "        self.convblock1 = ConvBlock(channels*2, channels)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = self.upsample(x)\n",
    "        if x.size(2) != skip.size(2) or x.size(3) != skip.size(3):\n",
    "            x = F.interpolate(x, size=(skip.size(2), skip.size(3)))\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.convblock1(x)\n",
    "        return x\n",
    "\n",
    "#Unet구조 middle의 xm값의 움직임에 주의\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self,n_classes):\n",
    "        super(Unet,self).__init__()\n",
    "        self.fconv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2)\n",
    "        self.fbn1 = nn.BatchNorm2d(64)\n",
    "        self.frelu1 = nn.ReLU()\n",
    "        self.fconv2 = nn.Conv2d(64, 128, kernel_size=1, stride=1)\n",
    "        self.fbn2 = nn.BatchNorm2d(128)\n",
    "        self.frelu2 = nn.ReLU()\n",
    "        self.fmaxpooling = nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "        \n",
    "        self.conv2 = Conv2(128,64,256)\n",
    "        self.conv3 = Conv3(256,128,512)\n",
    "        self.conv4 = Conv4(512,256,1024)\n",
    "        self.conv5 = Conv5(1024,512,2048)\n",
    "        \n",
    "        self.middleconv = ConvBlock(2048,4096)\n",
    "        #self.dropout = nn.Dropout2d(0.2) #\n",
    "           \n",
    "        self.decoder5 = DecoderBlock(2048)\n",
    "        self.decoder4 = DecoderBlock(1024)\n",
    "        self.decoder3 = DecoderBlock(512)\n",
    "        self.decoder2 = DecoderBlock(256)\n",
    "        self.decoder1 = DecoderBlock(128)\n",
    "        \n",
    "        self.segmap = nn.Conv2d(128,n_classes, kernel_size=1)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fconv1(x)#3->64\n",
    "        x = self.fbn1(x)\n",
    "        x = self.frelu1(x)\n",
    "        x = self.fconv2(x)#3->64\n",
    "        x = self.fbn2(x)\n",
    "        x1 = self.frelu2(x)\n",
    "        p = self.fmaxpooling(x)#첫 conv: x0([8, 64, 109, 109]) p([8, 64, 54, 54])\n",
    "        #print(\"첫 conv:\",x0.shape,p.shape)\n",
    "        x2,p = self.conv2(p)#conv2:  x1:([8, 256, 54, 54]) p([8, 256, 26, 26])\n",
    "        #print(\"conv2: \",x1.shape, p.shape)\n",
    "        x3,p = self.conv3(p)#conv3:  x2([8, 512, 26, 26]) p([8, 512, 12, 12])\n",
    "        #print(\"conv3: \",x2.shape, p.shape)\n",
    "        x4,p = self.conv4(p)#conv4:  x3([8, 1024, 12, 12]) p([8, 1024, 5, 5])\n",
    "        #print(\"conv4: \",x3.shape, p.shape)\n",
    "        x5,p = self.conv5(p)#conv5:  x4([8, 2048, 5, 5]) p([8, 2048, 2, 2])\n",
    "        #print(\"conv5: \",x4.shape, p.shape)\n",
    "        xm = self.middleconv(p)#xm([8, 4096, 2, 2])\n",
    "        #xm = self.dropout(xm)\n",
    "        #print(\"mid:\",xm.shape)\n",
    "        x = self.decoder5(xm,x5)#뉴런:2048*2->2048 1\n",
    "        #print(x.shape)\n",
    "        x = self.decoder4(x,x4)#뉴런:1024*2->1024 \n",
    "        #print(x.shape)\n",
    "        x = self.decoder3(x,x3) #14\n",
    "        #print(x.shape)\n",
    "        x = self.decoder2(x,x2)#28\n",
    "        #print(x.shape)\n",
    "        x = self.decoder1(x,x1)#55\n",
    "        \n",
    "        x = F.interpolate(x, size=(224, 224))\n",
    "        x = self.segmap(x)\n",
    "        #print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4773eff0",
   "metadata": {},
   "source": [
    "## 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd34483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_LR = 0.01\n",
    "END_LR = 0.01\n",
    "EP = 30\n",
    "BATCH_SIZE = 4\n",
    "ACCMULATION_STEP = 3 \n",
    "N_CLASSES = 13 #IoU 점수측정하기 위한 클래스의 개수\n",
    "WUP_ITERS = 10  # 웜업을 위한 반복 횟수\n",
    "# model 초기화\n",
    "#model = Unet_resnet18(n_classes = N_CLASSES).to(device)\n",
    "#model = ResNet50(num_classes=N_CLASSES).to(device)\n",
    "model = Unet(n_classes = N_CLASSES).to(device)\n",
    "\n",
    "\n",
    "# loss function과 optimizer 정의\n",
    "criterion =nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=BASE_LR)\n",
    "optimizer.zero_grad() \n",
    "# Warmup을 위한 스케줄러 설정\n",
    "scheduler_warmup = WarmUpLR(optimizer, WUP_ITERS)\n",
    "\n",
    "dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./train_source.csv'), transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8,pin_memory=True)\n",
    "valid_dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./val_source.csv'), transform=transform)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8,pin_memory=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0895765-fba0-4fd9-b955-a6c0e43012e9",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dec3e516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 49/549 [00:19<03:20,  2.49it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/MMI24limbyungwan/Design_Project/Design_project/U-net_Resnet_LBW copy.ipynb 셀 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsecond/home/MMI24limbyungwan/Design_Project/Design_project/U-net_Resnet_LBW%20copy.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, masks)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsecond/home/MMI24limbyungwan/Design_Project/Design_project/U-net_Resnet_LBW%20copy.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bsecond/home/MMI24limbyungwan/Design_Project/Design_project/U-net_Resnet_LBW%20copy.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsecond/home/MMI24limbyungwan/Design_Project/Design_project/U-net_Resnet_LBW%20copy.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsecond/home/MMI24limbyungwan/Design_Project/Design_project/U-net_Resnet_LBW%20copy.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# if (epoch+1) % ACCMULATION_STEP == 0:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsecond/home/MMI24limbyungwan/Design_Project/Design_project/U-net_Resnet_LBW%20copy.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m#     optimizer.step()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsecond/home/MMI24limbyungwan/Design_Project/Design_project/U-net_Resnet_LBW%20copy.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m#     optimizer.zero_grad()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsecond/home/MMI24limbyungwan/Design_Project/Design_project/U-net_Resnet_LBW%20copy.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m#     # Warmup 스케줄러 업데이트\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsecond/home/MMI24limbyungwan/Design_Project/Design_project/U-net_Resnet_LBW%20copy.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39m# if epoch < WUP_ITERS:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsecond/home/MMI24limbyungwan/Design_Project/Design_project/U-net_Resnet_LBW%20copy.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39m#     scheduler_warmup.step()\u001b[39;00m\n",
      "File \u001b[0;32m/home/MMI24leehyunwook/.conda/envs/net_bw/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:65\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     64\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/MMI24leehyunwook/.conda/envs/net_bw/lib/python3.8/site-packages/torch/optim/optimizer.py:89\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 89\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/MMI24leehyunwook/.conda/envs/net_bw/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/MMI24leehyunwook/.conda/envs/net_bw/lib/python3.8/site-packages/torch/optim/adam.py:108\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    107\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m--> 108\u001b[0m     F\u001b[39m.\u001b[39;49madam(params_with_grad,\n\u001b[1;32m    109\u001b[0m            grads,\n\u001b[1;32m    110\u001b[0m            exp_avgs,\n\u001b[1;32m    111\u001b[0m            exp_avg_sqs,\n\u001b[1;32m    112\u001b[0m            max_exp_avg_sqs,\n\u001b[1;32m    113\u001b[0m            state_steps,\n\u001b[1;32m    114\u001b[0m            group[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    115\u001b[0m            beta1,\n\u001b[1;32m    116\u001b[0m            beta2,\n\u001b[1;32m    117\u001b[0m            group[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    118\u001b[0m            group[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    119\u001b[0m            group[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    120\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/home/MMI24leehyunwook/.conda/envs/net_bw/lib/python3.8/site-packages/torch/optim/_functional.py:92\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     90\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39msqrt(bias_correction2))\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m     91\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39;49m math\u001b[39m.\u001b[39;49msqrt(bias_correction2))\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m     94\u001b[0m step_size \u001b[39m=\u001b[39m lr \u001b[39m/\u001b[39m bias_correction1\n\u001b[1;32m     96\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in range(EP):\n",
    "    # 클래스별 IoU를 누적할 리스트 초기화\n",
    "    train_class_ious = []\n",
    "    # 학습\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for images, masks in tqdm(dataloader):\n",
    "        images = images.float().to(device)\n",
    "        masks = masks.long().to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # if (epoch+1) % ACCMULATION_STEP == 0:\n",
    "        #     optimizer.step()\n",
    "        #     optimizer.zero_grad()\n",
    "        #     # Warmup 스케줄러 업데이트\n",
    "            # if epoch < WUP_ITERS:\n",
    "            #     scheduler_warmup.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    '''\n",
    "    #    # train 클래스별 IoU 계산\n",
    "    #    outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "    #    outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "\n",
    "    #     for class_id in range(N_CLASSES):\n",
    "    #         iou = calculate_iou_per_class(np.array(masks.cpu()), np.array(outputs), class_id)\n",
    "    #         train_class_ious.append(iou)\n",
    "\n",
    "    # train_class_ious = np.array(train_class_ious).reshape(N_CLASSES, -1)\n",
    "    # train_class_ious = np.mean(train_class_ious, axis=1)\n",
    "    # print(\"--IoU Scores Train--\")\n",
    "    # for class_id, iou in enumerate(train_class_ious):\n",
    "    #     print(f'Class{class_id}: {iou:.4f}', end=\" \")\n",
    "    #     if (class_id+1) % 6 == 0:\n",
    "    #         print()\n",
    "\n",
    "    ## mIoU 계산\n",
    "    #train_mIoU = np.mean(train_class_ious)\n",
    "    '''\n",
    "    # ___________________validation_____________________\n",
    "    val_loss = 0\n",
    "    val_class_ious = []  # 클래스별 IoU를 누적할 리스트 초기화\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for images, masks in tqdm(valid_dataloader):\n",
    "            images = images.float().to(device)\n",
    "            masks = masks.long().to(device)\n",
    "            outputs = model(images)\n",
    "            # validation loss 계산\n",
    "            val_loss += criterion(outputs, masks).item()\n",
    "            # validation 클래스별 IoU 계산\n",
    "            outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "            outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "            for class_id in range(N_CLASSES):\n",
    "                iou = calculate_iou_per_class(np.array(masks.cpu()), np.array(outputs), class_id)\n",
    "                val_class_ious.append(iou)\n",
    "    val_class_ious = np.array(val_class_ious).reshape(N_CLASSES, -1)\n",
    "    val_class_ious = np.mean(val_class_ious, axis=1)\n",
    "    print(\"--IoU Scores Valid--\")\n",
    "    for class_id, iou in enumerate(val_class_ious):\n",
    "        print(f'Class{class_id}: {iou:.4f}', end=\" \")\n",
    "        if (class_id+1) % 6 == 0:\n",
    "            print(\"\")\n",
    "    # mIoU 계산\n",
    "    val_mIoU = np.mean(val_class_ious)\n",
    "    # 에폭마다 결과 출력 \n",
    "    print(f\"\\nEpoch{epoch+1}\")\n",
    "    print(f\"Train Loss: {(epoch_loss/len(dataloader))}\")\n",
    "    print(f\"Validation Loss: {val_loss/len(valid_dataloader)}, Validation mIoU Score: {val_mIoU:.4f}\")\n",
    "    print(\"___________________________________________________________________________________________\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c32eb51c-a3fe-4e11-a616-3a717ba16f7e",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12371c8b-0c78-47df-89ec-2d8b55c8ea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = CustomDataset(csv_file='./test.csv', transform=transform, infer=True)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b431c-ac8e-4c40-9046-4d53e4bab14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     result = []\n",
    "#     for images in tqdm(test_dataloader):\n",
    "#         images = images.float().to(device)\n",
    "#         outputs = model(images)\n",
    "#         outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "#         outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "#         # batch에 존재하는 각 이미지에 대해서 반복\n",
    "#         for pred in outputs:\n",
    "#             pred = pred.astype(np.uint8)\n",
    "#             pred = Image.fromarray(pred) # 이미지로 변환\n",
    "#             pred = pred.resize((960, 540), Image.NEAREST) # 960 x 540 사이즈로 변환\n",
    "#             pred = np.array(pred) # 다시 수치로 변환\n",
    "#             # class 0 ~ 11에 해당하는 경우에 마스크 형성 / 12(배경)는 제외하고 진행\n",
    "#             for class_id in range(12):\n",
    "#                 class_mask = (pred == class_id).astype(np.uint8)\n",
    "#                 if np.sum(class_mask) > 0: # 마스크가 존재하는 경우 encode\n",
    "#                     mask_rle = rle_encode(class_mask)\n",
    "#                     result.append(mask_rle)\n",
    "#                 else: # 마스크가 존재하지 않는 경우 -1\n",
    "#                     result.append(-1)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36c2cbbb-04f1-4f9c-b4df-4b744dfce046",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac2a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit = pd.read_csv('./sample_submission.csv')\n",
    "# submit['mask_rle'] = result\n",
    "# submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da10cb6f-0826-4755-a376-97b695ae8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit.to_csv('./baseline_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seungyoon2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
