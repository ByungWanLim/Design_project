{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d73d24e3-5c9e-4ade-9e6e-ca6f46a2d914",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad9b681e-370a-4cfa-a452-dd2d7f0cd77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/MMI24leehyunwook/.conda/envs/net_bw/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "# GPU 사용이 가능할 경우, GPU를 사용할 수 있게 함.'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "print(device)\n",
    "\n",
    "print(os.environ.get('CUDA_VISIBLE_DEVICES'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20ff3de5-0d0e-497b-ac75-d5179a3f65d3",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "838e1d83-8670-407b-82f6-bf9652f58639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "# 클래스별 IoU를 계산하기 위한 함수\n",
    "def calculate_iou_per_class(y_true, y_pred, class_id):\n",
    "    intersection = np.sum((y_true == class_id) & (y_pred == class_id))\n",
    "    union = np.sum((y_true == class_id) | (y_pred == class_id))\n",
    "    iou = intersection / union if union > 0 else 0\n",
    "    return iou"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be76a29e-e9c2-411a-a569-04166f074184",
   "metadata": {},
   "source": [
    "## Dataset, Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5acf65a",
   "metadata": {},
   "source": [
    "출력이미지 크기 키우기->ex) resnet 2048->1024->512->256 conv 256->512->1024->2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8496767-2f64-4285-bec4-c6f53a1fd9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        directory_path = \"/mnt/nas27/Dataset/Samsung_DM\"\n",
    "        img_path = self.data.iloc[idx, 1]\n",
    "        img_path = os.path.join(directory_path, img_path[2:])\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "        \n",
    "        mask_path = self.data.iloc[idx, 2]\n",
    "        mask_path = os.path.join(directory_path, mask_path[2:])\n",
    "        mask = cv2.imread(mask_path)\n",
    "        #mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        mask[mask == 255] = 12 #배경을 픽셀값 12로 간주\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask\n",
    "    \n",
    "    # 이미지 전처리 클래스\n",
    "class ImageTransform():\n",
    "  \"\"\"\n",
    "  훈련, 검증 동작 다르게 설정\n",
    "  이미지 크기 resize, 색상 표준화\n",
    "  훈련시 RandomResizedCrop, RandomHorizontalFilp으로 데이터 확장\n",
    "  \"\"\"\n",
    "  def __init__(self, resize, mean, std):\n",
    "    self.data_transform = {\n",
    "        'train' : transforms.Compose([\n",
    "            #transforms.RandomResizedCrop(\n",
    "            #    resize, scale = (0.5, 1.0)), # 데이터 확장\n",
    "            transforms.RandomHorizontalFlip(), # 데이터 확장\n",
    "            transforms.ToTensor(), # Tensor로 변환\n",
    "            transforms.Normalize(mean = mean, std = std) #표준화\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            #transforms.Resize(resize), # Resize\n",
    "            #transforms.CenterCrop(resize), # 중앙을 resize*resize로 crop\n",
    "            transforms.ToTensor(), # Tensor로 변환\n",
    "            transforms.Normalize(mean = mean, std = std) # 표준화\n",
    "        ])\n",
    "\n",
    "    }\n",
    "  def __call__(self, img, phase = 'train'):\n",
    "    \"\"\"\n",
    "    phase : 'train' or 'test'\n",
    "    전처리 모드 지정\n",
    "    \"\"\"\n",
    "    return self.data_transform[phase](img)\n",
    "\n",
    "\n",
    "transform = A.Compose(\n",
    "    [   \n",
    "        #A.Resize(224, 224),\n",
    "        A.Resize(256, 256),\n",
    "        A.Normalize(),\n",
    "        \n",
    "        # 변형\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        # A.RandomRotate90(p=0.5),\n",
    "        A.HueSaturationValue(p=0.2),\n",
    "        \n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a91d6b1",
   "metadata": {},
   "source": [
    "Warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9e62c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmUpLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, total_iters, last_epoch=-1):\n",
    "        self.total_iters = total_iters\n",
    "        super(WarmUpLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [base_lr * self.last_epoch / self.total_iters for base_lr in self.base_lrs]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f42501fc-b573-4893-a7c4-5e280dfdaf09",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "867c4b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        # 1x1 convolution\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        # 3x3 convolution\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        # 1x1 convolution\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels * self.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * self.expansion)\n",
    "            )\n",
    "\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        identity = self.shortcut(identity)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu3(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# 예제 사용\n",
    "block = Bottleneck(64, 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3574888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unet의 기본이 되는 conv블럭\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)  # 여기서 in_channels는 out_channels와 동일해야 합니다.\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        return x\n",
    "\n",
    "#인코더 블럭\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(EncoderBlock,self).__init__()\n",
    "        self.convblock1 = ConvBlock(in_channels, out_channels)  # 첫 번째 ConvBlock의 in_channels는 입력 이미지의 채널 수와 일치해야 합니다.\n",
    "        self.convblock2 = ConvBlock(out_channels, out_channels)  # 두 번째 ConvBlock의 in_channels는 out_channels와 일치해야 합니다.\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.convblock1(x)\n",
    "        x = self.convblock2(x)\n",
    "        p = self.maxpool(x)\n",
    "        return x , p\n",
    "#디코더 블럭\n",
    "#디코더는 업샘플링 이후 스킵연결과 붙어서 convblock을 통과해야함\n",
    "#skip보다 작은 x x먼저 업샘플링 32 -> 64 , skip과 결합 6464 \n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(DecoderBlock,self).__init__()\n",
    "        self.upsample = nn.ConvTranspose2d(channels*2, channels, kernel_size=4, stride=2, padding=1)#x 업샘플링\n",
    "        self.convblock1 = ConvBlock(channels*2, channels)#차원감소\n",
    "        self.convblock2 = ConvBlock(channels, channels)\n",
    "    def forward(self,x,skip):\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.convblock1(x)\n",
    "        x = self.convblock2(x)\n",
    "        return x\n",
    "        \n",
    "#Unet구조 middle의 xm값의 움직임에 주의\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self,n_classes):\n",
    "        super(Unet,self).__init__()\n",
    "        self.encoder1 = EncoderBlock(3,64)\n",
    "        self.encoder2 = EncoderBlock(64,128)\n",
    "        self.encoder3 = EncoderBlock(128,256)\n",
    "        self.encoder4 = EncoderBlock(256,512)\n",
    "        \n",
    "        self.middleconv = ConvBlock(512,1024)\n",
    "        \n",
    "        \n",
    "        self.decoder4 = DecoderBlock(512)\n",
    "        self.decoder3 = DecoderBlock(256)\n",
    "        self.decoder2 = DecoderBlock(128)\n",
    "        self.decoder1 = DecoderBlock(64)\n",
    "        self.segmap = nn.Conv2d(64,n_classes, kernel_size=1)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x1,p = self.encoder1(x)#3->64   #P:256,256 x1 :512,512\n",
    "        x2,p = self.encoder2(p)#64->128 #P:128,128 x2:256,256\n",
    "        x3,p = self.encoder3(p)#128->256#p:64,64 x3:128,128\n",
    "        x4,p = self.encoder4(p)#256->512#p:32,32 x4:64,64\n",
    "        \n",
    "        xm = self.middleconv(p)#512->1024#32,32\n",
    "        \n",
    "        x = self.decoder4(xm,x4)#뉴런:1024->512->512 #출력tensor:64,64\n",
    "        x = self.decoder3(x,x3)#뉴런:512->256->256 #출력tensor:128,128\n",
    "        x = self.decoder2(x,x2)#뉴런:256->128->128 #출력tensor:256,256\n",
    "        x = self.decoder1(x,x1)#뉴런:128->64->64 #출력tensor:512,512\n",
    "        x = self.segmap(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdb7c3b",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baf22f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class UNetWithResnet50Encoder(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ResNet50 백본을 불러옵니다.\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        \n",
    "        # 인코더 부분\n",
    "        self.encoder0 = nn.Sequential(\n",
    "            self.resnet.conv1,\n",
    "            self.resnet.bn1,\n",
    "            self.resnet.relu,\n",
    "            self.resnet.maxpool\n",
    "        )\n",
    "        self.encoder1 = self.resnet.layer1\n",
    "        self.encoder2 = self.resnet.layer2\n",
    "        self.encoder3 = self.resnet.layer3\n",
    "        self.encoder4 = self.resnet.layer4\n",
    "        \n",
    "        # 중간 컨볼루션\n",
    "        self.middle_conv = nn.Sequential(\n",
    "            nn.Conv2d(2048, 1024, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # 디코더 부분\n",
    "        self.decoder3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1024+1024, 512, kernel_size=2, stride=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512+512, 256, kernel_size=2, stride=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # 디코더 부분\n",
    "        self.decoder1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256+256, 128, kernel_size=2, stride=2),  # 출력 채널 수를 128로 변경\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder0 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128+64, n_classes, kernel_size=2, stride=2),  # 입력 채널 수를 192로 변경\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 인코더 부분\n",
    "        x0 = self.encoder0(x)\n",
    "        x1 = self.encoder1(x0)\n",
    "        x2 = self.encoder2(x1)\n",
    "        x3 = self.encoder3(x2)\n",
    "        x4 = self.encoder4(x3)\n",
    "        \n",
    "        # 중간 컨볼루션 후 업샘플링\n",
    "        middle = self.middle_conv(x4)\n",
    "        middle_upsampled = nn.functional.interpolate(middle, scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        # 디코더 부분 (skip connection 추가)\n",
    "        d3 = self.decoder3(torch.cat([middle_upsampled, x3], dim=1))\n",
    "        d2 = self.decoder2(torch.cat([d3, x2], dim=1))\n",
    "        d1 = self.decoder1(torch.cat([d2, x1], dim=1))\n",
    "        out = self.decoder0(torch.cat([d1, x0], dim=1))\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd34483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "EP = 20\n",
    "BATCH_SIZE = 12\n",
    "ACCMULATION_STEP = 4 \n",
    "N_CLASSES = 13 #IoU 점수측정하기 위한 클래스의 개수\n",
    "WUP_ITERS = 10  # 웜업을 위한 반복 횟수\n",
    "# model 초기화\n",
    "#model = Unet_resnet18(n_classes = N_CLASSES).to(device)\n",
    "#model = ResNet50(num_classes=N_CLASSES).to(device)\n",
    "model = Unet(n_classes = N_CLASSES).to(device)\n",
    "\n",
    "# loss function과 optimizer 정의\n",
    "criterion =nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "optimizer.zero_grad() \n",
    "# Warmup을 위한 스케줄러 설정\n",
    "scheduler_warmup = WarmUpLR(optimizer, WUP_ITERS)\n",
    "\n",
    "dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./train_source.csv'), transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "valid_dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./val_source.csv'), transform=transform)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0895765-fba0-4fd9-b955-a6c0e43012e9",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dec3e516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [02:43<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.1185 Class1: 0.1468 Class2: 0.1675 Class3: 0.1612 Class4: 0.1804 Class5: 0.1786 \n",
      "Class6: 0.1645 Class7: 0.1843 Class8: 0.1922 Class9: 0.1832 Class10: 0.1903 Class11: 0.2033 \n",
      "Class12: 0.1883 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.0940 Class1: 0.0795 Class2: 0.0795 Class3: 0.0835 Class4: 0.0761 Class5: 0.0968 \n",
      "Class6: 0.0888 Class7: 0.0972 Class8: 0.0645 Class9: 0.0880 Class10: 0.0800 Class11: 0.0846 \n",
      "Class12: 0.0848 \n",
      "Epoch1\n",
      "Train Loss: 1.3610610294211758, Train mIoU Score: 0.1738\n",
      "Validation Loss: 7.84528286029131, Validation mIoU Score: 0.0844\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [02:42<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.1933 Class1: 0.2066 Class2: 0.1976 Class3: 0.1948 Class4: 0.1801 Class5: 0.1853 \n",
      "Class6: 0.2000 Class7: 0.2134 Class8: 0.2225 Class9: 0.2300 Class10: 0.2011 Class11: 0.2058 \n",
      "Class12: 0.2086 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:20<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.1654 Class1: 0.1676 Class2: 0.1526 Class3: 0.1611 Class4: 0.1672 Class5: 0.1726 \n",
      "Class6: 0.1854 Class7: 0.1625 Class8: 0.1451 Class9: 0.2037 Class10: 0.1583 Class11: 0.1866 \n",
      "Class12: 0.1587 \n",
      "Epoch2\n",
      "Train Loss: 1.1503531206500985, Train mIoU Score: 0.2030\n",
      "Validation Loss: 1.3221243986716638, Validation mIoU Score: 0.1682\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [02:42<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.2150 Class1: 0.2058 Class2: 0.2142 Class3: 0.2133 Class4: 0.2232 Class5: 0.2078 \n",
      "Class6: 0.2168 Class7: 0.2145 Class8: 0.2393 Class9: 0.1973 Class10: 0.1966 Class11: 0.2190 \n",
      "Class12: 0.2173 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:20<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.1309 Class1: 0.1286 Class2: 0.1286 Class3: 0.1408 Class4: 0.1210 Class5: 0.1248 \n",
      "Class6: 0.1289 Class7: 0.1279 Class8: 0.1133 Class9: 0.1302 Class10: 0.1275 Class11: 0.1326 \n",
      "Class12: 0.1216 \n",
      "Epoch3\n",
      "Train Loss: 1.09909642850115, Train mIoU Score: 0.2139\n",
      "Validation Loss: 1.7133020529380212, Validation mIoU Score: 0.1274\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [02:42<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.2250 Class1: 0.2292 Class2: 0.2090 Class3: 0.2102 Class4: 0.2052 Class5: 0.2222 \n",
      "Class6: 0.2295 Class7: 0.2374 Class8: 0.2343 Class9: 0.2396 Class10: 0.2546 Class11: 0.2289 \n",
      "Class12: 0.2526 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:20<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.2134 Class1: 0.1902 Class2: 0.2055 Class3: 0.2074 Class4: 0.1957 Class5: 0.2031 \n",
      "Class6: 0.2067 Class7: 0.1907 Class8: 0.1877 Class9: 0.2262 Class10: 0.1998 Class11: 0.1980 \n",
      "Class12: 0.1785 \n",
      "Epoch4\n",
      "Train Loss: 1.006772628247412, Train mIoU Score: 0.2290\n",
      "Validation Loss: 1.167797015263484, Validation mIoU Score: 0.2002\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [02:42<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.2347 Class1: 0.2395 Class2: 0.2284 Class3: 0.2338 Class4: 0.2397 Class5: 0.2484 \n",
      "Class6: 0.1954 Class7: 0.2325 Class8: 0.2339 Class9: 0.2187 Class10: 0.2208 Class11: 0.2325 \n",
      "Class12: 0.2154 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.0708 Class1: 0.0691 Class2: 0.0636 Class3: 0.0718 Class4: 0.0731 Class5: 0.0745 \n",
      "Class6: 0.0810 Class7: 0.0723 Class8: 0.0796 Class9: 0.0728 Class10: 0.0780 Class11: 0.0758 \n",
      "Class12: 0.0706 \n",
      "Epoch5\n",
      "Train Loss: 1.0105205315058348, Train mIoU Score: 0.2287\n",
      "Validation Loss: 2.398027077699319, Validation mIoU Score: 0.0733\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [02:43<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.2439 Class1: 0.2324 Class2: 0.2400 Class3: 0.2355 Class4: 0.2338 Class5: 0.2370 \n",
      "Class6: 0.2236 Class7: 0.2507 Class8: 0.2333 Class9: 0.2411 Class10: 0.2355 Class11: 0.2289 \n",
      "Class12: 0.2272 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:20<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.1150 Class1: 0.1106 Class2: 0.1193 Class3: 0.1253 Class4: 0.1164 Class5: 0.1148 \n",
      "Class6: 0.1212 Class7: 0.1212 Class8: 0.1079 Class9: 0.1251 Class10: 0.1161 Class11: 0.1159 \n",
      "Class12: 0.1193 \n",
      "Epoch6\n",
      "Train Loss: 0.9801666342495569, Train mIoU Score: 0.2356\n",
      "Validation Loss: 1.7739475048505342, Validation mIoU Score: 0.1175\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [02:42<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.2328 Class1: 0.2335 Class2: 0.1982 Class3: 0.1665 Class4: 0.0724 Class5: 0.1150 \n",
      "Class6: 0.1199 Class7: 0.1131 Class8: 0.0804 Class9: 0.0852 Class10: 0.0642 Class11: 0.0281 \n",
      "Class12: 0.0163 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import random\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in range(EP):\n",
    "    # 클래스별 IoU를 누적할 리스트 초기화\n",
    "    train_class_ious = []\n",
    "    # 학습\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for images, masks in tqdm(dataloader):\n",
    "        images = images.float().to(device)\n",
    "        masks = masks.long().to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        if (epoch+1) % ACCMULATION_STEP == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            # Warmup 스케줄러 업데이트\n",
    "            if epoch < WUP_ITERS:\n",
    "                scheduler_warmup.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # train 클래스별 IoU 계산\n",
    "        outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "        outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "\n",
    "        for class_id in range(N_CLASSES):\n",
    "            iou = calculate_iou_per_class(np.array(masks.cpu()), np.array(outputs), class_id)\n",
    "            train_class_ious.append(iou)\n",
    "\n",
    "    train_class_ious = np.array(train_class_ious).reshape(N_CLASSES, -1)\n",
    "    train_class_ious = np.mean(train_class_ious, axis=1)\n",
    "    print(\"--IoU Scores Train--\")\n",
    "    for class_id, iou in enumerate(train_class_ious):\n",
    "        print(f'Class{class_id}: {iou:.4f}', end=\" \")\n",
    "        if (class_id+1) % 6 == 0:\n",
    "            print()\n",
    "\n",
    "    # mIoU 계산\n",
    "    train_mIoU = np.mean(train_class_ious)\n",
    "\n",
    "    # validation\n",
    "    val_loss = 0\n",
    "    val_class_ious = []  # 클래스별 IoU를 누적할 리스트 초기화\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for images, masks in tqdm(valid_dataloader):\n",
    "            images = images.float().to(device)\n",
    "            masks = masks.long().to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            # validation loss 계산\n",
    "            val_loss += criterion(outputs, masks).item()\n",
    "\n",
    "            # validation 클래스별 IoU 계산\n",
    "            outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "            outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "\n",
    "            for class_id in range(N_CLASSES):\n",
    "                iou = calculate_iou_per_class(np.array(masks.cpu()), np.array(outputs), class_id)\n",
    "                val_class_ious.append(iou)\n",
    "\n",
    "    val_class_ious = np.array(val_class_ious).reshape(N_CLASSES, -1)\n",
    "    val_class_ious = np.mean(val_class_ious, axis=1)\n",
    "    print(\"--IoU Scores Valid--\")\n",
    "    for class_id, iou in enumerate(val_class_ious):\n",
    "        print(f'Class{class_id}: {iou:.4f}', end=\" \")\n",
    "        if (class_id+1) % 6 == 0:\n",
    "            print(\"\")\n",
    "\n",
    "    # mIoU 계산\n",
    "    val_mIoU = np.mean(val_class_ious)\n",
    "\n",
    "    # 에폭마다 결과 출력 \n",
    "    print(f\"\\nEpoch{epoch+1}\")\n",
    "    print(f\"Train Loss: {(epoch_loss/len(dataloader))}, Train mIoU Score: {train_mIoU:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss/len(valid_dataloader)}, Validation mIoU Score: {val_mIoU:.4f}\")\n",
    "    print(\"___________________________________________________________________________________________\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c32eb51c-a3fe-4e11-a616-3a717ba16f7e",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12371c8b-0c78-47df-89ec-2d8b55c8ea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = CustomDataset(csv_file='./test.csv', transform=transform, infer=True)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b431c-ac8e-4c40-9046-4d53e4bab14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     result = []\n",
    "#     for images in tqdm(test_dataloader):\n",
    "#         images = images.float().to(device)\n",
    "#         outputs = model(images)\n",
    "#         outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "#         outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "#         # batch에 존재하는 각 이미지에 대해서 반복\n",
    "#         for pred in outputs:\n",
    "#             pred = pred.astype(np.uint8)\n",
    "#             pred = Image.fromarray(pred) # 이미지로 변환\n",
    "#             pred = pred.resize((960, 540), Image.NEAREST) # 960 x 540 사이즈로 변환\n",
    "#             pred = np.array(pred) # 다시 수치로 변환\n",
    "#             # class 0 ~ 11에 해당하는 경우에 마스크 형성 / 12(배경)는 제외하고 진행\n",
    "#             for class_id in range(12):\n",
    "#                 class_mask = (pred == class_id).astype(np.uint8)\n",
    "#                 if np.sum(class_mask) > 0: # 마스크가 존재하는 경우 encode\n",
    "#                     mask_rle = rle_encode(class_mask)\n",
    "#                     result.append(mask_rle)\n",
    "#                 else: # 마스크가 존재하지 않는 경우 -1\n",
    "#                     result.append(-1)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36c2cbbb-04f1-4f9c-b4df-4b744dfce046",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac2a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit = pd.read_csv('./sample_submission.csv')\n",
    "# submit['mask_rle'] = result\n",
    "# submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da10cb6f-0826-4755-a376-97b695ae8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit.to_csv('./baseline_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seungyoon2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
