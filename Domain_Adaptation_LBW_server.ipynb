{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "#from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# GPU 사용이 가능할 경우, GPU를 사용할 수 있게 함.'\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "print(device)\n",
    "\n",
    "#print(os.environ.get('CUDA_VISIBLE_DEVICES'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "# 클래스별 IoU를 계산하기 위한 함수\n",
    "def calculate_iou_per_class(y_true, y_pred, class_id):\n",
    "    intersection = np.sum((y_true == class_id) & (y_pred == class_id))\n",
    "    union = np.sum((y_true == class_id) | (y_pred == class_id))\n",
    "    iou = intersection / union if union > 0 else 0\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #directory_path = \"/mnt/nas27/Dataset/Samsung_DM\"\n",
    "        directory_path = './data/224'\n",
    "        img_path = self.data.iloc[idx, 1]\n",
    "        img_path = os.path.join(directory_path, img_path)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "        \n",
    "        mask_path = self.data.iloc[idx, 2]\n",
    "        mask_path = os.path.join(directory_path, mask_path)\n",
    "        mask = cv2.imread(mask_path)\n",
    "        #mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        mask = np.round(mask).astype(np.uint8)\n",
    "        mask[mask > 12] = 12 #배경을 픽셀값 12로 간주\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# class CustomDataset_target(Dataset):\n",
    "#     def __init__(self, csv_file, transform=None, infer=False):\n",
    "#         self.data = pd.read_csv(csv_file)\n",
    "#         self.transform = transform\n",
    "#         self.infer = infer\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         directory_path = \"/mnt/nas27/Dataset/Samsung_DM\"\n",
    "#         img_path = self.data.iloc[idx, 1]\n",
    "#         img_path = os.path.join(directory_path, img_path[2:])\n",
    "#         image = cv2.imread(img_path)\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "#         if self.infer:\n",
    "#             if self.transform:\n",
    "#                 image = self.transform(image=image)['image']\n",
    "#             return image\n",
    "\n",
    "\n",
    "#         if self.transform:\n",
    "#             augmented = self.transform(image=image)\n",
    "#             image = augmented['image']\n",
    "            \n",
    "\n",
    "#         return image\n",
    "     \n",
    "\n",
    "transform = A.Compose(\n",
    "    [   \n",
    "        #A.Resize(224, 224),\n",
    "        #A.Resize(128, 128),\n",
    "        A.Normalize(),\n",
    "        \n",
    "        # 변형\n",
    "        # A.VerticalFlip(p=0.5),\n",
    "        # A.RandomRotate90(p=0.5),\n",
    "        # A.HueSaturationValue(p=0.2),\n",
    "        \n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unet의 기본이 되는 conv블럭\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)  # 여기서 in_channels는 out_channels와 동일해야 합니다.\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        return x\n",
    "\n",
    "#인코더 블럭\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(EncoderBlock,self).__init__()\n",
    "        self.convblock1 = ConvBlock(in_channels, out_channels)  # 첫 번째 ConvBlock의 in_channels는 입력 이미지의 채널 수와 일치해야 합니다.\n",
    "        #self.convblock2 = ConvBlock(out_channels, out_channels)  # 두 번째 ConvBlock의 in_channels는 out_channels와 일치해야 합니다.\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.convblock1(x)\n",
    "        #x = self.convblock2(x)\n",
    "        p = self.maxpool(x)\n",
    "        return x , p\n",
    "#디코더 블럭\n",
    "#디코더는 업샘플링 이후 스킵연결과 붙어서 convblock을 통과해야함\n",
    "#skip보다 작은 x x먼저 업샘플링 32 -> 64 , skip과 결합 6464 \n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(DecoderBlock,self).__init__()\n",
    "        self.upsample = nn.ConvTranspose2d(channels*2, channels, kernel_size=4, stride=2, padding=1)#x 업샘플링\n",
    "        self.convblock1 = ConvBlock(channels*2, channels)#차원감소\n",
    "        #self.convblock2 = ConvBlock(channels, channels)\n",
    "    def forward(self,x,skip):\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.convblock1(x)\n",
    "        #x = self.convblock2(x)\n",
    "        return x\n",
    "\n",
    "###########################################\n",
    "class GradReverse(torch.autograd.Function):\n",
    "    def forward(self, x):\n",
    "        return x.view_as(x)\n",
    "\n",
    "    def backward(self, grad_output): # 역전파 시에 gradient에 음수를 취함\n",
    "        return (grad_output * -1)\n",
    "\n",
    "class domain_classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(domain_classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(224*224*64, 10)\n",
    "        self.fc2 = nn.Linear(10, 1) # source = 0, target = 1 회귀 가정\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 224*224*64)\n",
    "        x = GradReverse.apply(x) # gradient reverse\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "###########################################\n",
    "\n",
    "\n",
    "#Unet구조 middle의 xm값의 움직임에 주의\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self,n_classes):\n",
    "        super(Unet,self).__init__()\n",
    "        self.encoder1 = EncoderBlock(3,64)\n",
    "        self.encoder2 = EncoderBlock(64,128)\n",
    "        self.encoder3 = EncoderBlock(128,256)\n",
    "        self.encoder4 = EncoderBlock(256,512)\n",
    "        \n",
    "        self.middleconv = ConvBlock(512,1024)\n",
    "        \n",
    "        \n",
    "        self.decoder4 = DecoderBlock(512)\n",
    "        self.decoder3 = DecoderBlock(256)\n",
    "        self.decoder2 = DecoderBlock(128)\n",
    "        self.decoder1 = DecoderBlock(64)\n",
    "        self.segmap = nn.Conv2d(64,n_classes, kernel_size=1)\n",
    "        \n",
    "        self.domain_classifier = domain_classifier()\n",
    "                                        \n",
    "\n",
    "    def forward(self,x):\n",
    "        x1,p = self.encoder1(x)#3->64   #P:256,256 x1 :512,512\n",
    "        x2,p = self.encoder2(p)#64->128 #P:128,128 x2:256,256\n",
    "        x3,p = self.encoder3(p)#128->256#p:64,64 x3:128,128\n",
    "        x4,p = self.encoder4(p)#256->512#p:32,32 x4:64,64\n",
    "        \n",
    "        xm = self.middleconv(p)#512->1024#32,32\n",
    "        \n",
    "        x = self.decoder4(xm,x4)#뉴런:1024->512->512 #출력tensor:64,64\n",
    "        x = self.decoder3(x,x3)#뉴런:512->256->256 #출력tensor:128,128\n",
    "        x = self.decoder2(x,x2)#뉴런:256->128->128 #출력tensor:256,256\n",
    "        x = self.decoder1(x,x1)#뉴런:128->64->64 #출력tensor:512,512\n",
    "\n",
    "        x_c = self.segmap(x)\n",
    "        x_d = self.domain_classifier(x)\n",
    "\n",
    "        return x_c, x_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   6.2232,   81.0473,    5.1017,   66.2180,  170.2419,  506.2671,\n",
      "         159.9452,    6.9654,    4.3830,  907.1918, 2223.4863,   10.2576,\n",
      "           7.6339], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# 저장된 class_weights를 불러옵니다.\n",
    "class_weights_path = 'CLASS_WEIGHTS.pkl'\n",
    "\n",
    "with open(class_weights_path, 'rb') as file:\n",
    "    CLASS_WEIGHTS = pickle.load(file)\n",
    "\n",
    "print(CLASS_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function과 optimizer 정의\n",
    "\n",
    "class DANN_Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DANN_Loss, self).__init__()\n",
    "\n",
    "        self.CE = nn.CrossEntropyLoss(weight=CLASS_WEIGHTS) # 0~9 class 분류용\n",
    "        self.BCE = nn.BCELoss() # 도메인 분류용\n",
    "        \n",
    "    # result : DANN_CNN에서 반환된 값\n",
    "    # label : 숫자 0 ~ 9에 대한 라벨\n",
    "    # domain_num : 0(source) or 1(target)\n",
    "    def forward(self, result, label, domain_num, alpha = 1):\n",
    "        label_logits, domain_logits = result # DANN_CNN의 결과\n",
    "\n",
    "        batch_size = domain_logits.shape[0]\n",
    "\n",
    "        domain_target = torch.FloatTensor([domain_num] * batch_size).unsqueeze(1).to(device)\n",
    "\n",
    "        domain_loss = self.BCE(domain_logits, domain_target) # domain 분류 loss\n",
    "        target_loss = self.CE(label_logits, label) # class 분류 loss\n",
    "\n",
    "        loss = target_loss + alpha * domain_loss\n",
    "\n",
    "        return loss\n",
    "    \n",
    "\n",
    "loss_fn = DANN_Loss().to(device)\n",
    "\n",
    "#criterion =nn.CrossEntropyLoss()\n",
    "#domain_criterion = nn.BCELoss()\n",
    "#criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "EP = 10\n",
    "BATCH_SIZE = 4\n",
    "ACCMULATION_STEP = 1 \n",
    "N_CLASSES = 13 #IoU 점수측정하기 위한 클래스의 개수\n",
    "ALPHA = 0.5\n",
    "# model 초기화\n",
    "#model = Unet_resnet18(n_classes = N_CLASSES).to(device)\n",
    "#model = ResNet50(num_classes=N_CLASSES).to(device)\n",
    "model = Unet(n_classes = N_CLASSES).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "optimizer.zero_grad() \n",
    "\n",
    "source_dataset = CustomDataset(csv_file='./data/DA_csv/train_source.csv', transform=transform)\n",
    "source_dataloader = DataLoader(source_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "target_dataset = CustomDataset(csv_file='./data/DA_csv/fish_train_source.csv', transform=transform)\n",
    "target_dataloader = DataLoader(target_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_source_dataset = CustomDataset(csv_file='./data/DA_csv/val_source.csv', transform=transform)\n",
    "val_source_dataloader = DataLoader(val_source_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_target_dataset = CustomDataset(csv_file='./data/DA_csv/fish_val_source.csv', transform=transform)\n",
    "val_target_dataloader = DataLoader(val_target_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "# source_dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./train_source.csv'), transform=transform)#\n",
    "# source_dataloader = DataLoader(source_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "# s_valid_dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./val_source.csv'), transform=transform)\n",
    "# s_valid_dataloader = DataLoader(s_valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "# #target_dataset = CustomDataset_target(csv_file='./f_train_source.csv', transform=transform)\n",
    "# target_dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./fish_val_source.csv'), transform=transform)\n",
    "# target_dataloader = DataLoader(target_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "\n",
    "# t_test_dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./test.csv'), transform=transform, infer=True)\n",
    "# t_test_dataloader = DataLoader(t_test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# a1 = pd.read_csv(\"./data/6_fish_source.csv\")\n",
    "# p = \"./data/224/\"\n",
    "# a2 = os.path.join(p, a1.iloc[3,2])\n",
    "# a3 = cv2.imread(a2)\n",
    "# a4 = cv2.cvtColor(a3, cv2.COLOR_BGR2GRAY)\n",
    "# a4 = np.round(a4).astype(np.uint8)\n",
    "# a5 = a4*20\n",
    "\n",
    "# plt.imshow(a5, cmap='gray')\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "275it [03:08,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.0527 Class1: 0.0934 Class2: 0.1218 Class3: 0.1561 Class4: 0.2113 Class5: 0.2406 Class6: 0.2449 \n",
      "Class7: 0.2596 Class8: 0.2714 Class9: 0.2643 Class10: 0.2883 Class11: 0.3021 Class12: 0.3052 \n",
      "--IoU Scores Fish Train--\n",
      "Class0: 0.0579 Class1: 0.1079 Class2: 0.1251 Class3: 0.1287 Class4: 0.1377 Class5: 0.1501 Class6: 0.2000 \n",
      "Class7: 0.2303 Class8: 0.2365 Class9: 0.2524 Class10: 0.2586 Class11: 0.2488 Class12: 0.2634 \n",
      "Epoch1\n",
      "Train Loss: 52.74013013319536\n",
      "Train mIoU: 0.21628485790380841, Fish_Train_mIoU: 0.1844224915116421\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:20,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores val--\n",
      "Class0: 0.1715 Class1: 0.2002 Class2: 0.1702 Class3: 0.1769 Class4: 0.1841 Class5: 0.1868 Class6: 0.1898 \n",
      "Class7: 0.1753 Class8: 0.1882 Class9: 0.1756 Class10: 0.1741 Class11: 0.1741 Class12: 0.1944 \n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.2140 Class1: 0.2233 Class2: 0.1919 Class3: 0.2083 Class4: 0.2147 Class5: 0.2082 Class6: 0.2123 \n",
      "Class7: 0.2074 Class8: 0.1947 Class9: 0.2127 Class10: 0.1947 Class11: 0.2040 Class12: 0.2023 \n",
      "Epoch1\n",
      "Train Loss: 53.4617869490284\n",
      "Train mIoU: 0.18162233750980766, Fish_Train_mIoU: 0.20680415587353929\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "275it [03:04,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.2963 Class1: 0.3096 Class2: 0.3124 Class3: 0.3156 Class4: 0.3336 Class5: 0.3055 Class6: 0.3288 \n",
      "Class7: 0.3258 Class8: 0.3358 Class9: 0.3425 Class10: 0.3388 Class11: 0.3360 Class12: 0.3358 \n",
      "--IoU Scores Fish Train--\n",
      "Class0: 0.2765 Class1: 0.2771 Class2: 0.2590 Class3: 0.2765 Class4: 0.2733 Class5: 0.2663 Class6: 0.2905 \n",
      "Class7: 0.2739 Class8: 0.2899 Class9: 0.3038 Class10: 0.2966 Class11: 0.2877 Class12: 0.2974 \n",
      "Epoch2\n",
      "Train Loss: 52.100992944890805\n",
      "Train mIoU: 0.3243598646152893, Fish_Train_mIoU: 0.2822070953907656\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:18,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores val--\n",
      "Class0: 0.2102 Class1: 0.2569 Class2: 0.2017 Class3: 0.2092 Class4: 0.2181 Class5: 0.2619 Class6: 0.2348 \n",
      "Class7: 0.2163 Class8: 0.2355 Class9: 0.2332 Class10: 0.2191 Class11: 0.2120 Class12: 0.2328 \n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.1926 Class1: 0.2145 Class2: 0.1700 Class3: 0.2125 Class4: 0.1979 Class5: 0.2013 Class6: 0.1903 \n",
      "Class7: 0.1956 Class8: 0.1850 Class9: 0.1904 Class10: 0.1914 Class11: 0.1954 Class12: 0.2079 \n",
      "Epoch2\n",
      "Train Loss: 53.20594464318227\n",
      "Train mIoU: 0.22628683129768884, Fish_Train_mIoU: 0.19574669131892714\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "275it [03:03,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.3417 Class1: 0.3580 Class2: 0.3524 Class3: 0.3531 Class4: 0.3566 Class5: 0.3523 Class6: 0.3673 \n",
      "Class7: 0.3644 Class8: 0.3655 Class9: 0.3530 Class10: 0.3607 Class11: 0.3473 Class12: 0.3583 \n",
      "--IoU Scores Fish Train--\n",
      "Class0: 0.3022 Class1: 0.3113 Class2: 0.2994 Class3: 0.3140 Class4: 0.3109 Class5: 0.3075 Class6: 0.3177 \n",
      "Class7: 0.3062 Class8: 0.3173 Class9: 0.3025 Class10: 0.3214 Class11: 0.3108 Class12: 0.3226 \n",
      "Epoch3\n",
      "Train Loss: 51.88267008001154\n",
      "Train mIoU: 0.35618259103244215, Fish_Train_mIoU: 0.31107735356704735\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:18,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores val--\n",
      "Class0: 0.3000 Class1: 0.3564 Class2: 0.2890 Class3: 0.3137 Class4: 0.3042 Class5: 0.3408 Class6: 0.3325 \n",
      "Class7: 0.3219 Class8: 0.3132 Class9: 0.3195 Class10: 0.3050 Class11: 0.3245 Class12: 0.3434 \n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.2367 Class1: 0.2535 Class2: 0.2117 Class3: 0.2305 Class4: 0.2430 Class5: 0.2353 Class6: 0.2320 \n",
      "Class7: 0.2308 Class8: 0.2257 Class9: 0.2339 Class10: 0.2317 Class11: 0.2377 Class12: 0.2345 \n",
      "Epoch3\n",
      "Train Loss: 52.54110549668134\n",
      "Train mIoU: 0.3203250400292034, Fish_Train_mIoU: 0.23361989944521053\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "275it [03:04,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.3656 Class1: 0.3693 Class2: 0.3742 Class3: 0.3773 Class4: 0.3726 Class5: 0.3831 Class6: 0.3969 \n",
      "Class7: 0.3905 Class8: 0.3818 Class9: 0.3701 Class10: 0.3661 Class11: 0.3808 Class12: 0.3750 \n",
      "--IoU Scores Fish Train--\n",
      "Class0: 0.3038 Class1: 0.3042 Class2: 0.3222 Class3: 0.3248 Class4: 0.3321 Class5: 0.3129 Class6: 0.3452 \n",
      "Class7: 0.3326 Class8: 0.3283 Class9: 0.3303 Class10: 0.3379 Class11: 0.3303 Class12: 0.3264 \n",
      "Epoch4\n",
      "Train Loss: 51.75123511574485\n",
      "Train mIoU: 0.37716566800335527, Fish_Train_mIoU: 0.3254616718206332\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:18,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores val--\n",
      "Class0: 0.2389 Class1: 0.2643 Class2: 0.2366 Class3: 0.2469 Class4: 0.2455 Class5: 0.2771 Class6: 0.2572 \n",
      "Class7: 0.2374 Class8: 0.2535 Class9: 0.2718 Class10: 0.2350 Class11: 0.2568 Class12: 0.2744 \n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.2051 Class1: 0.2371 Class2: 0.2068 Class3: 0.2162 Class4: 0.2234 Class5: 0.2292 Class6: 0.2242 \n",
      "Class7: 0.2170 Class8: 0.2143 Class9: 0.2254 Class10: 0.2179 Class11: 0.2208 Class12: 0.2216 \n",
      "Epoch4\n",
      "Train Loss: 53.70345345190016\n",
      "Train mIoU: 0.2535004711764286, Fish_Train_mIoU: 0.21993511689665957\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "275it [03:02,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.3809 Class1: 0.4006 Class2: 0.3871 Class3: 0.3920 Class4: 0.3889 Class5: 0.3975 Class6: 0.4047 \n",
      "Class7: 0.4008 Class8: 0.4031 Class9: 0.4008 Class10: 0.4155 Class11: 0.3966 Class12: 0.4084 \n",
      "--IoU Scores Fish Train--\n",
      "Class0: 0.3375 Class1: 0.3329 Class2: 0.3447 Class3: 0.3299 Class4: 0.3391 Class5: 0.3307 Class6: 0.3577 \n",
      "Class7: 0.3406 Class8: 0.3418 Class9: 0.3380 Class10: 0.3538 Class11: 0.3471 Class12: 0.3532 \n",
      "Epoch5\n",
      "Train Loss: 51.65214391534979\n",
      "Train mIoU: 0.39822000911352673, Fish_Train_mIoU: 0.34207440180725707\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:18,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores val--\n",
      "Class0: 0.3066 Class1: 0.3330 Class2: 0.2850 Class3: 0.2995 Class4: 0.3059 Class5: 0.3435 Class6: 0.3203 \n",
      "Class7: 0.3136 Class8: 0.3174 Class9: 0.3174 Class10: 0.3022 Class11: 0.3158 Class12: 0.3338 \n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.2342 Class1: 0.2709 Class2: 0.2305 Class3: 0.2343 Class4: 0.2601 Class5: 0.2412 Class6: 0.2534 \n",
      "Class7: 0.2544 Class8: 0.2427 Class9: 0.2519 Class10: 0.2582 Class11: 0.2427 Class12: 0.2468 \n",
      "Epoch5\n",
      "Train Loss: 53.06420057910984\n",
      "Train mIoU: 0.31491306070496294, Fish_Train_mIoU: 0.24779800584823605\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "275it [03:02,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.4133 Class1: 0.4035 Class2: 0.4034 Class3: 0.4073 Class4: 0.4069 Class5: 0.4030 Class6: 0.4098 \n",
      "Class7: 0.4071 Class8: 0.4148 Class9: 0.3918 Class10: 0.4214 Class11: 0.4245 Class12: 0.4119 \n",
      "--IoU Scores Fish Train--\n",
      "Class0: 0.3506 Class1: 0.3425 Class2: 0.3497 Class3: 0.3377 Class4: 0.3410 Class5: 0.3496 Class6: 0.3571 \n",
      "Class7: 0.3443 Class8: 0.3646 Class9: 0.3452 Class10: 0.3520 Class11: 0.3612 Class12: 0.3414 \n",
      "Epoch6\n",
      "Train Loss: 51.583058332963425\n",
      "Train mIoU: 0.4091369957926372, Fish_Train_mIoU: 0.34899080495886775\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:18,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores val--\n",
      "Class0: 0.3344 Class1: 0.3723 Class2: 0.3168 Class3: 0.3349 Class4: 0.3395 Class5: 0.3854 Class6: 0.3548 \n",
      "Class7: 0.3522 Class8: 0.3409 Class9: 0.3492 Class10: 0.3373 Class11: 0.3633 Class12: 0.3537 \n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.2355 Class1: 0.2697 Class2: 0.2217 Class3: 0.2511 Class4: 0.2559 Class5: 0.2505 Class6: 0.2479 \n",
      "Class7: 0.2524 Class8: 0.2402 Class9: 0.2423 Class10: 0.2506 Class11: 0.2432 Class12: 0.2577 \n",
      "Epoch6\n",
      "Train Loss: 52.97718533014847\n",
      "Train mIoU: 0.3488146509949773, Fish_Train_mIoU: 0.24759869081226263\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "275it [03:03,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.4262 Class1: 0.4294 Class2: 0.4325 Class3: 0.4048 Class4: 0.4121 Class5: 0.4415 Class6: 0.4094 \n",
      "Class7: 0.4007 Class8: 0.4268 Class9: 0.4363 Class10: 0.4203 Class11: 0.4349 Class12: 0.4436 \n",
      "--IoU Scores Fish Train--\n",
      "Class0: 0.3660 Class1: 0.3723 Class2: 0.3526 Class3: 0.3516 Class4: 0.3564 Class5: 0.3525 Class6: 0.3506 \n",
      "Class7: 0.3326 Class8: 0.3551 Class9: 0.3499 Class10: 0.3611 Class11: 0.3609 Class12: 0.3729 \n",
      "Epoch7\n",
      "Train Loss: 51.524165094549005\n",
      "Train mIoU: 0.42449333492356967, Fish_Train_mIoU: 0.3565126453032616\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:18,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores val--\n",
      "Class0: 0.3607 Class1: 0.3949 Class2: 0.3384 Class3: 0.3509 Class4: 0.3508 Class5: 0.4082 Class6: 0.3759 \n",
      "Class7: 0.3745 Class8: 0.3556 Class9: 0.3705 Class10: 0.3469 Class11: 0.3794 Class12: 0.3877 \n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.2179 Class1: 0.2668 Class2: 0.2431 Class3: 0.2502 Class4: 0.2607 Class5: 0.2475 Class6: 0.2551 \n",
      "Class7: 0.2507 Class8: 0.2457 Class9: 0.2532 Class10: 0.2506 Class11: 0.2444 Class12: 0.2499 \n",
      "Epoch7\n",
      "Train Loss: 53.477431087170615\n",
      "Train mIoU: 0.36881066344674684, Fish_Train_mIoU: 0.24890212255913752\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "275it [03:03,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.4366 Class1: 0.4309 Class2: 0.4429 Class3: 0.4438 Class4: 0.4198 Class5: 0.4244 Class6: 0.4520 \n",
      "Class7: 0.4356 Class8: 0.4333 Class9: 0.4291 Class10: 0.4399 Class11: 0.4097 Class12: 0.4437 \n",
      "--IoU Scores Fish Train--\n",
      "Class0: 0.3684 Class1: 0.3724 Class2: 0.3646 Class3: 0.3718 Class4: 0.3640 Class5: 0.3690 Class6: 0.3761 \n",
      "Class7: 0.3639 Class8: 0.3685 Class9: 0.3662 Class10: 0.3694 Class11: 0.3550 Class12: 0.3723 \n",
      "Epoch8\n",
      "Train Loss: 51.44958441994407\n",
      "Train mIoU: 0.43397579821946286, Fish_Train_mIoU: 0.36782138014570254\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:18,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores val--\n",
      "Class0: 0.3663 Class1: 0.4026 Class2: 0.3407 Class3: 0.3596 Class4: 0.3528 Class5: 0.4059 Class6: 0.3769 \n",
      "Class7: 0.3671 Class8: 0.3608 Class9: 0.3611 Class10: 0.3490 Class11: 0.3815 Class12: 0.3964 \n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.2586 Class1: 0.3089 Class2: 0.2690 Class3: 0.2689 Class4: 0.2915 Class5: 0.2711 Class6: 0.2898 \n",
      "Class7: 0.2904 Class8: 0.2771 Class9: 0.2787 Class10: 0.2793 Class11: 0.2813 Class12: 0.2672 \n",
      "Epoch8\n",
      "Train Loss: 52.55988964792025\n",
      "Train mIoU: 0.3708166275121986, Fish_Train_mIoU: 0.27938424863027395\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "275it [03:06,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.4511 Class1: 0.4304 Class2: 0.4406 Class3: 0.4525 Class4: 0.4455 Class5: 0.4375 Class6: 0.4488 \n",
      "Class7: 0.4522 Class8: 0.4487 Class9: 0.4508 Class10: 0.4686 Class11: 0.4717 Class12: 0.4536 \n",
      "--IoU Scores Fish Train--\n",
      "Class0: 0.3695 Class1: 0.3652 Class2: 0.3791 Class3: 0.3794 Class4: 0.3733 Class5: 0.3595 Class6: 0.3744 \n",
      "Class7: 0.3720 Class8: 0.3870 Class9: 0.3682 Class10: 0.3849 Class11: 0.3973 Class12: 0.3840 \n",
      "Epoch9\n",
      "Train Loss: 51.38250993208452\n",
      "Train mIoU: 0.4501600560367033, Fish_Train_mIoU: 0.37645357650778755\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:18,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores val--\n",
      "Class0: 0.3705 Class1: 0.3925 Class2: 0.3389 Class3: 0.3732 Class4: 0.3540 Class5: 0.4042 Class6: 0.3622 \n",
      "Class7: 0.3667 Class8: 0.3545 Class9: 0.3832 Class10: 0.3549 Class11: 0.3704 Class12: 0.3919 \n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.2083 Class1: 0.2421 Class2: 0.2177 Class3: 0.2095 Class4: 0.2393 Class5: 0.2104 Class6: 0.2324 \n",
      "Class7: 0.2207 Class8: 0.2236 Class9: 0.2160 Class10: 0.2310 Class11: 0.2162 Class12: 0.2166 \n",
      "Epoch9\n",
      "Train Loss: 52.689392477779066\n",
      "Train mIoU: 0.37053825130295653, Fish_Train_mIoU: 0.2218381059045987\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "275it [02:57,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.4355 Class1: 0.4768 Class2: 0.4680 Class3: 0.4601 Class4: 0.4811 Class5: 0.4719 Class6: 0.4600 \n",
      "Class7: 0.4589 Class8: 0.4594 Class9: 0.4666 Class10: 0.4585 Class11: 0.4274 Class12: 0.4383 \n",
      "--IoU Scores Fish Train--\n",
      "Class0: 0.3670 Class1: 0.3780 Class2: 0.3922 Class3: 0.3781 Class4: 0.3851 Class5: 0.3908 Class6: 0.3936 \n",
      "Class7: 0.3816 Class8: 0.3723 Class9: 0.3850 Class10: 0.3926 Class11: 0.3927 Class12: 0.3823 \n",
      "Epoch10\n",
      "Train Loss: 51.33317481301047\n",
      "Train mIoU: 0.4586333624853177, Fish_Train_mIoU: 0.38394673955663056\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:18,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores val--\n",
      "Class0: 0.3116 Class1: 0.3493 Class2: 0.2981 Class3: 0.3158 Class4: 0.3050 Class5: 0.3531 Class6: 0.3153 \n",
      "Class7: 0.3071 Class8: 0.2983 Class9: 0.3341 Class10: 0.3136 Class11: 0.3307 Class12: 0.3387 \n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.1706 Class1: 0.1977 Class2: 0.1811 Class3: 0.1728 Class4: 0.1964 Class5: 0.1864 Class6: 0.1966 \n",
      "Class7: 0.1708 Class8: 0.1926 Class9: 0.1849 Class10: 0.2069 Class11: 0.1780 Class12: 0.1892 \n",
      "Epoch10\n",
      "Train Loss: 53.64627295025324\n",
      "Train mIoU: 0.3208193601082262, Fish_Train_mIoU: 0.1864645563698246\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "#torch.cuda.empty_cache()\n",
    "#import wandb\n",
    "\n",
    "\n",
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"practice_10_06\",\n",
    "    \n",
    "#     # track hyperparameters and run metadata\n",
    "#     config={\n",
    "#     \"learning_rate\": LR,\n",
    "#     \"architecture\": \"CNN\",\n",
    "#     \"dataset\": \"Samsung\",\n",
    "#     \"epochs\": EP,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "for epoch in range(EP):\n",
    "    # 클래스별 IoU를 누적할 리스트 초기화\n",
    "    train_class_ious = []\n",
    "    fish_train_class_ious = []\n",
    "    # 학습\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for source_data, target_data in tqdm(zip(source_dataloader, target_dataloader)):\n",
    "\n",
    "        source_images = source_data[0].float().to(device)\n",
    "        source_masks = source_data[1].long().to(device)\n",
    "        target_images = target_data[0].float().to(device)\n",
    "        target_masks = target_data[1].long().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        source_outputs = model(source_images)\n",
    "        target_outputs = model(target_images)\n",
    "\n",
    "        source_loss = loss_fn(source_outputs, source_masks, 0, alpha = ALPHA)\n",
    "        target_loss = loss_fn(target_outputs, target_masks, 1, alpha = ALPHA)\n",
    "\n",
    "        loss = source_loss + target_loss\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "                # train 클래스별 IoU 계산\n",
    "        source_outputs = torch.softmax(source_outputs[0], dim=1).cpu()\n",
    "        source_outputs = torch.argmax(source_outputs, dim=1).numpy()\n",
    "\n",
    "        for class_id in range(N_CLASSES):\n",
    "            iou = calculate_iou_per_class(np.array(source_masks.cpu()), np.array(source_outputs), class_id)\n",
    "            train_class_ious.append(iou)\n",
    "\n",
    "        target_outputs = torch.softmax(target_outputs[0], dim=1).cpu()\n",
    "        target_outputs = torch.argmax(target_outputs, dim=1).numpy()\n",
    "\n",
    "        for class_id in range(N_CLASSES):\n",
    "            iou = calculate_iou_per_class(np.array(target_masks.cpu()), np.array(target_outputs), class_id)\n",
    "            fish_train_class_ious.append(iou)\n",
    "\n",
    "    train_class_ious = np.array(train_class_ious).reshape(N_CLASSES, -1)\n",
    "    train_class_ious = np.mean(train_class_ious, axis=1)\n",
    "    print(\"--IoU Scores Train--\")\n",
    "    for class_id, iou in enumerate(train_class_ious):\n",
    "        print(f'Class{class_id}: {iou:.4f}', end=\" \")\n",
    "        if (class_id+1) % 7 == 0:\n",
    "            print()\n",
    "\n",
    "    fish_train_class_ious = np.array(fish_train_class_ious).reshape(N_CLASSES, -1)\n",
    "    fish_train_class_ious = np.mean(fish_train_class_ious, axis=1)\n",
    "    print()\n",
    "    print(\"--IoU Scores Fish Train--\")\n",
    "    for class_id, iou in enumerate(fish_train_class_ious):\n",
    "        print(f'Class{class_id}: {iou:.4f}', end=\" \")\n",
    "        if (class_id+1) % 7 == 0:\n",
    "            print()\n",
    "\n",
    "    # mIoU 계산\n",
    "    train_mIoU = np.mean(train_class_ious)\n",
    "    fish_train_mIoU = np.mean(fish_train_class_ious)\n",
    "\n",
    "    # 에폭마다 결과 출력 \n",
    "    print(f\"\\nEpoch{epoch+1}\")\n",
    "    print(f\"Train Loss: {(epoch_loss/len(source_dataloader))}\")\n",
    "    print(f\"Train mIoU: {train_mIoU}, Fish_Train_mIoU: {fish_train_mIoU}\" )\n",
    "    print(\"___________________________________________________________________________________________\\n\")\n",
    "\n",
    "\n",
    "    ################################################################\n",
    "    # 클래스별 IoU를 누적할 리스트 초기화\n",
    "    val_class_ious = []\n",
    "    fish_val_class_ious = []\n",
    "    epoch_loss = 0\n",
    "    # 학습\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        for source_data, target_data in tqdm(zip(val_source_dataloader, val_target_dataloader)):\n",
    "\n",
    "            source_images = source_data[0].float().to(device)\n",
    "            source_masks = source_data[1].long().to(device)\n",
    "            target_images = target_data[0].float().to(device)\n",
    "            target_masks = target_data[1].long().to(device)\n",
    "\n",
    "            source_outputs = model(source_images)\n",
    "            target_outputs = model(target_images)\n",
    "\n",
    "            source_loss = loss_fn(source_outputs, source_masks, 0, alpha = ALPHA)\n",
    "            target_loss = loss_fn(target_outputs, target_masks, 1, alpha = ALPHA)\n",
    "\n",
    "            loss = source_loss + target_loss\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # train 클래스별 IoU 계산\n",
    "            source_outputs = torch.softmax(source_outputs[0], dim=1).cpu()\n",
    "            source_outputs = torch.argmax(source_outputs, dim=1).numpy()\n",
    "\n",
    "            for class_id in range(N_CLASSES):\n",
    "                iou = calculate_iou_per_class(np.array(source_masks.cpu()), np.array(source_outputs), class_id)\n",
    "                val_class_ious.append(iou)\n",
    "\n",
    "            target_outputs = torch.softmax(target_outputs[0], dim=1).cpu()\n",
    "            target_outputs = torch.argmax(target_outputs, dim=1).numpy()\n",
    "\n",
    "            for class_id in range(N_CLASSES):\n",
    "                iou = calculate_iou_per_class(np.array(target_masks.cpu()), np.array(target_outputs), class_id)\n",
    "                fish_val_class_ious.append(iou)\n",
    "\n",
    "    val_class_ious = np.array(val_class_ious).reshape(N_CLASSES, -1)\n",
    "    val_class_ious = np.mean(val_class_ious, axis=1)\n",
    "    print(\"--IoU Scores val--\")\n",
    "    for class_id, iou in enumerate(val_class_ious):\n",
    "        print(f'Class{class_id}: {iou:.4f}', end=\" \")\n",
    "        if (class_id+1) % 7 == 0:\n",
    "            print()\n",
    "\n",
    "    fish_val_class_ious = np.array(fish_val_class_ious).reshape(N_CLASSES, -1)\n",
    "    fish_val_class_ious = np.mean(fish_val_class_ious, axis=1)\n",
    "    print()\n",
    "    print(\"--IoU Scores Fish val--\")\n",
    "    for class_id, iou in enumerate(fish_val_class_ious):\n",
    "        print(f'Class{class_id}: {iou:.4f}', end=\" \")\n",
    "        if (class_id+1) % 7 == 0:\n",
    "            print()\n",
    "\n",
    "    # mIoU 계산\n",
    "    val_mIoU = np.mean(val_class_ious)\n",
    "    fish_val_mIoU = np.mean(fish_val_class_ious)\n",
    "\n",
    "    # 에폭마다 결과 출력 \n",
    "    print(f\"\\nEpoch{epoch+1}\")\n",
    "    print(f\"Train Loss: {(epoch_loss/len(val_source_dataloader))}\")\n",
    "    print(f\"Train mIoU: {val_mIoU}, Fish_Train_mIoU: {fish_val_mIoU}\" )\n",
    "    print(\"___________________________________________________________________________________________\\n\")\n",
    "\n",
    "#     # log metrics to wandb\n",
    "#     wandb.log({\"train score\": train_mIoU, \"train loss\": epoch_loss})\n",
    "#     wandb.log({\"val score\": val_mIoU, \"val loss\": val_loss})\n",
    "    \n",
    "    \n",
    "# # [optional] finish the wandb run, necessary in notebooks\n",
    "# wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byungwan_resn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
