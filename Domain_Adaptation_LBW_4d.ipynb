{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/MMI24limbyungwan/.conda/envs/byungwan_resn/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "#from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# GPU 사용이 가능할 경우, GPU를 사용할 수 있게 함.'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "print(device)\n",
    "\n",
    "print(os.environ.get('CUDA_VISIBLE_DEVICES'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "# 클래스별 IoU를 계산하기 위한 함수\n",
    "def calculate_iou_per_class(y_true, y_pred, class_id):\n",
    "    intersection = np.sum((y_true == class_id) & (y_pred == class_id))\n",
    "    union = np.sum((y_true == class_id) | (y_pred == class_id))\n",
    "    iou = intersection / union if union > 0 else 0\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "def apply_fisheye_distortion(images, masks, label):\n",
    "    # 이미지 크기 가져오기\n",
    "    batch, channel, height, width = images.shape\n",
    "\n",
    "    # 카메라 매트릭스 생성\n",
    "    focal_length = width / 4\n",
    "    center_x = width / 2\n",
    "    center_y = height / 2\n",
    "    camera_matrix = np.array([[focal_length, 0, center_x],\n",
    "                              [0, focal_length, center_y],\n",
    "                              [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "    # 왜곡 계수 생성\n",
    "    # dist_num = 0\n",
    "    # if label == 1:\n",
    "    #     dist_num = random.randint(1,3)\n",
    "    # elif label == 2.5:\n",
    "    #     dist_num = 2.5\n",
    "    dist_num = label\n",
    "    dist_coeffs = np.array([0, 0.1 * dist_num, 0, 0], dtype=np.float32)\n",
    "\n",
    "    # 왜곡 보정\n",
    "    undistorted_images = []\n",
    "    undistorted_masks = []\n",
    "\n",
    "    for i in range(batch):\n",
    "        image = images[i].permute(1, 2, 0).cpu().numpy()  # 텐서를 NumPy 배열로 변환\n",
    "        mask = masks[i].cpu().numpy()\n",
    "        undistorted_image = cv2.undistort(image, camera_matrix, dist_coeffs)\n",
    "        undistorted_mask = cv2.undistort(mask, camera_matrix, dist_coeffs)\n",
    "        undistorted_mask = np.round(undistorted_mask).astype(np.uint8)\n",
    "        undistorted_mask[undistorted_mask > 12] = 12\n",
    "\n",
    "        # 다시 텐서로 변환\n",
    "        undistorted_image = torch.from_numpy(undistorted_image).permute(2, 0, 1).float().to(device)\n",
    "        undistorted_mask = torch.from_numpy(undistorted_mask).long().to(device)\n",
    "\n",
    "        undistorted_images.append(undistorted_image)\n",
    "        undistorted_masks.append(undistorted_mask)\n",
    "\n",
    "    undistorted_images = torch.stack(undistorted_images, dim=0)\n",
    "    undistorted_masks = torch.stack(undistorted_masks, dim=0)\n",
    "\n",
    "    return undistorted_images, undistorted_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # 이미지 데이터 (batch, channel, height, width)\n",
    "# image_data = torch.randn(4, 3, 256, 256)\n",
    "\n",
    "# # 이미지 차원 변경 (batch, height, width, channel)\n",
    "# image_data_permuted = image_data.permute(0, 2, 3, 1)\n",
    "\n",
    "# # 이미지 크기 확인\n",
    "# print(image_data_permuted.shape)\n",
    "\n",
    "# # 4개의 이미지로 나누기\n",
    "# images = image_data_permuted.split(1, dim=0)\n",
    "# # 또는 images = torch.split(image_data_permuted, 1, dim=0)\n",
    "# undistorted_images = []\n",
    "# # 4개 이미지의 크기 확인\n",
    "# for i, image in enumerate(images):\n",
    "#     print(f\"Image {i + 1} shape: {image.shape}\")\n",
    "#     undistorted_images.append(images[i].squeeze())\n",
    "\n",
    "# undistorted_images2 = torch.stack(undistorted_images, dim=0)\n",
    "# undistorted_images3 = undistorted_images2.permute(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #directory_path = \"/mnt/nas27/Dataset/Samsung_DM\"\n",
    "        directory_path = './data/224'\n",
    "        img_path = self.data.iloc[idx, 1]\n",
    "        img_path = os.path.join(directory_path, img_path)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "        \n",
    "        mask_path = self.data.iloc[idx, 2]\n",
    "        mask_path = os.path.join(directory_path, mask_path)\n",
    "        mask = cv2.imread(mask_path)\n",
    "        #mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        mask = np.round(mask).astype(np.uint8)\n",
    "        mask[mask > 12] = 12 #배경을 픽셀값 12로 간주\n",
    "        mask += 1\n",
    "        mask[mask == 13] = 0\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# class CustomDataset_target(Dataset):\n",
    "#     def __init__(self, csv_file, transform=None, infer=False):\n",
    "#         self.data = pd.read_csv(csv_file)\n",
    "#         self.transform = transform\n",
    "#         self.infer = infer\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         directory_path = \"/mnt/nas27/Dataset/Samsung_DM\"\n",
    "#         img_path = self.data.iloc[idx, 1]\n",
    "#         img_path = os.path.join(directory_path, img_path[2:])\n",
    "#         image = cv2.imread(img_path)\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "#         if self.infer:\n",
    "#             if self.transform:\n",
    "#                 image = self.transform(image=image)['image']\n",
    "#             return image\n",
    "\n",
    "\n",
    "#         if self.transform:\n",
    "#             augmented = self.transform(image=image)\n",
    "#             image = augmented['image']\n",
    "            \n",
    "\n",
    "#         return image\n",
    "     \n",
    "\n",
    "transform = A.Compose(\n",
    "    [   \n",
    "        #A.Resize(224, 224),\n",
    "        #A.Resize(128, 128),\n",
    "        A.Normalize(),\n",
    "        \n",
    "        # 변형\n",
    "        # A.VerticalFlip(p=0.5),\n",
    "        # A.RandomRotate90(p=0.5),\n",
    "        # A.HueSaturationValue(p=0.2),\n",
    "        \n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Unet의 기본이 되는 conv블럭\n",
    "# class ConvBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(ConvBlock, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "#         self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "        \n",
    "#         self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)  # 여기서 in_channels는 out_channels와 동일해야 합니다.\n",
    "#         self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.relu1(x)\n",
    "        \n",
    "#         x = self.conv2(x)\n",
    "#         x = self.bn2(x)\n",
    "#         x = self.relu2(x)\n",
    "#         return x\n",
    "\n",
    "# #인코더 블럭\n",
    "# class EncoderBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(EncoderBlock,self).__init__()\n",
    "#         self.convblock1 = ConvBlock(in_channels, out_channels)  # 첫 번째 ConvBlock의 in_channels는 입력 이미지의 채널 수와 일치해야 합니다.\n",
    "#         #self.convblock2 = ConvBlock(out_channels, out_channels)  # 두 번째 ConvBlock의 in_channels는 out_channels와 일치해야 합니다.\n",
    "#         self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "#     def forward(self,x):\n",
    "#         x = self.convblock1(x)\n",
    "#         #x = self.convblock2(x)\n",
    "#         p = self.maxpool(x)\n",
    "#         return x , p\n",
    "# #디코더 블럭\n",
    "# #디코더는 업샘플링 이후 스킵연결과 붙어서 convblock을 통과해야함\n",
    "# #skip보다 작은 x x먼저 업샘플링 32 -> 64 , skip과 결합 6464 \n",
    "# class DecoderBlock(nn.Module):\n",
    "#     def __init__(self, channels):\n",
    "#         super(DecoderBlock,self).__init__()\n",
    "#         self.upsample = nn.ConvTranspose2d(channels*2, channels, kernel_size=4, stride=2, padding=1)#x 업샘플링\n",
    "#         self.convblock1 = ConvBlock(channels*2, channels)#차원감소\n",
    "#         #self.convblock2 = ConvBlock(channels, channels)\n",
    "#     def forward(self,x,skip):\n",
    "#         x = self.upsample(x)\n",
    "#         x = torch.cat([x, skip], dim=1)\n",
    "#         x = self.convblock1(x)\n",
    "#         #x = self.convblock2(x)\n",
    "#         return x\n",
    "\n",
    "# ###########################################\n",
    "# class GradReverse(torch.autograd.Function):\n",
    "#     @staticmethod\n",
    "#     def forward(self, x):\n",
    "#         return x.view_as(x)\n",
    "#     @staticmethod\n",
    "#     def backward(self, grad_output): # 역전파 시에 gradient에 음수를 취함\n",
    "#         return (grad_output * -1)\n",
    "\n",
    "# class domain_classifier(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(domain_classifier, self).__init__()\n",
    "#         self.fc1 = nn.Linear(224*224*64, 10)\n",
    "#         self.fc2 = nn.Linear(10, 4) # source = 0, target = 1 회귀 가정\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.view(-1, 224*224*64)\n",
    "#         x = GradReverse.apply(x) # gradient reverse\n",
    "#         x = F.leaky_relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "        \n",
    "#         return x\n",
    "\n",
    "# ###########################################\n",
    "\n",
    "\n",
    "# #Unet구조 middle의 xm값의 움직임에 주의\n",
    "# class Unet(nn.Module):\n",
    "#     def __init__(self,n_classes):\n",
    "#         super(Unet,self).__init__()\n",
    "#         self.encoder1 = EncoderBlock(3,64)\n",
    "#         self.encoder2 = EncoderBlock(64,128)\n",
    "#         self.encoder3 = EncoderBlock(128,256)\n",
    "#         self.encoder4 = EncoderBlock(256,512)\n",
    "        \n",
    "#         self.middleconv = ConvBlock(512,1024)\n",
    "        \n",
    "        \n",
    "#         self.decoder4 = DecoderBlock(512)\n",
    "#         self.decoder3 = DecoderBlock(256)\n",
    "#         self.decoder2 = DecoderBlock(128)\n",
    "#         self.decoder1 = DecoderBlock(64)\n",
    "#         self.segmap = nn.Conv2d(64,n_classes, kernel_size=1)\n",
    "        \n",
    "#         self.domain_classifier = domain_classifier()\n",
    "                                        \n",
    "\n",
    "#     def forward(self,x):\n",
    "#         x1,p = self.encoder1(x)#3->64   #P:256,256 x1 :512,512\n",
    "#         x2,p = self.encoder2(p)#64->128 #P:128,128 x2:256,256\n",
    "#         x3,p = self.encoder3(p)#128->256#p:64,64 x3:128,128\n",
    "#         x4,p = self.encoder4(p)#256->512#p:32,32 x4:64,64\n",
    "        \n",
    "#         xm = self.middleconv(p)#512->1024#32,32\n",
    "        \n",
    "#         x = self.decoder4(xm,x4)#뉴런:1024->512->512 #출력tensor:64,64\n",
    "#         x = self.decoder3(x,x3)#뉴런:512->256->256 #출력tensor:128,128\n",
    "#         x = self.decoder2(x,x2)#뉴런:256->128->128 #출력tensor:256,256\n",
    "#         x = self.decoder1(x,x1)#뉴런:128->64->64 #출력tensor:512,512\n",
    "\n",
    "#         x_c = self.segmap(x)\n",
    "#         x_d = self.domain_classifier(x)\n",
    "#         # print(\"x_c\", x_c.shape)\n",
    "#         # print(\"x_d\", x_d.shape)\n",
    "#         return x_c, x_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GradReverse(torch.autograd.Function):\n",
    "#     @staticmethod\n",
    "#     def forward(self, x):\n",
    "#         return x.view_as(x)\n",
    "#     @staticmethod\n",
    "#     def backward(self, grad_output): # 역전파 시에 gradient에 음수를 취함\n",
    "#         return grad_output * (-1)\n",
    "\n",
    "# class domain_classifier(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(domain_classifier, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(128, 1, kernel_size=1)\n",
    "#         self.fc1 = nn.Linear(224*224*1, 10)\n",
    "#         self.fc2 = nn.Linear(10, 4) # source = 0, target = 1 회귀 가정\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = x.view(-1, 224*224*1)\n",
    "#         #print(x.shape)\n",
    "#         x = GradReverse.apply(x) # gradient reverse\n",
    "#         x = F.leaky_relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         #print(x.shape)\n",
    "#         #return torch.sigmoid(x)\n",
    "#         return x\n",
    "\n",
    "# #Unet의 기본이 되는 conv블럭\n",
    "# class ConvBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels,kernel_size = 3):\n",
    "#         super(ConvBlock, self).__init__()\n",
    "#         self.kernel_size = kernel_size\n",
    "#         self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=1)\n",
    "#         self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "        \n",
    "#         self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, padding=1)  # 여기서 in_channels는 out_channels와 동일해야 합니다.\n",
    "#         self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.relu1(x)\n",
    "        \n",
    "#         x = self.conv2(x)\n",
    "#         x = self.bn2(x)\n",
    "#         x = self.relu2(x)\n",
    "#         return x\n",
    "# class IdentityBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, mid_channels, out_channels, stride=1):\n",
    "#         super(IdentityBlock, self).__init__()\n",
    "        \n",
    "#         # 1x1 convolution\n",
    "#         self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=1, stride=stride, bias=False)\n",
    "#         self.bn1 = nn.BatchNorm2d(mid_channels)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "\n",
    "#         # 3x3 convolution\n",
    "#         self.conv2 = nn.Conv2d(mid_channels, mid_channels, kernel_size=3, padding=1, bias=False)\n",
    "#         self.bn2 = nn.BatchNorm2d(mid_channels)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "\n",
    "#         # 1x1 convolution\n",
    "#         self.conv3 = nn.Conv2d(mid_channels, out_channels, kernel_size=1, bias=False)\n",
    "#         self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "#         self.relu3 = nn.ReLU()\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         out = self.conv1(x)\n",
    "#         out = self.bn1(out)\n",
    "#         out = self.relu1(out)\n",
    "        \n",
    "#         out = self.conv2(out)\n",
    "#         out = self.bn2(out)\n",
    "#         out = self.relu2(out)\n",
    "         \n",
    "#         out = self.conv3(out)\n",
    "#         out = self.bn3(out)\n",
    "#         out = self.relu3(out)\n",
    "        \n",
    "#         return out\n",
    "# class HeadBlock(IdentityBlock):\n",
    "#     def __init__(self, in_channels, mid_channels, out_channels, stride=1):\n",
    "#         super(HeadBlock, self).__init__(in_channels, mid_channels, out_channels, stride)\n",
    "        \n",
    "#         self.shortcut = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "#             nn.BatchNorm2d(out_channels)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         identity = x\n",
    "#         out = super().forward(x)\n",
    "        \n",
    "#         if identity.size() != out.size():\n",
    "#             identity = F.interpolate(identity, size=out.size()[2:])\n",
    "#         identity = self.shortcut(identity)\n",
    "        \n",
    "#         out += identity\n",
    "#         out = self.relu3(out)\n",
    "        \n",
    "#         return out\n",
    "# #인코더 블럭\n",
    "# class Conv2(nn.Module):\n",
    "#     def __init__(self,in_channels, mid_channels, out_channels):\n",
    "#         super(Conv2,self).__init__() \n",
    "#         self.headblock = HeadBlock(in_channels,mid_channels,out_channels)\n",
    "#         self.identityblock1 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "#         self.identityblock2 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "#     def forward(self,x):\n",
    "#         x = self.headblock(x)\n",
    "#         x = self.identityblock1(x)\n",
    "#         x = self.identityblock2(x)\n",
    "#         p = self.maxpool(x)\n",
    "#         return x , p\n",
    "# class Conv3(nn.Module):\n",
    "#     def __init__(self,in_channels, mid_channels, out_channels):\n",
    "#         super(Conv3,self).__init__() \n",
    "#         self.headblock = HeadBlock(in_channels,mid_channels,out_channels)\n",
    "#         self.identityblock1 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "#         self.identityblock2 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "#         self.identityblock3 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "#     def forward(self,x):\n",
    "#         x = self.headblock(x)\n",
    "#         x = self.identityblock1(x)\n",
    "#         x = self.identityblock2(x)\n",
    "#         x = self.identityblock3(x)\n",
    "#         p = self.maxpool(x)\n",
    "#         return x , p\n",
    "# class Conv4(nn.Module):\n",
    "#     def __init__(self,in_channels, mid_channels, out_channels):\n",
    "#         super(Conv4,self).__init__() \n",
    "#         self.headblock = HeadBlock(in_channels,mid_channels,out_channels)\n",
    "#         self.identityblock1 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "#         self.identityblock2 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "#         self.identityblock3 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "#         self.identityblock4 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "#         self.identityblock5 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "#     def forward(self,x):\n",
    "#         x = self.headblock(x)\n",
    "#         x = self.identityblock1(x)\n",
    "#         x = self.identityblock2(x)\n",
    "#         x = self.identityblock3(x)\n",
    "#         x = self.identityblock4(x)\n",
    "#         x = self.identityblock5(x)\n",
    "#         p = self.maxpool(x)\n",
    "#         return x , p\n",
    "# class Conv5(nn.Module):\n",
    "#     def __init__(self,in_channels, mid_channels, out_channels):\n",
    "#         super(Conv5,self).__init__() \n",
    "#         self.headblock = HeadBlock(in_channels,mid_channels,out_channels)\n",
    "#         self.identityblock1 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "#         self.identityblock2 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "#     def forward(self,x):\n",
    "#         x = self.headblock(x)\n",
    "#         x = self.identityblock1(x)\n",
    "#         x = self.identityblock2(x)\n",
    "#         p = self.maxpool(x)\n",
    "#         return x , p\n",
    "# #디코더 블럭\n",
    "# class DecoderBlock(nn.Module):\n",
    "#     def __init__(self, channels):\n",
    "#         super(DecoderBlock, self).__init__()\n",
    "#         self.upsample = nn.ConvTranspose2d(channels*2, channels, kernel_size=4, stride=2, padding=1, output_padding=1) # output_padding 추가\n",
    "#         self.convblock1 = ConvBlock(channels*2, channels)\n",
    "\n",
    "#     def forward(self, x, skip):\n",
    "#         x = self.upsample(x)\n",
    "#         if x.size(2) != skip.size(2) or x.size(3) != skip.size(3):\n",
    "#             x = F.interpolate(x, size=(skip.size(2), skip.size(3)))\n",
    "#         x = torch.cat([x, skip], dim=1)\n",
    "#         x = self.convblock1(x)\n",
    "#         return x\n",
    "\n",
    "# #Unet구조 middle의 xm값의 움직임에 주의\n",
    "# class Resnet50_Unet(nn.Module):\n",
    "#     def __init__(self,n_classes):\n",
    "#         super(Resnet50_Unet,self).__init__()\n",
    "#         self.fconv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2)\n",
    "#         self.fbn1 = nn.BatchNorm2d(64)\n",
    "#         self.frelu1 = nn.ReLU()\n",
    "#         self.fconv2 = nn.Conv2d(64, 128, kernel_size=1, stride=1)\n",
    "#         self.fbn2 = nn.BatchNorm2d(128)\n",
    "#         self.frelu2 = nn.ReLU()\n",
    "#         self.fmaxpooling = nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "        \n",
    "#         self.conv2 = Conv2(128,64,256)\n",
    "#         self.conv3 = Conv3(256,128,512)\n",
    "#         self.conv4 = Conv4(512,256,1024)\n",
    "#         self.conv5 = Conv5(1024,512,2048)\n",
    "        \n",
    "#         self.middleconv = ConvBlock(2048,4096)\n",
    "#         self.dropout = nn.Dropout2d(0.4) #\n",
    "           \n",
    "#         self.decoder5 = DecoderBlock(2048)\n",
    "#         self.decoder4 = DecoderBlock(1024)\n",
    "#         self.decoder3 = DecoderBlock(512)\n",
    "#         self.decoder2 = DecoderBlock(256)\n",
    "#         self.decoder1 = DecoderBlock(128)\n",
    "        \n",
    "#         self.segmap = nn.Conv2d(128,n_classes, kernel_size=1)\n",
    "#         self.domain_classifier = domain_classifier()\n",
    "        \n",
    "#     def forward(self,x):\n",
    "#         x = self.fconv1(x)#3->64\n",
    "#         x = self.fbn1(x)\n",
    "#         x = self.frelu1(x)\n",
    "#         x = self.fconv2(x)\n",
    "#         x = self.fbn2(x)\n",
    "#         x1 = self.frelu2(x)\n",
    "#         p = self.fmaxpooling(x)#첫 conv: x0([8, 64, 109, 109]) p([8, 64, 54, 54])\n",
    "#         x2,p = self.conv2(p)#conv2:  x1:([8, 256, 54, 54]) p([8, 256, 26, 26])\n",
    "#         x3,p = self.conv3(p)#conv3:  x2([8, 512, 26, 26]) p([8, 512, 12, 12])\n",
    "#         x4,p = self.conv4(p)#conv4:  x3([8, 1024, 12, 12]) p([8, 1024, 5, 5])\n",
    "#         x5,p = self.conv5(p)#conv5:  x4([8, 2048, 5, 5]) p([8, 2048, 2, 2])\n",
    "        \n",
    "#         xm = self.middleconv(p)#xm([8, 4096, 2, 2])\n",
    "#         xm = self.dropout(xm)\n",
    "        \n",
    "#         x = self.decoder5(xm,x5)#뉴런:2048*2->2048 1\n",
    "#         x = self.decoder4(x,x4)#뉴런:1024*2->1024 \n",
    "#         x = self.decoder3(x,x3) #14\n",
    "#         x = self.decoder2(x,x2)#28\n",
    "#         x = self.decoder1(x,x1)#55\n",
    "        \n",
    "#         x = F.interpolate(x, size=(224, 224))\n",
    "#         x_c = self.segmap(x)\n",
    "#         x_d = self.domain_classifier(x)\n",
    "#         #print(x.shape)\n",
    "#         return x_c,x_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradReverse(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(self, x):\n",
    "        return x.view_as(x)\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output): # 역전파 시에 gradient에 음수를 취함\n",
    "        return grad_output * (-1)\n",
    "\n",
    "class domain_classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(domain_classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(224*224*64, 10)\n",
    "        self.fc2 = nn.Linear(10, 4) # source = 0, target = 1 회귀 가정\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 224*224*64)\n",
    "        x = GradReverse.apply(x) # gradient reverse\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        #return torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "class IdentityBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(IdentityBlock, self).__init__()\n",
    "        \n",
    "        # 3x3 convolution\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # 3x3 convolution\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # Skip connection\n",
    "        self.skip = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        # Adding the skip connection\n",
    "        out += self.skip(identity)\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "#인코더 블럭\n",
    "class Conv2(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels):\n",
    "        super(Conv2,self).__init__() \n",
    "        self.identityblock1 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock2 = IdentityBlock(in_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
    "    def forward(self,x):\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        p = self.maxpool(x)\n",
    "        \n",
    "        return x , p\n",
    "class Conv3(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels):\n",
    "        super(Conv3,self).__init__()         \n",
    "        self.identityblock1 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock2 = IdentityBlock(in_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
    "    def forward(self,x):\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        p = self.maxpool(x)\n",
    "        \n",
    "        return x , p\n",
    "class Conv4(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels):\n",
    "        super(Conv4,self).__init__()         \n",
    "        self.identityblock1 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock2 = IdentityBlock(in_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
    "    def forward(self,x):\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        p = self.maxpool(x)\n",
    "        \n",
    "        return x , p\n",
    "class Conv5(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels):\n",
    "        super(Conv5,self).__init__() \n",
    "        self.identityblock1 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock2 = IdentityBlock(in_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        p = self.maxpool(x)\n",
    "        \n",
    "        return x , p\n",
    "#디코더 블럭\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.upsample = nn.ConvTranspose2d(channels*2, channels, kernel_size=4, stride=2, padding=1) # output_padding 추가\n",
    "        self.convblock1 = IdentityBlock(channels*2, channels)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = self.upsample(x)\n",
    "        if x.size(2) != skip.size(2) or x.size(3) != skip.size(3):\n",
    "            x = F.interpolate(x, size=(skip.size(2), skip.size(3)))\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.convblock1(x)\n",
    "        #print(\"x\",x.shape,\"skip: \",skip.shape)\n",
    "        return x\n",
    "\n",
    "#Unet구조 middle의 xm값의 움직임에 주의\n",
    "class Resnet18_Unet(nn.Module):\n",
    "    def __init__(self,n_classes):\n",
    "        super(Resnet18_Unet,self).__init__()\n",
    "        self.fconv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.fbn1 = nn.BatchNorm2d(64)\n",
    "        self.frelu1 = nn.ReLU()\n",
    "        self.fmaxpooling = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "        \n",
    "        self.conv2 = Conv2(64,128)\n",
    "        self.conv3 = Conv3(128,256)\n",
    "        self.conv4 = Conv4(256,512)\n",
    "        self.conv5 = Conv5(512,1024)\n",
    "        \n",
    "        self.middleconv = IdentityBlock(1024,2048)\n",
    "        self.dropout = nn.Dropout2d(0.1) #\n",
    "           \n",
    "        self.decoder5 = DecoderBlock(1024)\n",
    "        self.decoder4 = DecoderBlock(512)\n",
    "        self.decoder3 = DecoderBlock(256)\n",
    "        self.decoder2 = DecoderBlock(128)\n",
    "        self.decoder1 = DecoderBlock(64)\n",
    "        self.transpose = nn.ConvTranspose2d(64, 64, kernel_size=4, stride=2, padding=1) # output_padding 추가\n",
    "        \n",
    "        self.segmap = nn.Conv2d(64,n_classes, kernel_size=1)\n",
    "        self.domain_classifier = domain_classifier()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fconv1(x)#3->64\n",
    "        x0 = self.fbn1(x)\n",
    "        x1 = self.frelu1(x)\n",
    "        p = self.fmaxpooling(x1)#첫 conv: x0([8, 64, 109, 109]) p([8, 64, 54, 54])\n",
    "        #print(\"conv1: \",x1.shape, \"maxpooling: \",p.shape)\n",
    "        x2,p = self.conv2(p)\n",
    "        #print(\"conv2: \",x2.shape, \"maxpooling: \",p.shape)\n",
    "        x3,p = self.conv3(p)\n",
    "        #print(\"conv3: \",x3.shape, \"maxpooling: \",p.shape)\n",
    "        x4,p = self.conv4(p)\n",
    "        #print(\"conv4: \",x4.shape, \"maxpooling: \",p.shape)\n",
    "        x5,p = self.conv5(p)\n",
    "        #print(\"conv5: \",x5.shape, \"maxpooling: \",p.shape)\n",
    "        \n",
    "        xm = self.middleconv(p)#xm([8, 4096, 2, 2])\n",
    "        #print(\"xm: \",xm.shape, \"maxpooling: \",p.shape)\n",
    "        xm = self.dropout(xm)\n",
    "        \n",
    "        x = self.decoder5(xm,x5)#뉴런:2048*2->2048 1\n",
    "        x = self.decoder4(x,x4)#뉴런:1024*2->1024 \n",
    "        x = self.decoder3(x,x3) #14\n",
    "        x = self.decoder2(x,x2)#28\n",
    "        x = self.decoder1(x,x1)#55\n",
    "        x = self.transpose(x)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        #x = F.interpolate(x, size=(224, 224))\n",
    "        x_c = self.segmap(x)\n",
    "        x_d = self.domain_classifier(x)\n",
    "        \n",
    "        return x_c,x_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # 저장된 class_weights를 불러옵니다.\n",
    "# class_weights_path = 'CLASS_WEIGHTS.pkl'\n",
    "\n",
    "# with open(class_weights_path, 'rb') as file:\n",
    "#     CLASS_WEIGHTS = pickle.load(file)\n",
    "\n",
    "# print(CLASS_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function과 optimizer 정의\n",
    "\n",
    "class DANN_Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DANN_Loss, self).__init__()\n",
    "\n",
    "        #self.CE = nn.CrossEntropyLoss(weight=CLASS_WEIGHTS) # 0~9 class 분류용\n",
    "        self.CE = nn.CrossEntropyLoss()\n",
    "        #self.BCE = nn.BCELoss() # 도메인 분류용\n",
    "        \n",
    "    # result : DANN_CNN에서 반환된 값\n",
    "    # label : 숫자 0 ~ 9에 대한 라벨\n",
    "    # domain_num : 0(source) or 1(target)\n",
    "    def forward(self, result, label, domain_num, alpha = 1):\n",
    "        label_logits, domain_logits = result # DANN_CNN의 결과\n",
    "\n",
    "        batch_size = domain_logits.shape[0]\n",
    "\n",
    "        # print(\"segment_mask : \", label.shape)\n",
    "        # print(\"domain_answer : \", domain_target.shape)\n",
    "        segment_loss = self.CE(label_logits, label) # class 분류 loss\n",
    "\n",
    "        # domain_target = torch.FloatTensor([domain_num] * batch_size).unsqueeze(1).to(device)\n",
    "        # domain_loss = self.BCE(domain_logits, domain_target)\n",
    "\n",
    "        domain_target = torch.LongTensor([domain_num] * batch_size).to(device)\n",
    "        domain_loss = self.CE(domain_logits, domain_target) # domain 분류 loss\n",
    "        \n",
    "        loss = segment_loss + alpha * domain_loss\n",
    "\n",
    "        return loss, segment_loss, domain_loss\n",
    "    \n",
    "\n",
    "loss_fn = DANN_Loss().to(device)\n",
    "\n",
    "#criterion =nn.CrossEntropyLoss()\n",
    "#domain_criterion = nn.BCELoss()\n",
    "#criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "EP = 25\n",
    "BATCH_SIZE = 16\n",
    "ACCMULATION_STEP = 1 \n",
    "N_CLASSES = 13 #IoU 점수측정하기 위한 클래스의 개수\n",
    "ALPHA = 0.5\n",
    "# model 초기화\n",
    "model = Resnet18_Unet(n_classes = N_CLASSES).to(device)\n",
    "#model = Resnet50_Unet(n_classes = N_CLASSES).to(device)\n",
    "#model = Unet(n_classes = N_CLASSES).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "optimizer.zero_grad() \n",
    "\n",
    "source_dataset = CustomDataset(csv_file='./data/896_csv/train_source.csv', transform=transform)\n",
    "source_dataloader = DataLoader(source_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_target_dataset = CustomDataset(csv_file='./data/896_csv/val_source.csv', transform=transform)\n",
    "val_target_dataloader = DataLoader(val_target_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# a1 = pd.read_csv(\"./data/6_fish_source.csv\")\n",
    "# p = \"./data/224/\"\n",
    "# a2 = os.path.join(p, a1.iloc[3,2])\n",
    "# a3 = cv2.imread(a2)\n",
    "# a4 = cv2.cvtColor(a3, cv2.COLOR_BGR2GRAY)\n",
    "# a4 = np.round(a4).astype(np.uint8)\n",
    "# a5 = a4*20\n",
    "\n",
    "# plt.imshow(a5, cmap='gray')\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# #torch.cuda.empty_cache()\n",
    "# # import wandb\n",
    "\n",
    "\n",
    "# # wandb.init(\n",
    "# #     # set the wandb project where this run will be logged\n",
    "# #     project=\"practice_10_27_4d_res18\",\n",
    "    \n",
    "# #     # track hyperparameters and run metadata\n",
    "# #     config={\n",
    "# #     \"learning_rate\": LR,\n",
    "# #     \"architecture\": \"CNN\",\n",
    "# #     \"dataset\": \"Samsung\",\n",
    "# #     \"epochs\": EP,\n",
    "# #     }\n",
    "# # )\n",
    "\n",
    "# for epoch in range(EP):\n",
    "#     # 클래스별 IoU를 누적할 리스트 초기화\n",
    "#     train_class_ious = []\n",
    "#     fish_train_class_ious = []\n",
    "#     # 학습\n",
    "#     model.train()\n",
    "#     epoch_loss = 0\n",
    "#     seg_loss = 0\n",
    "#     dom_loss = 0\n",
    "\n",
    "#     for source_images, source_masks in tqdm(source_dataloader):\n",
    "#         label = random.randint(0,3)\n",
    "#         source_images, source_masks = apply_fisheye_distortion(source_images, source_masks, label)\n",
    "#         source_images = source_images.float().to(device)\n",
    "#         source_masks = source_masks.long().to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         source_outputs = model(source_images)\n",
    "\n",
    "#         source_loss, segment_loss, domain_loss = loss_fn(source_outputs, source_masks, label, alpha = ALPHA)\n",
    "\n",
    "#         loss = source_loss\n",
    "#         epoch_loss += loss.item()\n",
    "#         seg_loss += segment_loss.item()\n",
    "#         dom_loss += domain_loss.item()\n",
    "\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         #scheduler.step()\n",
    "#                 # train 클래스별 IoU 계산\n",
    "#         source_outputs = torch.softmax(source_outputs[0], dim=1).cpu()\n",
    "#         source_outputs = torch.argmax(source_outputs, dim=1).numpy()\n",
    "\n",
    "#         for class_id in range(N_CLASSES):\n",
    "#             iou = calculate_iou_per_class(np.array(source_masks.cpu()), np.array(source_outputs), class_id)\n",
    "#             train_class_ious.append(iou)\n",
    "\n",
    "#     train_class_ious = np.array(train_class_ious).reshape(N_CLASSES, -1)\n",
    "#     train_class_ious = np.mean(train_class_ious, axis=1)\n",
    "#     print(\"--IoU Scores Train--\")\n",
    "#     for class_id, iou in enumerate(train_class_ious):\n",
    "#         print(f'Class{class_id}: {iou:.4f}', end=\" \")\n",
    "#         if (class_id+1) % 7 == 0:\n",
    "#             print()\n",
    "\n",
    "#     # mIoU 계산\n",
    "#     train_mIoU = np.mean(train_class_ious)\n",
    "\n",
    "#     # 에폭마다 결과 출력 \n",
    "#     print(f\"\\nEpoch{epoch+1}\")\n",
    "#     print(f\"Train seg Loss: {(seg_loss/len(source_dataloader))}\")\n",
    "#     print(f\"Train dom Loss: {(dom_loss/len(source_dataloader))}\")\n",
    "#     print(f\"Train Loss: {(epoch_loss/len(source_dataloader))}\")\n",
    "#     print(f\"Train mIoU: {train_mIoU}\" )\n",
    "#     print(\"___________________________________________________________________________________________\\n\")\n",
    "\n",
    "\n",
    "#     ################################################################\n",
    "#     # 클래스별 IoU를 누적할 리스트 초기화\n",
    "#     val_class_ious = []\n",
    "#     fish_val_class_ious = []\n",
    "#     val_epoch_loss = 0\n",
    "#     val_seg_loss = 0\n",
    "#     val_dom_loss = 0\n",
    "#     # 학습\n",
    "#     with torch.no_grad():\n",
    "#         model.eval()\n",
    "\n",
    "#         for target_images, target_masks in tqdm(val_target_dataloader):\n",
    "#             label = 2.5\n",
    "#             target_images, target_masks = apply_fisheye_distortion(target_images, target_masks, label)\n",
    "#             target_images = target_images.float().to(device)\n",
    "#             target_masks = target_masks.long().to(device)\n",
    "\n",
    "#             target_outputs = model(target_images)\n",
    "\n",
    "#             target_loss, val_segment_loss, val_domain_loss = loss_fn(target_outputs, target_masks, 0, alpha = ALPHA)\n",
    "\n",
    "#             loss = target_loss\n",
    "\n",
    "#             val_epoch_loss += loss.item()\n",
    "#             val_seg_loss += val_segment_loss.item()\n",
    "#             val_dom_loss += val_domain_loss.item()\n",
    "\n",
    "#             # train 클래스별 IoU 계산\n",
    "#             target_outputs = torch.softmax(target_outputs[0], dim=1).cpu()\n",
    "#             target_outputs = torch.argmax(target_outputs, dim=1).numpy()\n",
    "\n",
    "#             for class_id in range(N_CLASSES):\n",
    "#                 iou = calculate_iou_per_class(np.array(target_masks.cpu()), np.array(target_outputs), class_id)\n",
    "#                 fish_val_class_ious.append(iou)\n",
    "\n",
    "#     fish_val_class_ious = np.array(fish_val_class_ious).reshape(N_CLASSES, -1)\n",
    "#     fish_val_class_ious = np.mean(fish_val_class_ious, axis=1)\n",
    "#     print()\n",
    "#     print(\"--IoU Scores Fish val--\")\n",
    "#     for class_id, iou in enumerate(fish_val_class_ious):\n",
    "#         print(f'Class{class_id}: {iou:.4f}', end=\" \")\n",
    "#         if (class_id+1) % 7 == 0:\n",
    "#             print()\n",
    "\n",
    "#     # mIoU 계산\n",
    "#     fish_val_mIoU = np.mean(fish_val_class_ious)\n",
    "\n",
    "#     # 에폭마다 결과 출력 \n",
    "#     print(f\"\\nEpoch{epoch+1}\")\n",
    "#     print(f\"Valid seg Loss: {(val_seg_loss/len(val_target_dataloader))}\")\n",
    "#     print(f\"Valid dom Loss: {(val_dom_loss/len(val_target_dataloader))}\")\n",
    "#     print(f\"Valid Loss: {(val_epoch_loss/len(val_target_dataloader))}\")\n",
    "#     print(f\"Valid mIoU: {fish_val_mIoU}\" )\n",
    "#     print(\"___________________________________________________________________________________________\\n\")\n",
    "\n",
    "# #     # log metrics to wandb\n",
    "# #     wandb.log({\"train score\": train_mIoU})\n",
    "# #     wandb.log({\"val score\": fish_val_mIoU})\n",
    "# #     wandb.log({\"train loss\": (epoch_loss/len(source_dataloader))})\n",
    "# #     wandb.log({\"val loss\": (val_epoch_loss/len(val_target_dataloader))})\n",
    "    \n",
    "    \n",
    "# # # [optional] finish the wandb run, necessary in notebooks\n",
    "# # wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [07:30<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.0250 Class1: 0.0421 Class2: 0.0619 Class3: 0.0771 Class4: 0.0881 Class5: 0.0957 Class6: 0.0989 \n",
      "Class7: 0.1015 Class8: 0.1024 Class9: 0.1042 Class10: 0.1042 Class11: 0.1092 Class12: 0.1068 \n",
      "Epoch1\n",
      "Train seg Loss: 8.043044443363728\n",
      "Train dom Loss: 4120.223648688067\n",
      "Train Loss: 2068.154870762989\n",
      "Train mIoU: 0.0859469899195324\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:33<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.3272 Class1: 0.2622 Class2: 0.3152 Class3: 0.3432 Class4: 0.2880 Class5: 0.3192 Class6: 0.3506 \n",
      "Class7: 0.2695 Class8: 0.3118 Class9: 0.3158 Class10: 0.2984 Class11: 0.2929 Class12: 0.3071 \n",
      "Epoch1\n",
      "Valid seg Loss: 0.34410766859849296\n",
      "Valid dom Loss: 1621.4189575195312\n",
      "Valid Loss: 811.0535827636719\n",
      "Valid mIoU: 0.3077791571180629\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [07:48<00:00,  3.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.1079 Class1: 0.1120 Class2: 0.1075 Class3: 0.1094 Class4: 0.1102 Class5: 0.1101 Class6: 0.1139 \n",
      "Class7: 0.1095 Class8: 0.1133 Class9: 0.1146 Class10: 0.1112 Class11: 0.1142 Class12: 0.1119 \n",
      "Epoch2\n",
      "Train seg Loss: 7.393550135411214\n",
      "Train dom Loss: 3956.806703871575\n",
      "Train Loss: 1985.7968951187272\n",
      "Train mIoU: 0.11121403342275389\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:32<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.3478 Class1: 0.2749 Class2: 0.3276 Class3: 0.3598 Class4: 0.3004 Class5: 0.3382 Class6: 0.3675 \n",
      "Class7: 0.2815 Class8: 0.3203 Class9: 0.3304 Class10: 0.3123 Class11: 0.3138 Class12: 0.3362 \n",
      "Epoch2\n",
      "Valid seg Loss: 0.29289004355669024\n",
      "Valid dom Loss: 1453.8564900716146\n",
      "Valid Loss: 727.2211385091146\n",
      "Valid mIoU: 0.3239039295945703\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [07:59<00:00,  3.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.1092 Class1: 0.1180 Class2: 0.1135 Class3: 0.1227 Class4: 0.1226 Class5: 0.1232 Class6: 0.1261 \n",
      "Class7: 0.1223 Class8: 0.1275 Class9: 0.1299 Class10: 0.1302 Class11: 0.1285 Class12: 0.1268 \n",
      "Epoch3\n",
      "Train seg Loss: 7.002437955875328\n",
      "Train dom Loss: 3545.7874340112658\n",
      "Train Loss: 1779.8961557857153\n",
      "Train mIoU: 0.12311486339274443\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:30<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.3650 Class1: 0.2987 Class2: 0.3577 Class3: 0.3659 Class4: 0.3106 Class5: 0.3470 Class6: 0.3882 \n",
      "Class7: 0.2951 Class8: 0.3375 Class9: 0.3456 Class10: 0.3334 Class11: 0.3266 Class12: 0.3632 \n",
      "Epoch3\n",
      "Valid seg Loss: 0.28992779105901717\n",
      "Valid dom Loss: 1390.7484903971354\n",
      "Valid Loss: 695.6641723632813\n",
      "Valid mIoU: 0.34112050505970826\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [08:14<00:00,  3.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.1262 Class1: 0.1316 Class2: 0.1290 Class3: 0.1301 Class4: 0.1315 Class5: 0.1289 Class6: 0.1329 \n",
      "Class7: 0.1291 Class8: 0.1330 Class9: 0.1330 Class10: 0.1300 Class11: 0.1350 Class12: 0.1282 \n",
      "Epoch4\n",
      "Train seg Loss: 6.77889253857775\n",
      "Train dom Loss: 3188.2376913540606\n",
      "Train Loss: 1600.897733581239\n",
      "Train mIoU: 0.13064881763044003\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:31<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.3513 Class1: 0.2908 Class2: 0.3302 Class3: 0.3583 Class4: 0.3000 Class5: 0.3326 Class6: 0.3728 \n",
      "Class7: 0.2924 Class8: 0.3163 Class9: 0.3387 Class10: 0.3232 Class11: 0.3150 Class12: 0.3449 \n",
      "Epoch4\n",
      "Valid seg Loss: 0.33341602484385174\n",
      "Valid dom Loss: 1215.2132202148437\n",
      "Valid Loss: 607.9400268554688\n",
      "Valid mIoU: 0.3281951561752931\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [07:05<00:00,  3.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.1291 Class1: 0.1314 Class2: 0.1335 Class3: 0.1324 Class4: 0.1329 Class5: 0.1367 Class6: 0.1384 \n",
      "Class7: 0.1329 Class8: 0.1358 Class9: 0.1371 Class10: 0.1313 Class11: 0.1377 Class12: 0.1343 \n",
      "Epoch5\n",
      "Train seg Loss: 6.513803583448348\n",
      "Train dom Loss: 2930.8144778928895\n",
      "Train Loss: 1471.9210438289936\n",
      "Train mIoU: 0.13410786992907414\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.3862 Class1: 0.3262 Class2: 0.3711 Class3: 0.4025 Class4: 0.3349 Class5: 0.3699 Class6: 0.4084 \n",
      "Class7: 0.3211 Class8: 0.3636 Class9: 0.3703 Class10: 0.3610 Class11: 0.3448 Class12: 0.3718 \n",
      "Epoch5\n",
      "Valid seg Loss: 0.2872675970196724\n",
      "Valid dom Loss: 1122.522391764323\n",
      "Valid Loss: 561.5484578450521\n",
      "Valid mIoU: 0.36398547471958526\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [05:12<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.1374 Class1: 0.1397 Class2: 0.1362 Class3: 0.1408 Class4: 0.1378 Class5: 0.1391 Class6: 0.1403 \n",
      "Class7: 0.1346 Class8: 0.1412 Class9: 0.1375 Class10: 0.1417 Class11: 0.1371 Class12: 0.1356 \n",
      "Epoch6\n",
      "Train seg Loss: 6.504420339845229\n",
      "Train dom Loss: 2748.0382827537646\n",
      "Train Loss: 1380.5235655212748\n",
      "Train mIoU: 0.1383835054849744\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:37<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.3739 Class1: 0.2947 Class2: 0.3480 Class3: 0.3841 Class4: 0.3148 Class5: 0.3480 Class6: 0.3932 \n",
      "Class7: 0.3135 Class8: 0.3340 Class9: 0.3501 Class10: 0.3325 Class11: 0.3323 Class12: 0.3553 \n",
      "Epoch6\n",
      "Valid seg Loss: 0.34226140975952146\n",
      "Valid dom Loss: 1089.300927734375\n",
      "Valid Loss: 544.992724609375\n",
      "Valid mIoU: 0.34416904059686093\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [08:04<00:00,  3.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.1430 Class1: 0.1440 Class2: 0.1430 Class3: 0.1419 Class4: 0.1387 Class5: 0.1386 Class6: 0.1430 \n",
      "Class7: 0.1373 Class8: 0.1397 Class9: 0.1413 Class10: 0.1452 Class11: 0.1430 Class12: 0.1356 \n",
      "Epoch7\n",
      "Train seg Loss: 6.537801382496305\n",
      "Train dom Loss: 2615.199572687564\n",
      "Train Loss: 1314.1375887193649\n",
      "Train mIoU: 0.14110152011454305\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:34<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.3623 Class1: 0.2921 Class2: 0.3424 Class3: 0.3541 Class4: 0.3136 Class5: 0.3402 Class6: 0.3738 \n",
      "Class7: 0.2990 Class8: 0.3364 Class9: 0.3432 Class10: 0.3249 Class11: 0.3175 Class12: 0.3530 \n",
      "Epoch7\n",
      "Valid seg Loss: 0.3915048638979594\n",
      "Valid dom Loss: 1018.6250345865885\n",
      "Valid Loss: 509.7040222167969\n",
      "Valid mIoU: 0.33480417823034386\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [08:06<00:00,  3.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.1243 Class1: 0.1308 Class2: 0.1291 Class3: 0.1328 Class4: 0.1357 Class5: 0.1375 Class6: 0.1350 \n",
      "Class7: 0.1369 Class8: 0.1397 Class9: 0.1417 Class10: 0.1416 Class11: 0.1411 Class12: 0.1353 \n",
      "Epoch8\n",
      "Train seg Loss: 7.280893391727106\n",
      "Train dom Loss: 2590.3169708251953\n",
      "Train Loss: 1302.4393777135165\n",
      "Train mIoU: 0.13550217638095166\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:34<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.3343 Class1: 0.2730 Class2: 0.3099 Class3: 0.3467 Class4: 0.2878 Class5: 0.3100 Class6: 0.3607 \n",
      "Class7: 0.2749 Class8: 0.2926 Class9: 0.3173 Class10: 0.3005 Class11: 0.3220 Class12: 0.3195 \n",
      "Epoch8\n",
      "Valid seg Loss: 0.4380874166886012\n",
      "Valid dom Loss: 1051.25888671875\n",
      "Valid Loss: 526.0675313313802\n",
      "Valid mIoU: 0.31146940552027824\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [07:59<00:00,  3.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.1389 Class1: 0.1427 Class2: 0.1425 Class3: 0.1434 Class4: 0.1408 Class5: 0.1440 Class6: 0.1474 \n",
      "Class7: 0.1405 Class8: 0.1430 Class9: 0.1450 Class10: 0.1415 Class11: 0.1448 Class12: 0.1428 \n",
      "Epoch9\n",
      "Train seg Loss: 7.013086240576661\n",
      "Train dom Loss: 2387.3105744071627\n",
      "Train Loss: 1200.668373345033\n",
      "Train mIoU: 0.14286589436681324\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:37<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.3986 Class1: 0.3350 Class2: 0.3821 Class3: 0.4062 Class4: 0.3414 Class5: 0.3767 Class6: 0.4135 \n",
      "Class7: 0.3317 Class8: 0.3670 Class9: 0.3802 Class10: 0.3694 Class11: 0.3641 Class12: 0.3957 \n",
      "Epoch9\n",
      "Valid seg Loss: 0.3241594463586807\n",
      "Valid dom Loss: 911.8014831542969\n",
      "Valid Loss: 456.224897257487\n",
      "Valid mIoU: 0.3739710014090219\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [07:55<00:00,  3.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.1432 Class1: 0.1465 Class2: 0.1447 Class3: 0.1456 Class4: 0.1441 Class5: 0.1455 Class6: 0.1476 \n",
      "Class7: 0.1400 Class8: 0.1439 Class9: 0.1493 Class10: 0.1462 Class11: 0.1441 Class12: 0.1412 \n",
      "Epoch10\n",
      "Train seg Loss: 7.148139301363541\n",
      "Train dom Loss: 2273.7719088568206\n",
      "Train Loss: 1144.0340986507204\n",
      "Train mIoU: 0.14476386442409508\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:32<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.3777 Class1: 0.3057 Class2: 0.3521 Class3: 0.3796 Class4: 0.3188 Class5: 0.3470 Class6: 0.3940 \n",
      "Class7: 0.3190 Class8: 0.3376 Class9: 0.3476 Class10: 0.3352 Class11: 0.3452 Class12: 0.3554 \n",
      "Epoch10\n",
      "Valid seg Loss: 0.41460055907567345\n",
      "Valid dom Loss: 793.3798909505208\n",
      "Valid Loss: 397.10454813639325\n",
      "Valid mIoU: 0.3473081238604644\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [08:05<00:00,  3.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.1454 Class1: 0.1494 Class2: 0.1487 Class3: 0.1480 Class4: 0.1476 Class5: 0.1437 Class6: 0.1470 \n",
      "Class7: 0.1440 Class8: 0.1492 Class9: 0.1471 Class10: 0.1448 Class11: 0.1467 Class12: 0.1470 \n",
      "Epoch11\n",
      "Train seg Loss: 7.197104964243329\n",
      "Train dom Loss: 2304.226340694704\n",
      "Train Loss: 1159.3102781173327\n",
      "Train mIoU: 0.146820681448471\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:37<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.4047 Class1: 0.3452 Class2: 0.3958 Class3: 0.4223 Class4: 0.3473 Class5: 0.3797 Class6: 0.4285 \n",
      "Class7: 0.3449 Class8: 0.3792 Class9: 0.3884 Class10: 0.3698 Class11: 0.3616 Class12: 0.3855 \n",
      "Epoch11\n",
      "Valid seg Loss: 0.3320065190394719\n",
      "Valid dom Loss: 926.0720418294271\n",
      "Valid Loss: 463.36802571614584\n",
      "Valid mIoU: 0.38099990466896644\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [07:49<00:00,  3.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.1491 Class1: 0.1523 Class2: 0.1435 Class3: 0.1529 Class4: 0.1473 Class5: 0.1495 Class6: 0.1571 \n",
      "Class7: 0.1500 Class8: 0.1511 Class9: 0.1501 Class10: 0.1515 Class11: 0.1506 Class12: 0.1504 \n",
      "Epoch12\n",
      "Train seg Loss: 7.222664496550958\n",
      "Train dom Loss: 2353.217725670856\n",
      "Train Loss: 1183.831527206183\n",
      "Train mIoU: 0.15041953974123987\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:38<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.4232 Class1: 0.3485 Class2: 0.4004 Class3: 0.4298 Class4: 0.3605 Class5: 0.3956 Class6: 0.4404 \n",
      "Class7: 0.3597 Class8: 0.3884 Class9: 0.4016 Class10: 0.3784 Class11: 0.3769 Class12: 0.3995 \n",
      "Epoch12\n",
      "Valid seg Loss: 0.34001403947671255\n",
      "Valid dom Loss: 846.3194396972656\n",
      "Valid Loss: 423.4997314453125\n",
      "Valid mIoU: 0.3925256115678222\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [08:20<00:00,  3.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.1530 Class1: 0.1556 Class2: 0.1506 Class3: 0.1538 Class4: 0.1573 Class5: 0.1545 Class6: 0.1566 \n",
      "Class7: 0.1585 Class8: 0.1529 Class9: 0.1530 Class10: 0.1560 Class11: 0.1593 Class12: 0.1500 \n",
      "Epoch13\n",
      "Train seg Loss: 7.212527254461378\n",
      "Train dom Loss: 2362.562331489895\n",
      "Train Loss: 1188.4936907952247\n",
      "Train mIoU: 0.15470217766240488\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:35<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.3667 Class1: 0.3041 Class2: 0.3373 Class3: 0.3706 Class4: 0.3104 Class5: 0.3357 Class6: 0.3843 \n",
      "Class7: 0.3114 Class8: 0.3295 Class9: 0.3486 Class10: 0.3378 Class11: 0.3321 Class12: 0.3403 \n",
      "Epoch13\n",
      "Valid seg Loss: 0.45072137117385863\n",
      "Valid dom Loss: 1036.530118815104\n",
      "Valid Loss: 518.7157806396484\n",
      "Valid mIoU: 0.33915707456848754\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [08:02<00:00,  3.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.1546 Class1: 0.1486 Class2: 0.1557 Class3: 0.1553 Class4: 0.1544 Class5: 0.1562 Class6: 0.1595 \n",
      "Class7: 0.1595 Class8: 0.1553 Class9: 0.1573 Class10: 0.1553 Class11: 0.1568 Class12: 0.1523 \n",
      "Epoch14\n",
      "Train seg Loss: 7.251577904582888\n",
      "Train dom Loss: 2425.3346986632414\n",
      "Train Loss: 1219.918926169151\n",
      "Train mIoU: 0.1554472075266575\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:36<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.4112 Class1: 0.3370 Class2: 0.3805 Class3: 0.4157 Class4: 0.3420 Class5: 0.3787 Class6: 0.4230 \n",
      "Class7: 0.3478 Class8: 0.3703 Class9: 0.3783 Class10: 0.3655 Class11: 0.3565 Class12: 0.3906 \n",
      "Epoch14\n",
      "Valid seg Loss: 0.3645203133424123\n",
      "Valid dom Loss: 921.4470174153646\n",
      "Valid Loss: 461.08803304036456\n",
      "Valid mIoU: 0.3766988651322375\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [08:04<00:00,  3.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.1529 Class1: 0.1611 Class2: 0.1568 Class3: 0.1597 Class4: 0.1569 Class5: 0.1572 Class6: 0.1652 \n",
      "Class7: 0.1631 Class8: 0.1600 Class9: 0.1580 Class10: 0.1615 Class11: 0.1607 Class12: 0.1507 \n",
      "Epoch15\n",
      "Train seg Loss: 7.279094790148994\n",
      "Train dom Loss: 2497.8266696653504\n",
      "Train Loss: 1256.192429040707\n",
      "Train mIoU: 0.15875850426762145\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:38<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.4186 Class1: 0.3528 Class2: 0.3942 Class3: 0.4190 Class4: 0.3494 Class5: 0.3886 Class6: 0.4368 \n",
      "Class7: 0.3585 Class8: 0.3793 Class9: 0.3914 Class10: 0.3747 Class11: 0.3628 Class12: 0.3931 \n",
      "Epoch15\n",
      "Valid seg Loss: 0.3555991659561793\n",
      "Valid dom Loss: 967.453358968099\n",
      "Valid Loss: 484.0822784423828\n",
      "Valid mIoU: 0.38607602244874667\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [08:03<00:00,  3.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.1596 Class1: 0.1608 Class2: 0.1590 Class3: 0.1588 Class4: 0.1561 Class5: 0.1644 Class6: 0.1576 \n",
      "Class7: 0.1537 Class8: 0.1583 Class9: 0.1592 Class10: 0.1623 Class11: 0.1622 Class12: 0.1617 \n",
      "Epoch16\n",
      "Train seg Loss: 7.47514873035792\n",
      "Train dom Loss: 2641.0895548281464\n",
      "Train Loss: 1328.0199266561456\n",
      "Train mIoU: 0.15950224992333298\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:37<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.3722 Class1: 0.2921 Class2: 0.3382 Class3: 0.3848 Class4: 0.3150 Class5: 0.3489 Class6: 0.3890 \n",
      "Class7: 0.2965 Class8: 0.3330 Class9: 0.3437 Class10: 0.3295 Class11: 0.3357 Class12: 0.3390 \n",
      "Epoch16\n",
      "Valid seg Loss: 0.45279190440972644\n",
      "Valid dom Loss: 941.3682312011719\n",
      "Valid Loss: 471.13690490722655\n",
      "Valid mIoU: 0.3398096657622505\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [08:15<00:00,  3.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.1567 Class1: 0.1667 Class2: 0.1658 Class3: 0.1632 Class4: 0.1577 Class5: 0.1567 Class6: 0.1651 \n",
      "Class7: 0.1585 Class8: 0.1619 Class9: 0.1697 Class10: 0.1644 Class11: 0.1596 Class12: 0.1563 \n",
      "Epoch17\n",
      "Train seg Loss: 7.488540522484244\n",
      "Train dom Loss: 2637.8837418487105\n",
      "Train Loss: 1326.430407172582\n",
      "Train mIoU: 0.16172707398376415\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:36<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.4271 Class1: 0.3552 Class2: 0.4031 Class3: 0.4275 Class4: 0.3616 Class5: 0.3925 Class6: 0.4391 \n",
      "Class7: 0.3665 Class8: 0.3928 Class9: 0.4027 Class10: 0.3840 Class11: 0.3767 Class12: 0.4047 \n",
      "Epoch17\n",
      "Valid seg Loss: 0.3471609304348628\n",
      "Valid dom Loss: 1040.8671081542968\n",
      "Valid Loss: 520.7807098388672\n",
      "Valid mIoU: 0.39488137636029363\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [08:16<00:00,  3.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.1646 Class1: 0.1656 Class2: 0.1583 Class3: 0.1631 Class4: 0.1607 Class5: 0.1591 Class6: 0.1648 \n",
      "Class7: 0.1618 Class8: 0.1632 Class9: 0.1610 Class10: 0.1562 Class11: 0.1632 Class12: 0.1647 \n",
      "Epoch18\n",
      "Train seg Loss: 7.34114836955416\n",
      "Train dom Loss: 2701.8788830301037\n",
      "Train Loss: 1358.2805891529374\n",
      "Train mIoU: 0.16202490970198558\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:37<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.4091 Class1: 0.3417 Class2: 0.3928 Class3: 0.4131 Class4: 0.3511 Class5: 0.3856 Class6: 0.4193 \n",
      "Class7: 0.3512 Class8: 0.3799 Class9: 0.3796 Class10: 0.3711 Class11: 0.3706 Class12: 0.3939 \n",
      "Epoch18\n",
      "Valid seg Loss: 0.37191645900408427\n",
      "Valid dom Loss: 1061.7663879394531\n",
      "Valid Loss: 531.2551137288411\n",
      "Valid mIoU: 0.3814518017362639\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [07:59<00:00,  3.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.1607 Class1: 0.1635 Class2: 0.1615 Class3: 0.1631 Class4: 0.1657 Class5: 0.1619 Class6: 0.1634 \n",
      "Class7: 0.1597 Class8: 0.1585 Class9: 0.1650 Class10: 0.1641 Class11: 0.1636 Class12: 0.1629 \n",
      "Epoch19\n",
      "Train seg Loss: 7.404952771448786\n",
      "Train dom Loss: 2831.726946291716\n",
      "Train Loss: 1423.2684298390118\n",
      "Train mIoU: 0.16258373582995034\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:31<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.4021 Class1: 0.3254 Class2: 0.3716 Class3: 0.4079 Class4: 0.3334 Class5: 0.3654 Class6: 0.4097 \n",
      "Class7: 0.3432 Class8: 0.3656 Class9: 0.3683 Class10: 0.3608 Class11: 0.3575 Class12: 0.3728 \n",
      "Epoch19\n",
      "Valid seg Loss: 0.4257915904124578\n",
      "Valid dom Loss: 1007.8824971516927\n",
      "Valid Loss: 504.367035929362\n",
      "Valid mIoU: 0.36797824424560244\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [08:14<00:00,  3.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.1631 Class1: 0.1684 Class2: 0.1538 Class3: 0.1656 Class4: 0.1666 Class5: 0.1691 Class6: 0.1628 \n",
      "Class7: 0.1595 Class8: 0.1623 Class9: 0.1675 Class10: 0.1638 Class11: 0.1656 Class12: 0.1618 \n",
      "Epoch20\n",
      "Train seg Loss: 7.264267780156671\n",
      "Train dom Loss: 2909.572013412697\n",
      "Train Loss: 1462.0502776925223\n",
      "Train mIoU: 0.16383437029461143\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:32<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.4107 Class1: 0.3375 Class2: 0.3859 Class3: 0.4219 Class4: 0.3495 Class5: 0.3799 Class6: 0.4207 \n",
      "Class7: 0.3577 Class8: 0.3755 Class9: 0.3870 Class10: 0.3746 Class11: 0.3698 Class12: 0.3782 \n",
      "Epoch20\n",
      "Valid seg Loss: 0.3883258859316508\n",
      "Valid dom Loss: 1124.1257446289062\n",
      "Valid Loss: 562.4511983235677\n",
      "Valid mIoU: 0.38066985254030483\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [08:00<00:00,  3.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.1651 Class1: 0.1638 Class2: 0.1637 Class3: 0.1617 Class4: 0.1692 Class5: 0.1652 Class6: 0.1676 \n",
      "Class7: 0.1601 Class8: 0.1585 Class9: 0.1705 Class10: 0.1641 Class11: 0.1567 Class12: 0.1620 \n",
      "Epoch21\n",
      "Train seg Loss: 7.252095736914139\n",
      "Train dom Loss: 2916.067600858384\n",
      "Train Loss: 1465.285894755247\n",
      "Train mIoU: 0.16370445918171686\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:34<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.4270 Class1: 0.3479 Class2: 0.3979 Class3: 0.4257 Class4: 0.3620 Class5: 0.3919 Class6: 0.4312 \n",
      "Class7: 0.3648 Class8: 0.3898 Class9: 0.3939 Class10: 0.3851 Class11: 0.3761 Class12: 0.3936 \n",
      "Epoch21\n",
      "Valid seg Loss: 0.36490958631038667\n",
      "Valid dom Loss: 1095.3556030273437\n",
      "Valid Loss: 548.0427103678386\n",
      "Valid mIoU: 0.3912985026805857\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [08:03<00:00,  3.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.1670 Class1: 0.1661 Class2: 0.1612 Class3: 0.1727 Class4: 0.1620 Class5: 0.1671 Class6: 0.1712 \n",
      "Class7: 0.1623 Class8: 0.1668 Class9: 0.1647 Class10: 0.1636 Class11: 0.1562 Class12: 0.1601 \n",
      "Epoch22\n",
      "Train seg Loss: 7.296182446640687\n",
      "Train dom Loss: 3021.902721239173\n",
      "Train Loss: 1518.2475409298002\n",
      "Train mIoU: 0.16468406991332563\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:34<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.4253 Class1: 0.3514 Class2: 0.4041 Class3: 0.4345 Class4: 0.3646 Class5: 0.3912 Class6: 0.4375 \n",
      "Class7: 0.3645 Class8: 0.3904 Class9: 0.3977 Class10: 0.3842 Class11: 0.3788 Class12: 0.3960 \n",
      "Epoch22\n",
      "Valid seg Loss: 0.3390574793020884\n",
      "Valid dom Loss: 1232.9248128255208\n",
      "Valid Loss: 616.8014668782552\n",
      "Valid mIoU: 0.39386448764980425\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [03:39<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.1690 Class1: 0.1665 Class2: 0.1640 Class3: 0.1663 Class4: 0.1653 Class5: 0.1610 Class6: 0.1752 \n",
      "Class7: 0.1639 Class8: 0.1660 Class9: 0.1627 Class10: 0.1628 Class11: 0.1658 Class12: 0.1647 \n",
      "Epoch23\n",
      "Train seg Loss: 7.331304105997518\n",
      "Train dom Loss: 3115.0483369689055\n",
      "Train Loss: 1564.8554746792045\n",
      "Train mIoU: 0.1656415093317278\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.4100 Class1: 0.3469 Class2: 0.3915 Class3: 0.4144 Class4: 0.3604 Class5: 0.3899 Class6: 0.4320 \n",
      "Class7: 0.3417 Class8: 0.3837 Class9: 0.3852 Class10: 0.3775 Class11: 0.3748 Class12: 0.3874 \n",
      "Epoch23\n",
      "Valid seg Loss: 0.3551828016837438\n",
      "Valid dom Loss: 1329.8970011393228\n",
      "Valid Loss: 665.3036865234375\n",
      "Valid mIoU: 0.38424852866292397\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [02:14<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.1713 Class1: 0.1652 Class2: 0.1659 Class3: 0.1653 Class4: 0.1674 Class5: 0.1666 Class6: 0.1703 \n",
      "Class7: 0.1656 Class8: 0.1605 Class9: 0.1696 Class10: 0.1707 Class11: 0.1651 Class12: 0.1621 \n",
      "Epoch24\n",
      "Train seg Loss: 7.337432422607705\n",
      "Train dom Loss: 3202.3229003021684\n",
      "Train Loss: 1608.498883517756\n",
      "Train mIoU: 0.16658884445315214\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.4137 Class1: 0.3375 Class2: 0.3893 Class3: 0.4153 Class4: 0.3419 Class5: 0.3843 Class6: 0.4222 \n",
      "Class7: 0.3500 Class8: 0.3789 Class9: 0.3763 Class10: 0.3734 Class11: 0.3694 Class12: 0.3897 \n",
      "Epoch24\n",
      "Valid seg Loss: 0.3617448717355728\n",
      "Valid dom Loss: 1330.7086588541667\n",
      "Valid Loss: 665.716074625651\n",
      "Valid mIoU: 0.3801467394268263\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [02:14<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.1566 Class1: 0.1660 Class2: 0.1684 Class3: 0.1635 Class4: 0.1678 Class5: 0.1577 Class6: 0.1682 \n",
      "Class7: 0.1619 Class8: 0.1649 Class9: 0.1670 Class10: 0.1715 Class11: 0.1666 Class12: 0.1689 \n",
      "Epoch25\n",
      "Train seg Loss: 7.605005503078734\n",
      "Train dom Loss: 3241.8818520808563\n",
      "Train Loss: 1628.545929117695\n",
      "Train mIoU: 0.1653107699461978\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--IoU Scores Fish val--\n",
      "Class0: 0.4272 Class1: 0.3558 Class2: 0.4019 Class3: 0.4294 Class4: 0.3593 Class5: 0.3964 Class6: 0.4374 \n",
      "Class7: 0.3602 Class8: 0.3916 Class9: 0.3937 Class10: 0.3854 Class11: 0.3782 Class12: 0.4020 \n",
      "Epoch25\n",
      "Valid seg Loss: 0.34594605565071107\n",
      "Valid dom Loss: 1389.3079956054687\n",
      "Valid Loss: 694.9999430338542\n",
      "Valid mIoU: 0.3937357508919259\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "#torch.cuda.empty_cache()\n",
    "# import wandb\n",
    "\n",
    "\n",
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"practice_10_27_4d_res18\",\n",
    "    \n",
    "#     # track hyperparameters and run metadata\n",
    "#     config={\n",
    "#     \"learning_rate\": LR,\n",
    "#     \"architecture\": \"CNN\",\n",
    "#     \"dataset\": \"Samsung\",\n",
    "#     \"epochs\": EP,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "for epoch in range(EP):\n",
    "    # 클래스별 IoU를 누적할 리스트 초기화\n",
    "    train_class_ious = []\n",
    "    fish_train_class_ious = []\n",
    "    # 학습\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    seg_loss = 0\n",
    "    dom_loss = 0\n",
    "\n",
    "    for source_images, source_masks in tqdm(source_dataloader):\n",
    "        for label in range(4):\n",
    "            source_image, source_mask = apply_fisheye_distortion(source_images, source_masks, label)\n",
    "            source_image = source_image.float().to(device)\n",
    "            source_mask = source_mask.long().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            source_outputs = model(source_image)\n",
    "\n",
    "            source_loss, segment_loss, domain_loss = loss_fn(source_outputs, source_mask, label, alpha = ALPHA)\n",
    "\n",
    "            loss = source_loss\n",
    "            epoch_loss += loss.item()\n",
    "            seg_loss += segment_loss.item()\n",
    "            dom_loss += domain_loss.item()\n",
    "                                \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "                # train 클래스별 IoU 계산\n",
    "        source_outputs = torch.softmax(source_outputs[0], dim=1).cpu()\n",
    "        source_outputs = torch.argmax(source_outputs, dim=1).numpy()\n",
    "\n",
    "        for class_id in range(N_CLASSES):\n",
    "            iou = calculate_iou_per_class(np.array(source_masks.cpu()), np.array(source_outputs), class_id)\n",
    "            train_class_ious.append(iou)\n",
    "\n",
    "    train_class_ious = np.array(train_class_ious).reshape(N_CLASSES, -1)\n",
    "    train_class_ious = np.mean(train_class_ious, axis=1)\n",
    "    print(\"--IoU Scores Train--\")\n",
    "    for class_id, iou in enumerate(train_class_ious):\n",
    "        print(f'Class{class_id}: {iou:.4f}', end=\" \")\n",
    "        if (class_id+1) % 7 == 0:\n",
    "            print()\n",
    "\n",
    "    # mIoU 계산\n",
    "    train_mIoU = np.mean(train_class_ious)\n",
    "\n",
    "    # 에폭마다 결과 출력 \n",
    "    print(f\"\\nEpoch{epoch+1}\")\n",
    "    print(f\"Train seg Loss: {(seg_loss/len(source_dataloader))}\")\n",
    "    print(f\"Train dom Loss: {(dom_loss/len(source_dataloader))}\")\n",
    "    print(f\"Train Loss: {(epoch_loss/len(source_dataloader))}\")\n",
    "    print(f\"Train mIoU: {train_mIoU}\" )\n",
    "    print(\"___________________________________________________________________________________________\\n\")\n",
    "\n",
    "\n",
    "    ################################################################\n",
    "    # 클래스별 IoU를 누적할 리스트 초기화\n",
    "    val_class_ious = []\n",
    "    fish_val_class_ious = []\n",
    "    val_epoch_loss = 0\n",
    "    val_seg_loss = 0\n",
    "    val_dom_loss = 0\n",
    "    # 학습\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        for target_images, target_masks in tqdm(val_target_dataloader):\n",
    "            label = 2.5\n",
    "            target_images, target_masks = apply_fisheye_distortion(target_images, target_masks, label)\n",
    "            target_images = target_images.float().to(device)\n",
    "            target_masks = target_masks.long().to(device)\n",
    "\n",
    "            target_outputs = model(target_images)\n",
    "\n",
    "            target_loss, val_segment_loss, val_domain_loss = loss_fn(target_outputs, target_masks, 0, alpha = ALPHA)\n",
    "\n",
    "            loss = target_loss\n",
    "\n",
    "            val_epoch_loss += loss.item()\n",
    "            val_seg_loss += val_segment_loss.item()\n",
    "            val_dom_loss += val_domain_loss.item()\n",
    "\n",
    "            # train 클래스별 IoU 계산\n",
    "            target_outputs = torch.softmax(target_outputs[0], dim=1).cpu()\n",
    "            target_outputs = torch.argmax(target_outputs, dim=1).numpy()\n",
    "\n",
    "            for class_id in range(N_CLASSES):\n",
    "                iou = calculate_iou_per_class(np.array(target_masks.cpu()), np.array(target_outputs), class_id)\n",
    "                fish_val_class_ious.append(iou)\n",
    "\n",
    "    fish_val_class_ious = np.array(fish_val_class_ious).reshape(N_CLASSES, -1)\n",
    "    fish_val_class_ious = np.mean(fish_val_class_ious, axis=1)\n",
    "    print()\n",
    "    print(\"--IoU Scores Fish val--\")\n",
    "    for class_id, iou in enumerate(fish_val_class_ious):\n",
    "        print(f'Class{class_id}: {iou:.4f}', end=\" \")\n",
    "        if (class_id+1) % 7 == 0:\n",
    "            print()\n",
    "\n",
    "    # mIoU 계산\n",
    "    fish_val_mIoU = np.mean(fish_val_class_ious)\n",
    "\n",
    "    # 에폭마다 결과 출력 \n",
    "    print(f\"\\nEpoch{epoch+1}\")\n",
    "    print(f\"Valid seg Loss: {(val_seg_loss/len(val_target_dataloader))}\")\n",
    "    print(f\"Valid dom Loss: {(val_dom_loss/len(val_target_dataloader))}\")\n",
    "    print(f\"Valid Loss: {(val_epoch_loss/len(val_target_dataloader))}\")\n",
    "    print(f\"Valid mIoU: {fish_val_mIoU}\" )\n",
    "    print(\"___________________________________________________________________________________________\\n\")\n",
    "\n",
    "#     # log metrics to wandb\n",
    "#     wandb.log({\"train score\": train_mIoU})\n",
    "#     wandb.log({\"val score\": fish_val_mIoU})\n",
    "#     wandb.log({\"train loss\": (epoch_loss/len(source_dataloader))})\n",
    "#     wandb.log({\"val loss\": (val_epoch_loss/len(val_target_dataloader))})\n",
    "    \n",
    "    \n",
    "# # [optional] finish the wandb run, necessary in notebooks\n",
    "# wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './data/resnet_unet_soft4_25ep.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byungwan_resn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
