{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/MMI24limbyungwan/.conda/envs/byungwan_resn/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from torch.optim.lr_scheduler import _LRScheduler\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import random\n",
    "\n",
    "# GPU 사용이 가능할 경우, GPU를 사용할 수 있게 함.'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "print(device)\n",
    "\n",
    "print(os.environ.get('CUDA_VISIBLE_DEVICES'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GradReverse(torch.autograd.Function):\n",
    "#     @staticmethod\n",
    "#     def forward(self, x):\n",
    "#         return x.view_as(x)\n",
    "#     @staticmethod\n",
    "#     def backward(self, grad_output): # 역전파 시에 gradient에 음수를 취함\n",
    "#         return grad_output * (-1)\n",
    "\n",
    "# class domain_classifier(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(domain_classifier, self).__init__()\n",
    "#         self.fc1 = nn.Linear(224*224*64, 10)\n",
    "#         self.fc2 = nn.Linear(10, 4) # source = 0, target = 1 회귀 가정\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.view(-1, 224*224*64)\n",
    "#         x = GradReverse.apply(x) # gradient reverse\n",
    "#         x = F.leaky_relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "        \n",
    "#         #return torch.sigmoid(x)\n",
    "#         return x\n",
    "\n",
    "# class IdentityBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, stride=1):\n",
    "#         super(IdentityBlock, self).__init__()\n",
    "        \n",
    "#         # 3x3 convolution\n",
    "#         self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "#         self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "        \n",
    "#         # 3x3 convolution\n",
    "#         self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "#         self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "        \n",
    "#         # Skip connection\n",
    "#         self.skip = nn.Sequential()\n",
    "#         if stride != 1 or in_channels != out_channels:\n",
    "#             self.skip = nn.Sequential(\n",
    "#                 nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "#                 nn.BatchNorm2d(out_channels)\n",
    "#             )\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         identity = x\n",
    "        \n",
    "#         out = self.conv1(x)\n",
    "#         out = self.bn1(out)\n",
    "#         out = self.relu1(out)\n",
    "        \n",
    "#         out = self.conv2(out)\n",
    "#         out = self.bn2(out)\n",
    "        \n",
    "#         # Adding the skip connection\n",
    "#         out += self.skip(identity)\n",
    "#         out = self.relu2(out)\n",
    "        \n",
    "#         return out\n",
    "\n",
    "\n",
    "# #인코더 블럭\n",
    "# class Conv2(nn.Module):\n",
    "#     def __init__(self,in_channels, out_channels):\n",
    "#         super(Conv2,self).__init__() \n",
    "#         self.identityblock1 = IdentityBlock(in_channels,in_channels)\n",
    "#         self.identityblock2 = IdentityBlock(in_channels,out_channels)\n",
    "#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
    "#     def forward(self,x):\n",
    "#         x = self.identityblock1(x)\n",
    "#         x = self.identityblock2(x)\n",
    "#         p = self.maxpool(x)\n",
    "        \n",
    "#         return x , p\n",
    "# class Conv3(nn.Module):\n",
    "#     def __init__(self,in_channels, out_channels):\n",
    "#         super(Conv3,self).__init__()         \n",
    "#         self.identityblock1 = IdentityBlock(in_channels,in_channels)\n",
    "#         self.identityblock2 = IdentityBlock(in_channels,out_channels)\n",
    "#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
    "#     def forward(self,x):\n",
    "#         x = self.identityblock1(x)\n",
    "#         x = self.identityblock2(x)\n",
    "#         p = self.maxpool(x)\n",
    "        \n",
    "#         return x , p\n",
    "# class Conv4(nn.Module):\n",
    "#     def __init__(self,in_channels, out_channels):\n",
    "#         super(Conv4,self).__init__()         \n",
    "#         self.identityblock1 = IdentityBlock(in_channels,in_channels)\n",
    "#         self.identityblock2 = IdentityBlock(in_channels,out_channels)\n",
    "#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
    "#     def forward(self,x):\n",
    "#         x = self.identityblock1(x)\n",
    "#         x = self.identityblock2(x)\n",
    "#         p = self.maxpool(x)\n",
    "        \n",
    "#         return x , p\n",
    "# class Conv5(nn.Module):\n",
    "#     def __init__(self,in_channels, out_channels):\n",
    "#         super(Conv5,self).__init__() \n",
    "#         self.identityblock1 = IdentityBlock(in_channels,in_channels)\n",
    "#         self.identityblock2 = IdentityBlock(in_channels,out_channels)\n",
    "#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
    "        \n",
    "#     def forward(self,x):\n",
    "#         x = self.identityblock1(x)\n",
    "#         x = self.identityblock2(x)\n",
    "#         p = self.maxpool(x)\n",
    "        \n",
    "#         return x , p\n",
    "# #디코더 블럭\n",
    "# class DecoderBlock(nn.Module):\n",
    "#     def __init__(self, channels):\n",
    "#         super(DecoderBlock, self).__init__()\n",
    "#         self.upsample = nn.ConvTranspose2d(channels*2, channels, kernel_size=4, stride=2, padding=1) # output_padding 추가\n",
    "#         self.convblock1 = IdentityBlock(channels*2, channels)\n",
    "\n",
    "#     def forward(self, x, skip):\n",
    "#         x = self.upsample(x)\n",
    "#         if x.size(2) != skip.size(2) or x.size(3) != skip.size(3):\n",
    "#             x = F.interpolate(x, size=(skip.size(2), skip.size(3)))\n",
    "#         x = torch.cat([x, skip], dim=1)\n",
    "#         x = self.convblock1(x)\n",
    "#         #print(\"x\",x.shape,\"skip: \",skip.shape)\n",
    "#         return x\n",
    "\n",
    "# #Unet구조 middle의 xm값의 움직임에 주의\n",
    "# class Resnet18_Unet(nn.Module):\n",
    "#     def __init__(self,n_classes):\n",
    "#         super(Resnet18_Unet,self).__init__()\n",
    "#         self.fconv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "#         self.fbn1 = nn.BatchNorm2d(64)\n",
    "#         self.frelu1 = nn.ReLU()\n",
    "#         self.fmaxpooling = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "        \n",
    "#         self.conv2 = Conv2(64,128)\n",
    "#         self.conv3 = Conv3(128,256)\n",
    "#         self.conv4 = Conv4(256,512)\n",
    "#         self.conv5 = Conv5(512,1024)\n",
    "        \n",
    "#         self.middleconv = IdentityBlock(1024,2048)\n",
    "#         self.dropout = nn.Dropout2d(0.1) #\n",
    "           \n",
    "#         self.decoder5 = DecoderBlock(1024)\n",
    "#         self.decoder4 = DecoderBlock(512)\n",
    "#         self.decoder3 = DecoderBlock(256)\n",
    "#         self.decoder2 = DecoderBlock(128)\n",
    "#         self.decoder1 = DecoderBlock(64)\n",
    "#         self.transpose = nn.ConvTranspose2d(64, 64, kernel_size=4, stride=2, padding=1) # output_padding 추가\n",
    "        \n",
    "#         self.segmap = nn.Conv2d(64,n_classes, kernel_size=1)\n",
    "#         self.domain_classifier = domain_classifier()\n",
    "        \n",
    "#     def forward(self,x):\n",
    "#         x = self.fconv1(x)#3->64\n",
    "#         x0 = self.fbn1(x)\n",
    "#         x1 = self.frelu1(x)\n",
    "#         p = self.fmaxpooling(x1)#첫 conv: x0([8, 64, 109, 109]) p([8, 64, 54, 54])\n",
    "#         #print(\"conv1: \",x1.shape, \"maxpooling: \",p.shape)\n",
    "#         x2,p = self.conv2(p)\n",
    "#         #print(\"conv2: \",x2.shape, \"maxpooling: \",p.shape)\n",
    "#         x3,p = self.conv3(p)\n",
    "#         #print(\"conv3: \",x3.shape, \"maxpooling: \",p.shape)\n",
    "#         x4,p = self.conv4(p)\n",
    "#         #print(\"conv4: \",x4.shape, \"maxpooling: \",p.shape)\n",
    "#         x5,p = self.conv5(p)\n",
    "#         #print(\"conv5: \",x5.shape, \"maxpooling: \",p.shape)\n",
    "        \n",
    "#         xm = self.middleconv(p)#xm([8, 4096, 2, 2])\n",
    "#         #print(\"xm: \",xm.shape, \"maxpooling: \",p.shape)\n",
    "#         xm = self.dropout(xm)\n",
    "        \n",
    "#         x = self.decoder5(xm,x5)#뉴런:2048*2->2048 1\n",
    "#         x = self.decoder4(x,x4)#뉴런:1024*2->1024 \n",
    "#         x = self.decoder3(x,x3) #14\n",
    "#         x = self.decoder2(x,x2)#28\n",
    "#         x = self.decoder1(x,x1)#55\n",
    "#         x = self.transpose(x)\n",
    "        \n",
    "#         #print(x.shape)\n",
    "#         #x = F.interpolate(x, size=(224, 224))\n",
    "#         x_c = self.segmap(x)\n",
    "#         x_d = self.domain_classifier(x)\n",
    "        \n",
    "#         return x_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradReverse(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(self, x):\n",
    "        return x.view_as(x)\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output): # 역전파 시에 gradient에 음수를 취함\n",
    "        return grad_output * (-1)\n",
    "\n",
    "class domain_classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(domain_classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(224*224*64, 50)\n",
    "        self.fc2 = nn.Linear(50, 3) # source = 0, target = 1 회귀 가정\n",
    "        ##\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 224*224*64)\n",
    "        x = GradReverse.apply(x) # gradient reverse\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        #return torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "class domain_linear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(domain_linear, self).__init__()\n",
    "        self.fc1 = nn.Linear(224*224*64, 10)\n",
    "        self.fc2 = nn.Linear(10, 1) # source = 0, target = 1 회귀 가정\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 224*224*64)\n",
    "        x = GradReverse.apply(x) # gradient reverse\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return torch.sigmoid(x)\n",
    "        #return x\n",
    "class IdentityBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(IdentityBlock, self).__init__()\n",
    "        \n",
    "        # 3x3 convolution\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # 3x3 convolution\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # Skip connection\n",
    "        self.skip = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        # Adding the skip connection\n",
    "        out += self.skip(identity)\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "        return out\n",
    "#인코더 블럭\n",
    "class Conv2(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels):\n",
    "        super(Conv2,self).__init__() \n",
    "        self.identityblock1 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock2 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock3 = IdentityBlock(in_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
    "    def forward(self,x):\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        x = self.identityblock3(x)\n",
    "        p = self.maxpool(x)\n",
    "        \n",
    "        return x , p\n",
    "class Conv3(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels):\n",
    "        super(Conv3,self).__init__()         \n",
    "        self.identityblock1 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock2 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock3 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock4 = IdentityBlock(in_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
    "    def forward(self,x):\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        x = self.identityblock3(x)\n",
    "        x = self.identityblock4(x)\n",
    "        p = self.maxpool(x)\n",
    "        \n",
    "        return x , p\n",
    "class Conv4(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels):\n",
    "        super(Conv4,self).__init__()         \n",
    "        self.identityblock1 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock2 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock3 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock4 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock5 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock6 = IdentityBlock(in_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
    "    def forward(self,x):\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        x = self.identityblock3(x)\n",
    "        x = self.identityblock4(x)\n",
    "        x = self.identityblock5(x)\n",
    "        x = self.identityblock6(x)\n",
    "        p = self.maxpool(x)\n",
    "        \n",
    "        return x , p\n",
    "class Conv5(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels):\n",
    "        super(Conv5,self).__init__() \n",
    "        self.identityblock1 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock2 = IdentityBlock(in_channels,in_channels)\n",
    "        self.identityblock3 = IdentityBlock(in_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2,padding=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        x = self.identityblock3(x)\n",
    "        p = self.maxpool(x)\n",
    "        \n",
    "        return x , p\n",
    "#디코더 블럭\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.upsample = nn.ConvTranspose2d(channels*2, channels, kernel_size=4, stride=2, padding=1) # output_padding 추가\n",
    "        self.convblock1 = IdentityBlock(channels*2, channels)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = self.upsample(x)\n",
    "        if x.size(2) != skip.size(2) or x.size(3) != skip.size(3):\n",
    "            x = F.interpolate(x, size=(skip.size(2), skip.size(3)))\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.convblock1(x)\n",
    "        #print(\"x\",x.shape,\"skip: \",skip.shape)\n",
    "        return x\n",
    "\n",
    "#Unet구조 middle의 xm값의 움직임에 주의\n",
    "class Resnet34_Unet(nn.Module):\n",
    "    def __init__(self,n_classes):\n",
    "        super(Resnet34_Unet,self).__init__()\n",
    "        self.fconv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.fbn1 = nn.BatchNorm2d(64)\n",
    "        self.frelu1 = nn.ReLU()\n",
    "        self.fmaxpooling = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "        \n",
    "        self.conv2 = Conv2(64,128)\n",
    "        self.conv3 = Conv3(128,256)\n",
    "        self.conv4 = Conv4(256,512)\n",
    "        self.conv5 = Conv5(512,1024)\n",
    "        \n",
    "        self.middleconv = IdentityBlock(1024,2048)\n",
    "        self.dropout = nn.Dropout2d(0.1) #\n",
    "           \n",
    "        self.decoder5 = DecoderBlock(1024)\n",
    "        self.decoder4 = DecoderBlock(512)\n",
    "        self.decoder3 = DecoderBlock(256)\n",
    "        self.decoder2 = DecoderBlock(128)\n",
    "        self.decoder1 = DecoderBlock(64)\n",
    "        self.transpose = nn.ConvTranspose2d(64, 64, kernel_size=4, stride=2, padding=1) # output_padding 추가\n",
    "        \n",
    "        self.segmap = nn.Conv2d(64,n_classes, kernel_size=1)\n",
    "        self.domain_classifier = domain_classifier()\n",
    "        self.domain_linear = domain_linear()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fconv1(x)#3->64\n",
    "        x0 = self.fbn1(x)\n",
    "        x1 = self.frelu1(x)\n",
    "        p = self.fmaxpooling(x1)#첫 conv: x0([8, 64, 109, 109]) p([8, 64, 54, 54])\n",
    "        #print(\"conv1: \",x1.shape, \"maxpooling: \",p.shape)\n",
    "        x2,p = self.conv2(p)\n",
    "        #print(\"conv2: \",x2.shape, \"maxpooling: \",p.shape)\n",
    "        x3,p = self.conv3(p)\n",
    "        #print(\"conv3: \",x3.shape, \"maxpooling: \",p.shape)\n",
    "        x4,p = self.conv4(p)\n",
    "        #print(\"conv4: \",x4.shape, \"maxpooling: \",p.shape)\n",
    "        x5,p = self.conv5(p)\n",
    "        #print(\"conv5: \",x5.shape, \"maxpooling: \",p.shape)\n",
    "        \n",
    "        xm = self.middleconv(p)#xm([8, 4096, 2, 2])\n",
    "        #print(\"xm: \",xm.shape, \"maxpooling: \",p.shape)\n",
    "        xm = self.dropout(xm)\n",
    "        \n",
    "        x = self.decoder5(xm,x5)#뉴런:2048*2->2048 1\n",
    "        x = self.decoder4(x,x4)#뉴런:1024*2->1024 \n",
    "        x = self.decoder3(x,x3) #14\n",
    "        x = self.decoder2(x,x2)#28\n",
    "        x = self.decoder1(x,x1)#55\n",
    "        x = self.transpose(x)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        #x = F.interpolate(x, size=(224, 224))\n",
    "        x_c = self.segmap(x)\n",
    "        #x_d = self.domain_linear(x)\n",
    "        x_d = self.domain_classifier(x)\n",
    "        \n",
    "        \n",
    "        return x_c,x_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GradReverse(torch.autograd.Function):\n",
    "#     @staticmethod\n",
    "#     def forward(self, x):\n",
    "#         return x.view_as(x)\n",
    "#     @staticmethod\n",
    "#     def backward(self, grad_output): # 역전파 시에 gradient에 음수를 취함\n",
    "#         return grad_output * (-1)\n",
    "\n",
    "# class domain_classifier(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(domain_classifier, self).__init__()\n",
    "#         self.fc1 = nn.Linear(224*224*64, 10)\n",
    "#         self.fc2 = nn.Linear(10, 4) # source = 0, target = 1 회귀 가정\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.view(-1, 224*224*64)\n",
    "#         x = GradReverse.apply(x) # gradient reverse\n",
    "#         x = F.leaky_relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "        \n",
    "#         #return torch.sigmoid(x)\n",
    "#         return x\n",
    "\n",
    "# #Unet의 기본이 되는 conv블럭\n",
    "# class ConvBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels,kernel_size = 3):\n",
    "#         super(ConvBlock, self).__init__()\n",
    "#         self.kernel_size = kernel_size\n",
    "#         self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=1)\n",
    "#         self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "        \n",
    "#         self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, padding=1)  # 여기서 in_channels는 out_channels와 동일해야 합니다.\n",
    "#         self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.relu1(x)\n",
    "        \n",
    "#         x = self.conv2(x)\n",
    "#         x = self.bn2(x)\n",
    "#         x = self.relu2(x)\n",
    "#         return x\n",
    "# class IdentityBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, mid_channels, out_channels, stride=1):\n",
    "#         super(IdentityBlock, self).__init__()\n",
    "        \n",
    "#         # 1x1 convolution\n",
    "#         self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=1, stride=stride, bias=False)\n",
    "#         self.bn1 = nn.BatchNorm2d(mid_channels)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "\n",
    "#         # 3x3 convolution\n",
    "#         self.conv2 = nn.Conv2d(mid_channels, mid_channels, kernel_size=3, padding=1, bias=False)\n",
    "#         self.bn2 = nn.BatchNorm2d(mid_channels)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "\n",
    "#         # 1x1 convolution\n",
    "#         self.conv3 = nn.Conv2d(mid_channels, out_channels, kernel_size=1, bias=False)\n",
    "#         self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "#         self.relu3 = nn.ReLU()\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         out = self.conv1(x)\n",
    "#         out = self.bn1(out)\n",
    "#         out = self.relu1(out)\n",
    "        \n",
    "#         out = self.conv2(out)\n",
    "#         out = self.bn2(out)\n",
    "#         out = self.relu2(out)\n",
    "         \n",
    "#         out = self.conv3(out)\n",
    "#         out = self.bn3(out)\n",
    "#         out = self.relu3(out)\n",
    "        \n",
    "#         return out\n",
    "# class HeadBlock(IdentityBlock):\n",
    "#     def __init__(self, in_channels, mid_channels, out_channels, stride=1):\n",
    "#         super(HeadBlock, self).__init__(in_channels, mid_channels, out_channels, stride)\n",
    "        \n",
    "#         self.shortcut = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "#             nn.BatchNorm2d(out_channels)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         identity = x\n",
    "#         out = super().forward(x)\n",
    "        \n",
    "#         if identity.size() != out.size():\n",
    "#             identity = F.interpolate(identity, size=out.size()[2:])\n",
    "#         identity = self.shortcut(identity)\n",
    "        \n",
    "#         out += identity\n",
    "#         out = self.relu3(out)\n",
    "        \n",
    "#         return out\n",
    "# #인코더 블럭\n",
    "# class Conv2(nn.Module):\n",
    "#     def __init__(self,in_channels, mid_channels, out_channels):\n",
    "#         super(Conv2,self).__init__() \n",
    "#         self.headblock = HeadBlock(in_channels,mid_channels,out_channels)\n",
    "#         self.identityblock1 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "#         self.identityblock2 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "#     def forward(self,x):\n",
    "#         x = self.headblock(x)\n",
    "#         x = self.identityblock1(x)\n",
    "#         x = self.identityblock2(x)\n",
    "#         p = self.maxpool(x)\n",
    "#         return x , p\n",
    "# class Conv3(nn.Module):\n",
    "#     def __init__(self,in_channels, mid_channels, out_channels):\n",
    "#         super(Conv3,self).__init__() \n",
    "#         self.headblock = HeadBlock(in_channels,mid_channels,out_channels)\n",
    "#         self.identityblock1 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "#         self.identityblock2 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "#         self.identityblock3 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "#     def forward(self,x):\n",
    "#         x = self.headblock(x)\n",
    "#         x = self.identityblock1(x)\n",
    "#         x = self.identityblock2(x)\n",
    "#         x = self.identityblock3(x)\n",
    "#         p = self.maxpool(x)\n",
    "#         return x , p\n",
    "# class Conv4(nn.Module):\n",
    "#     def __init__(self,in_channels, mid_channels, out_channels):\n",
    "#         super(Conv4,self).__init__() \n",
    "#         self.headblock = HeadBlock(in_channels,mid_channels,out_channels)\n",
    "#         self.identityblock1 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "#         self.identityblock2 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "#         self.identityblock3 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "#         self.identityblock4 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "#         self.identityblock5 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "#     def forward(self,x):\n",
    "#         x = self.headblock(x)\n",
    "#         x = self.identityblock1(x)\n",
    "#         x = self.identityblock2(x)\n",
    "#         x = self.identityblock3(x)\n",
    "#         x = self.identityblock4(x)\n",
    "#         x = self.identityblock5(x)\n",
    "#         p = self.maxpool(x)\n",
    "#         return x , p\n",
    "# class Conv5(nn.Module):\n",
    "#     def __init__(self,in_channels, mid_channels, out_channels):\n",
    "#         super(Conv5,self).__init__() \n",
    "#         self.headblock = HeadBlock(in_channels,mid_channels,out_channels)\n",
    "#         self.identityblock1 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "#         self.identityblock2 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "#     def forward(self,x):\n",
    "#         x = self.headblock(x)\n",
    "#         x = self.identityblock1(x)\n",
    "#         x = self.identityblock2(x)\n",
    "#         p = self.maxpool(x)\n",
    "#         return x , p\n",
    "# #디코더 블럭\n",
    "# class DecoderBlock(nn.Module):\n",
    "#     def __init__(self, channels):\n",
    "#         super(DecoderBlock, self).__init__()\n",
    "#         self.upsample = nn.ConvTranspose2d(channels*2, channels, kernel_size=4, stride=2, padding=1, output_padding=1) # output_padding 추가\n",
    "#         self.convblock1 = ConvBlock(channels*2, channels)\n",
    "\n",
    "#     def forward(self, x, skip):\n",
    "#         x = self.upsample(x)\n",
    "#         if x.size(2) != skip.size(2) or x.size(3) != skip.size(3):\n",
    "#             x = F.interpolate(x, size=(skip.size(2), skip.size(3)))\n",
    "#         x = torch.cat([x, skip], dim=1)\n",
    "#         x = self.convblock1(x)\n",
    "#         return x\n",
    "\n",
    "# #Unet구조 middle의 xm값의 움직임에 주의\n",
    "# class Resnet50_Unet(nn.Module):\n",
    "#     def __init__(self,n_classes):\n",
    "#         super(Resnet50_Unet,self).__init__()\n",
    "#         self.fconv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2)\n",
    "#         self.fbn1 = nn.BatchNorm2d(64)\n",
    "#         self.frelu1 = nn.ReLU()\n",
    "#         self.fconv2 = nn.Conv2d(64, 128, kernel_size=1, stride=1)\n",
    "#         self.fbn2 = nn.BatchNorm2d(128)\n",
    "#         self.frelu2 = nn.ReLU()\n",
    "#         self.fmaxpooling = nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "        \n",
    "#         self.conv2 = Conv2(128,64,256)\n",
    "#         self.conv3 = Conv3(256,128,512)\n",
    "#         self.conv4 = Conv4(512,256,1024)\n",
    "#         self.conv5 = Conv5(1024,512,2048)\n",
    "        \n",
    "#         self.middleconv = ConvBlock(2048,4096)\n",
    "#         self.dropout = nn.Dropout2d(0.4) #\n",
    "           \n",
    "#         self.decoder5 = DecoderBlock(2048)\n",
    "#         self.decoder4 = DecoderBlock(1024)\n",
    "#         self.decoder3 = DecoderBlock(512)\n",
    "#         self.decoder2 = DecoderBlock(256)\n",
    "#         self.decoder1 = DecoderBlock(128)\n",
    "        \n",
    "#         self.segmap = nn.Conv2d(128,n_classes, kernel_size=1)\n",
    "#         self.domain_classifier = domain_classifier()\n",
    "        \n",
    "#     def forward(self,x):\n",
    "#         x = self.fconv1(x)#3->64\n",
    "#         x = self.fbn1(x)\n",
    "#         x = self.frelu1(x)\n",
    "#         x = self.fconv2(x)\n",
    "#         x = self.fbn2(x)\n",
    "#         x1 = self.frelu2(x)\n",
    "#         p = self.fmaxpooling(x)#첫 conv: x0([8, 64, 109, 109]) p([8, 64, 54, 54])\n",
    "#         x2,p = self.conv2(p)#conv2:  x1:([8, 256, 54, 54]) p([8, 256, 26, 26])\n",
    "#         x3,p = self.conv3(p)#conv3:  x2([8, 512, 26, 26]) p([8, 512, 12, 12])\n",
    "#         x4,p = self.conv4(p)#conv4:  x3([8, 1024, 12, 12]) p([8, 1024, 5, 5])\n",
    "#         x5,p = self.conv5(p)#conv5:  x4([8, 2048, 5, 5]) p([8, 2048, 2, 2])\n",
    "        \n",
    "#         xm = self.middleconv(p)#xm([8, 4096, 2, 2])\n",
    "#         xm = self.dropout(xm)\n",
    "        \n",
    "#         x = self.decoder5(xm,x5)#뉴런:2048*2->2048 1\n",
    "#         x = self.decoder4(x,x4)#뉴런:1024*2->1024 \n",
    "#         x = self.decoder3(x,x3) #14\n",
    "#         x = self.decoder2(x,x2)#28\n",
    "#         x = self.decoder1(x,x1)#55\n",
    "        \n",
    "#         x = F.interpolate(x, size=(224, 224))\n",
    "#         x_c = self.segmap(x)\n",
    "#         x_d = self.domain_classifier(x)\n",
    "#         #print(x.shape)\n",
    "#         return x_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    \n",
    "    # 이미지를 0과 1 사이의 값으로 스케일 조정\n",
    "    normalized_image = image / 255.0\n",
    "    \n",
    "    # 평균을 빼고 표준 편차로 나누어 정규화\n",
    "    normalized_image = (normalized_image - mean) / std\n",
    "    \n",
    "    return normalized_image\n",
    "\n",
    "def make_bumper(image):\n",
    "    h,w,c = image.shape\n",
    "    center = (w//2, int(h*0.375))  # x,y\n",
    "    axis_length = (w//2, int(h*0.64))  # 장축 반지름과 단축 반지름\n",
    "\n",
    "    # 타원 그리기 (타원을 1로 채우고 나머지 부분은 0으로 채움)\n",
    "    oval = np.zeros((h,w,1),dtype=np.uint8)\n",
    "    cv2.ellipse(oval, center, axis_length, 0, 0, 360, 1, -1)\n",
    "\n",
    "    target_image_path = './data/224/train_target_image/TRAIN_TARGET_0001.png'\n",
    "    target_image = cv2.imread(target_image_path, cv2.IMREAD_COLOR)\n",
    "    target_image = cv2.cvtColor(target_image, cv2.COLOR_BGR2RGB)\n",
    "    target_image = normalize_image(target_image)\n",
    "\n",
    "    mixed_image = image * oval + target_image * (1-oval)\n",
    "\n",
    "    return mixed_image\n",
    "\n",
    "\n",
    "\n",
    "def apply_fisheye_distortion(images, masks=None, label=1):\n",
    "    # 이미지 크기 가져오기\n",
    "    batch, channel, height, width = images.shape\n",
    "\n",
    "    # 카메라 매트릭스 생성\n",
    "    focal_length = width / 2\n",
    "    center_x = width / 2\n",
    "    center_y = height / 2\n",
    "    camera_matrix = np.array([[focal_length, 0, center_x],\n",
    "                              [0, focal_length, center_y],\n",
    "                              [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "    # 왜곡 계수 생성\n",
    "    label = random.randint(0, label)\n",
    "    #print(label)\n",
    "    dist_coeffs = np.array([0, 0.075 * label, 0, 0], dtype=np.float32)\n",
    "\n",
    "    # 왜곡 보정\n",
    "    undistorted_images = []\n",
    "    undistorted_masks = []\n",
    "\n",
    "    for i in range(batch):\n",
    "        image = images[i].permute(1, 2, 0).cpu().numpy()\n",
    "        undistorted_image = cv2.undistort(image, camera_matrix, dist_coeffs)\n",
    "        undistorted_image = torch.from_numpy(undistorted_image).permute(2, 0, 1).float().to(device)\n",
    "        undistorted_image = make_bumper(undistorted_image)\n",
    "        undistorted_images.append(undistorted_image)\n",
    "        \n",
    "        if masks is not None:\n",
    "            mask = masks[i].cpu().numpy()\n",
    "            undistorted_mask = cv2.undistort(mask, camera_matrix, dist_coeffs)\n",
    "            undistorted_mask = np.round(undistorted_mask).astype(np.uint8)\n",
    "            undistorted_mask[undistorted_mask > 12] = 12\n",
    "            undistorted_mask = torch.from_numpy(undistorted_mask).long().to(device)\n",
    "            undistorted_masks.append(undistorted_mask)\n",
    "\n",
    "    undistorted_images = torch.stack(undistorted_images, dim=0)\n",
    "\n",
    "    if masks is not None:\n",
    "        undistorted_masks = torch.stack(undistorted_masks, dim=0)\n",
    "    else:\n",
    "        undistorted_masks = None\n",
    "\n",
    "    return undistorted_images, undistorted_masks\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False, apply_distortion=False, label=1):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "        self.apply_distortion = apply_distortion\n",
    "        self.label = label\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #directory_path = \"/mnt/nas27/Dataset/Samsung_DM\"\n",
    "        directory_path = './data/224'\n",
    "        img_path = self.data.iloc[idx, 1]\n",
    "        img_path = os.path.join(directory_path, img_path)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = np.transpose(image, (2, 0, 1))\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if self.apply_distortion:\n",
    "            image, _ = apply_fisheye_distortion(torch.tensor(image).unsqueeze(0), None, self.label)\n",
    "            image = image.squeeze(0).cpu().numpy()\n",
    "            \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "\n",
    "        return image\n",
    "\n",
    "transform = A.Compose([\n",
    "    #A.Normalize(),\n",
    "    ToTensorV2(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/MMI24limbyungwan/Design_Project/Design_project/Clustering.ipynb 셀 9\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/Clustering.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m distorted_data_iter \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(dataloader_distorted)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/Clustering.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m original \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(original_data_iter)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/Clustering.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m distorted \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(distorted_data_iter)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/Clustering.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# 모델을 통과\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/Clustering.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/.conda/envs/byungwan_resn/lib/python3.8/site-packages/torch/utils/data/dataloader.py:517\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    516\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 517\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    518\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    519\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    520\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    521\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/byungwan_resn/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    556\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    558\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    559\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/.conda/envs/byungwan_resn/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:44\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     43\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 44\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     45\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/byungwan_resn/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:44\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     43\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 44\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     45\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32m/home/MMI24limbyungwan/Design_Project/Design_project/Clustering.ipynb 셀 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/Clustering.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=96'>97</a>\u001b[0m \u001b[39m#image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/Clustering.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=98'>99</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_distortion:\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/Clustering.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=99'>100</a>\u001b[0m     image, _ \u001b[39m=\u001b[39m apply_fisheye_distortion(torch\u001b[39m.\u001b[39;49mtensor(image)\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m), \u001b[39mNone\u001b[39;49;00m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/Clustering.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=100'>101</a>\u001b[0m     image \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/Clustering.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=102'>103</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer:\n",
      "\u001b[1;32m/home/MMI24limbyungwan/Design_Project/Design_project/Clustering.ipynb 셀 9\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/Clustering.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m undistorted_image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mundistort(image, camera_matrix, dist_coeffs)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/Clustering.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m undistorted_image \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(undistorted_image)\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/Clustering.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m undistorted_image \u001b[39m=\u001b[39m make_bumper(undistorted_image)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/Clustering.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m undistorted_images\u001b[39m.\u001b[39mappend(undistorted_image)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/Clustering.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39mif\u001b[39;00m masks \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;32m/home/MMI24limbyungwan/Design_Project/Design_project/Clustering.ipynb 셀 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/Clustering.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m target_image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(target_image, cv2\u001b[39m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/Clustering.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m target_image \u001b[39m=\u001b[39m normalize_image(target_image)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/Clustering.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m mixed_image \u001b[39m=\u001b[39m image \u001b[39m*\u001b[39;49m oval \u001b[39m+\u001b[39m target_image \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m\u001b[39m-\u001b[39moval)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/Clustering.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mreturn\u001b[39;00m mixed_image\n",
      "File \u001b[0;32m~/.conda/envs/byungwan_resn/lib/python3.8/site-packages/torch/tensor.py:621\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__array__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    620\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    622\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "# 원본 데이터 로드\n",
    "dataset_original = CustomDataset('./data/train_source.csv', transform=transform)\n",
    "#dataset_original = CustomDataset('./dataset/train_source.csv', transform=transform)\n",
    "dataloader_original = DataLoader(dataset_original, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "dataset_distorted = CustomDataset('./data/train_source.csv', transform=transform, apply_distortion=True, label=1)\n",
    "#dataset_distorted = CustomDataset('./dataset/test.csv', transform=transform, apply_distortion=True,label=3)\n",
    "dataloader_distorted = DataLoader(dataset_distorted, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "#모델 불러오기\n",
    "model = Resnet34_Unet(n_classes=13).to(device)\n",
    "model.load_state_dict(torch.load('./data/resnet34_1113_dropout_bumper.pth'), strict=False)\n",
    "model.eval()\n",
    "\n",
    "features = []\n",
    "def hook_fn(module, input, output):\n",
    "    features.append(output)\n",
    "    \n",
    "layer_to_get = model.transpose\n",
    "hook = layer_to_get.register_forward_hook(hook_fn)\n",
    "\n",
    "# 데이터 로드\n",
    "original_data_iter = iter(dataloader_original)\n",
    "distorted_data_iter = iter(dataloader_distorted)\n",
    "original = next(original_data_iter).float().to(device)\n",
    "distorted = next(distorted_data_iter).float().to(device)\n",
    "\n",
    "# 모델을 통과\n",
    "with torch.no_grad():\n",
    "    model(original)\n",
    "    original_features = torch.cat(features).cpu().numpy()\n",
    "    features.clear()\n",
    "    \n",
    "    model(distorted)\n",
    "    distorted_features = torch.cat(features).cpu().numpy()\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "# 3. t-SNE 변환\n",
    "tsne = TSNE(n_components=2)\n",
    "original = original.cpu()\n",
    "distorted = distorted.cpu()\n",
    "df = pd.DataFrame(np.concatenate([original.reshape(original.shape[0], -1), distorted.reshape(distorted.shape[0], -1)], 0))\n",
    "image_tsne = tsne.fit_transform(df)\n",
    "\n",
    "original_first = original_features[:, 0, :, :]\n",
    "distorted_first = distorted_features[:, 0, :, :]\n",
    "\n",
    "df = pd.DataFrame(np.concatenate([original_first.reshape(original_first.shape[0], -1), distorted_first.reshape(distorted_first.shape[0], -1)], 0))\n",
    "#df = pd.DataFrame(np.concatenate([original_features.reshape(original_features.shape[0], -1), distorted_features.reshape(distorted_features.shape[0], -1)], 0))\n",
    "features_tsne = tsne.fit_transform(df)\n",
    "# 4. 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# 왼쪽: 원본 이미지의 t-SNE 결과\n",
    "plt.subplot(1, 2, 1)\n",
    "i0 = image_tsne[:BATCH_SIZE]\n",
    "i1 = image_tsne[BATCH_SIZE:]\n",
    "plt.scatter(i0[:, 0], i0[:, 1], c='r', label='Source Domain')\n",
    "plt.scatter(i1[:, 0], i1[:, 1], c='b', label='Target Domain')\n",
    "plt.title('Original Images')\n",
    "plt.legend()\n",
    "\n",
    "f0 = features_tsne[:BATCH_SIZE]\n",
    "f1 = features_tsne[BATCH_SIZE:]\n",
    "# 오른쪽: 모델을 통과한 feature map의 t-SNE 결과\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(f0[:, 0], f0[:, 1], c='r', label='Source Domain')\n",
    "plt.scatter(f1[:, 0], f1[:, 1], c='b', label='Target Domain')\n",
    "plt.title('Model Features')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "# import matplotlib.pyplot as plt\n",
    "# # 3. t-SNE 변환\n",
    "# tsne = TSNE(n_components=2)\n",
    "# df = pd.DataFrame(np.concatenate([original_features_trained.reshape(original_features_trained.shape[0], -1), distorted_features_trained.reshape(distorted_features_trained.shape[0], -1)], 0))\n",
    "# trained_tsne = tsne.fit_transform(df)\n",
    "# df = pd.DataFrame(np.concatenate([original_features_untrained.reshape(original_features_untrained.shape[0], -1), distorted_features_untrained.reshape(distorted_features_untrained.shape[0], -1)], 0))\n",
    "# untrained_tsne = tsne.fit_transform(df)\n",
    "# # 4. 시각화\n",
    "# plt.figure(figsize=(12, 6))\n",
    "\n",
    "# # 왼쪽: 원본 이미지의 t-SNE 결과\n",
    "# plt.subplot(1, 2, 1)\n",
    "# i0 = trained_tsne[:100]\n",
    "# i1 = trained_tsne[100:]\n",
    "# plt.scatter(i0[:, 0], i0[:, 1], c='r', label='Source Domain')\n",
    "# plt.scatter(i1[:, 0], i1[:, 1], c='b', label='Target Domain')\n",
    "# plt.title('Trained')\n",
    "# plt.legend()\n",
    "\n",
    "# f0 = untrained_tsne[:100]\n",
    "# f1 = untrained_tsne[100:]\n",
    "# # 오른쪽: 모델을 통과한 feature map의 t-SNE 결과\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.scatter(f0[:, 0], f0[:, 1], c='r', label='Source Domain')\n",
    "# plt.scatter(f1[:, 0], f1[:, 1], c='b', label='Target Domain')\n",
    "# plt.title('Untrained')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import torchvision\n",
    "\n",
    "# # original 이미지 플롯\n",
    "# def plot_images(images, title):\n",
    "#     batch_size, num_channels, height, width = images.shape\n",
    "#     fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "#     fig.suptitle(title, fontsize=16)\n",
    "\n",
    "#     for i in range(3):\n",
    "#         # 이미지를 [0, 1] 범위로 정규화\n",
    "#         image = images[i].cpu().permute(1, 2, 0)\n",
    "#         image = (image - image.min()) / (image.max() - image.min())\n",
    "#         axes[i].imshow(image)\n",
    "#         axes[i].axis('off')\n",
    "\n",
    "# # original 이미지 플롯\n",
    "# plot_images(original, title='Original Images')\n",
    "# plt.show()\n",
    "\n",
    "# # distorted 이미지 플롯\n",
    "# plot_images(distorted, title='Distorted Images')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
