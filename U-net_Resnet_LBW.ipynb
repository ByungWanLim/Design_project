{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d73d24e3-5c9e-4ade-9e6e-ca6f46a2d914",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad9b681e-370a-4cfa-a452-dd2d7f0cd77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torchvision import models\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51fb2d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# GPU 사용이 가능할 경우, GPU를 사용할 수 있게 함.'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "print(device)\n",
    "\n",
    "print(os.environ.get('CUDA_VISIBLE_DEVICES'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20ff3de5-0d0e-497b-ac75-d5179a3f65d3",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "838e1d83-8670-407b-82f6-bf9652f58639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be76a29e-e9c2-411a-a569-04166f074184",
   "metadata": {},
   "source": [
    "## Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8496767-2f64-4285-bec4-c6f53a1fd9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        directory_path = \"/mnt/nas27/Dataset/Samsung_DM\"\n",
    "        img_path = self.data.iloc[idx, 1]\n",
    "        img_path = os.path.join(directory_path, img_path[2:])\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "        \n",
    "        mask_path = self.data.iloc[idx, 2]\n",
    "        mask_path = os.path.join(directory_path, mask_path[2:])\n",
    "        mask = cv2.imread(mask_path)\n",
    "        #mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        mask[mask == 255] = 12 #배경을 픽셀값 12로 간주\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc955893-22fd-4320-88be-7aa0d790cbd9",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65dabc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 전처리 클래스\n",
    "class ImageTransform():\n",
    "  \"\"\"\n",
    "  훈련, 검증 동작 다르게 설정\n",
    "  이미지 크기 resize, 색상 표준화\n",
    "  훈련시 RandomResizedCrop, RandomHorizontalFilp으로 데이터 확장\n",
    "  \"\"\"\n",
    "  def __init__(self, resize, mean, std):\n",
    "    self.data_transform = {\n",
    "        'train' : transforms.Compose([\n",
    "            #transforms.RandomResizedCrop(\n",
    "            #    resize, scale = (0.5, 1.0)), # 데이터 확장\n",
    "            transforms.RandomHorizontalFlip(), # 데이터 확장\n",
    "            transforms.ToTensor(), # Tensor로 변환\n",
    "            transforms.Normalize(mean = mean, std = std) #표준화\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            #transforms.Resize(resize), # Resize\n",
    "            #transforms.CenterCrop(resize), # 중앙을 resize*resize로 crop\n",
    "            transforms.ToTensor(), # Tensor로 변환\n",
    "            transforms.Normalize(mean = mean, std = std) # 표준화\n",
    "        ])\n",
    "\n",
    "    }\n",
    "  def __call__(self, img, phase = 'train'):\n",
    "    \"\"\"\n",
    "    phase : 'train' or 'test'\n",
    "    전처리 모드 지정\n",
    "    \"\"\"\n",
    "    return self.data_transform[phase](img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b708503-2ff9-4584-9d73-40990b3572f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose(\n",
    "    [   \n",
    "        #A.Resize(224, 224),\n",
    "        A.Resize(256, 256),\n",
    "        A.Normalize(),\n",
    "        \n",
    "        # 변형\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        # A.RandomRotate90(p=0.5),\n",
    "        A.HueSaturationValue(p=0.2),\n",
    "        \n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./train_source.csv'), transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "valid_dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./val_source.csv'), transform=transform)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1096fe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스(레이블) 수\n",
    "num_classes = 12\n",
    "\n",
    "# 클래스별 IoU를 계산하기 위한 함수\n",
    "def calculate_iou_per_class(y_true, y_pred, class_id):\n",
    "    intersection = np.sum((y_true == class_id) & (y_pred == class_id))\n",
    "    union = np.sum((y_true == class_id) | (y_pred == class_id))\n",
    "    iou = intersection / union if union > 0 else 0\n",
    "    return iou"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f42501fc-b573-4893-a7c4-5e280dfdaf09",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65960bfb-803a-4c40-b713-6f647779e4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channel, mid_channel, out_channel):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channel, mid_channel, kernel_size=3, stride=1, padding=1) #keep ratio\n",
    "        self.conv_trans = nn.ConvTranspose2d(mid_channel, out_channel, kernel_size=4, stride=2, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv(x), inplace=True)\n",
    "        x = F.relu(self.conv_trans(x), inplace=True)\n",
    "        return x\n",
    "    \n",
    "class Unet_resnet18(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(Unet_resnet18, self).__init__()\n",
    "        \n",
    "        #encoder\n",
    "        self.encoder = models.resnet18(pretrained=False)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv1 = nn.Sequential(self.encoder.conv1, self.encoder.bn1,\n",
    "                                  self.encoder.relu, self.pool) #64\n",
    "        self.conv2 = self.encoder.layer1 #64\n",
    "        self.conv3 = self.encoder.layer2 #128\n",
    "        self.conv4 = self.encoder.layer3 #256\n",
    "        self.conv5 = self.encoder.layer4 #depth 512\n",
    "        \n",
    "        #center\n",
    "        self.center = Decoder(512, 312, 256)\n",
    "        \n",
    "        #decoder\n",
    "        self.decoder5 = Decoder(256+512, 256, 256)\n",
    "        self.decoder4 = Decoder(256+256, 128, 128)\n",
    "        self.decoder3 = Decoder(128+128, 64, 64)\n",
    "        self.decoder2 = Decoder(64+64, 32, 32)\n",
    "        self.decoder1 = Decoder(32, 16, 16)\n",
    "        self.decoder0 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "    \n",
    "        self.final = nn.Conv2d(8, n_classes, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #encoder\n",
    "        conv1 = self.conv1(x) #64x64\n",
    "        conv2 = self.conv2(conv1) #32x32\n",
    "        conv3 = self.conv3(conv2) #16x16\n",
    "        conv4 = self.conv4(conv3) #8x8\n",
    "        conv5 = self.conv5(conv4) #4x4\n",
    "        \n",
    "        center = self.center(self.pool(conv5)) #4x4\n",
    "        #decoder\n",
    "        dec5 = self.decoder5(torch.cat([center, conv5], 1)) #8x8\n",
    "        dec4 = self.decoder4(torch.cat([dec5, conv4], 1)) #16x16\n",
    "        dec3 = self.decoder3(torch.cat([dec4, conv3], 1)) #32x32\n",
    "        dec2 = self.decoder2(torch.cat([dec3, conv2], 1)) #64x64\n",
    "        dec1 = self.decoder1(dec2) #128x128\n",
    "        dec0 = F.relu(self.decoder0(dec1))\n",
    "        \n",
    "        final = torch.sigmoid(self.final(dec0))\n",
    "        \n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "baf22f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channel, mid_channel, out_channel):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channel, mid_channel, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_trans = nn.ConvTranspose2d(mid_channel, out_channel, kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv(x), inplace=True)\n",
    "        x = F.relu(self.conv_trans(x), inplace=True)\n",
    "        return x\n",
    "\n",
    "class Unet_resnet50(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(Unet_resnet50, self).__init__()\n",
    "\n",
    "        # Encoder (ResNet-50)\n",
    "        self.encoder = models.resnet50(pretrained=True)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv1 = nn.Sequential(self.encoder.conv1, self.encoder.bn1, self.encoder.relu, self.pool)\n",
    "        self.conv2 = self.encoder.layer1\n",
    "        self.conv3 = self.encoder.layer2\n",
    "        self.conv4 = self.encoder.layer3\n",
    "        self.conv5 = self.encoder.layer4\n",
    "\n",
    "        # Center\n",
    "        self.center = Decoder(2048, 1024, 512)  # Adjusted for ResNet-50\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder5 = Decoder(512 + 2048, 1024, 512)  # Adjusted for ResNet-50\n",
    "        self.decoder4 = Decoder(512 + 1024, 512, 256)  # Adjusted for ResNet-50\n",
    "        self.decoder3 = Decoder(256 + 512, 256, 128)   # Adjusted for ResNet-50\n",
    "        self.decoder2 = Decoder(128 + 256, 128, 64)    # Adjusted for ResNet-50\n",
    "        self.decoder1 = Decoder(64, 32, 32)\n",
    "        self.decoder0 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.final = nn.Conv2d(16, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        conv1 = self.conv1(x)\n",
    "        conv2 = self.conv2(conv1)\n",
    "        conv3 = self.conv3(conv2)\n",
    "        conv4 = self.conv4(conv3)\n",
    "        conv5 = self.conv5(conv4)\n",
    "\n",
    "        center = self.center(self.pool(conv5))\n",
    "\n",
    "        # Decoder\n",
    "        dec5 = self.decoder5(torch.cat([center, conv5], 1))\n",
    "        dec4 = self.decoder4(torch.cat([dec5, conv4], 1))\n",
    "        dec3 = self.decoder3(torch.cat([dec4, conv3], 1))\n",
    "        dec2 = self.decoder2(torch.cat([dec3, conv2], 1))\n",
    "        dec1 = self.decoder1(dec2)\n",
    "        dec0 = F.relu(self.decoder0(dec1))\n",
    "\n",
    "        final = torch.sigmoid(self.final(dec0))\n",
    "\n",
    "        return final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd34483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 초기화\n",
    "model = Unet_resnet18(n_classes = 13).to(device)\n",
    "#model = Unet_resnet50(n_classes = 13).to(device)\n",
    "\n",
    "# loss function과 optimizer 정의\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0895765-fba0-4fd9-b955-a6c0e43012e9",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dec3e516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:nclo18wj) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train loss</td><td>█▁▁▁</td></tr><tr><td>train score</td><td>█▁▁▁</td></tr><tr><td>val loss</td><td>▁█▆█</td></tr><tr><td>val score</td><td>▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train loss</td><td>151.59922</td></tr><tr><td>train score</td><td>0.01339</td></tr><tr><td>val loss</td><td>32.82194</td></tr><tr><td>val score</td><td>0.01447</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fallen-glade-2</strong> at: <a href='https://wandb.ai/limbw/practice_09_28/runs/nclo18wj' target=\"_blank\">https://wandb.ai/limbw/practice_09_28/runs/nclo18wj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230928_163746-nclo18wj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:nclo18wj). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/MMI24limbyungwan/Design_Project/Design_project/wandb/run-20230928_165150-3kebrt70</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/limbw/practice_09_28/runs/3kebrt70' target=\"_blank\">icy-hill-3</a></strong> to <a href='https://wandb.ai/limbw/practice_09_28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/limbw/practice_09_28' target=\"_blank\">https://wandb.ai/limbw/practice_09_28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/limbw/practice_09_28/runs/3kebrt70' target=\"_blank\">https://wandb.ai/limbw/practice_09_28/runs/3kebrt70</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [02:12<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 IoU: 0.0141\n",
      "Class 1 IoU: 0.0143\n",
      "Class 2 IoU: 0.0145\n",
      "Class 3 IoU: 0.0120\n",
      "Class 4 IoU: 0.0142\n",
      "Class 5 IoU: 0.0139\n",
      "Class 6 IoU: 0.0136\n",
      "Class 7 IoU: 0.0117\n",
      "Class 8 IoU: 0.0137\n",
      "Class 9 IoU: 0.0137\n",
      "Class 10 IoU: 0.0144\n",
      "Class 11 IoU: 0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:17<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 IoU: 0.0221\n",
      "Class 1 IoU: 0.0113\n",
      "Class 2 IoU: 0.0108\n",
      "Class 3 IoU: 0.0124\n",
      "Class 4 IoU: 0.0234\n",
      "Class 5 IoU: 0.0121\n",
      "Class 6 IoU: 0.0111\n",
      "Class 7 IoU: 0.0109\n",
      "Class 8 IoU: 0.0246\n",
      "Class 9 IoU: 0.0118\n",
      "Class 10 IoU: 0.0116\n",
      "Class 11 IoU: 0.0119\n",
      "\n",
      "Epoch1\n",
      "Train Loss: 2.3387430681698564, Train mIoU Score: 0.0135\n",
      "Validation Loss: 2.2608136494954425, Validation mIoU Score: 0.0145\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:18<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 IoU: 0.0141\n",
      "Class 1 IoU: 0.0140\n",
      "Class 2 IoU: 0.0139\n",
      "Class 3 IoU: 0.0115\n",
      "Class 4 IoU: 0.0139\n",
      "Class 5 IoU: 0.0140\n",
      "Class 6 IoU: 0.0139\n",
      "Class 7 IoU: 0.0114\n",
      "Class 8 IoU: 0.0137\n",
      "Class 9 IoU: 0.0144\n",
      "Class 10 IoU: 0.0144\n",
      "Class 11 IoU: 0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:17<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 IoU: 0.0221\n",
      "Class 1 IoU: 0.0113\n",
      "Class 2 IoU: 0.0110\n",
      "Class 3 IoU: 0.0124\n",
      "Class 4 IoU: 0.0234\n",
      "Class 5 IoU: 0.0121\n",
      "Class 6 IoU: 0.0112\n",
      "Class 7 IoU: 0.0109\n",
      "Class 8 IoU: 0.0247\n",
      "Class 9 IoU: 0.0118\n",
      "Class 10 IoU: 0.0117\n",
      "Class 11 IoU: 0.0119\n",
      "\n",
      "Epoch2\n",
      "Train Loss: 2.2601535804029824, Train mIoU Score: 0.0134\n",
      "Validation Loss: 2.240032116572062, Validation mIoU Score: 0.0145\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 26/69 [00:36<01:00,  1.40s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/MMI24limbyungwan/Design_Project/Design_project/U-net_Resnet_LBW.ipynb 셀 17\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/U-net_Resnet_LBW.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# train 클래스별 IoU 계산\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/U-net_Resnet_LBW.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msoftmax(outputs, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcpu()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/U-net_Resnet_LBW.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49margmax(outputs, dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/U-net_Resnet_LBW.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mfor\u001b[39;00m class_id \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_classes):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/U-net_Resnet_LBW.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m     iou \u001b[39m=\u001b[39m calculate_iou_per_class(np\u001b[39m.\u001b[39marray(masks\u001b[39m.\u001b[39mcpu()), np\u001b[39m.\u001b[39marray(outputs), class_id)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"practice_09_28\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.005,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"Samsung\",\n",
    "    \"epochs\": 20,\n",
    "    }\n",
    ")\n",
    "\n",
    "for epoch in range(5):  # 5 에폭 동안 학습합니다.\n",
    "          \n",
    "    # 클래스별 IoU를 누적할 리스트 초기화\n",
    "    train_class_ious = []\n",
    "    \n",
    "    # 학습\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for images, masks in tqdm(dataloader):\n",
    "        images = images.float().to(device)\n",
    "        masks = masks.long().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks.squeeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # train 클래스별 IoU 계산\n",
    "        outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "        outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "\n",
    "        for class_id in range(num_classes):\n",
    "            iou = calculate_iou_per_class(np.array(masks.cpu()), np.array(outputs), class_id)\n",
    "            train_class_ious.append(iou)\n",
    "            \n",
    "    train_class_ious = np.array(train_class_ious).reshape(num_classes, -1)\n",
    "    #print(np.shape(train_class_ious))\n",
    "    train_class_ious = np.mean(train_class_ious, axis=1)\n",
    "    #print(train_class_ious)\n",
    "    \n",
    "    for class_id, iou in enumerate(train_class_ious):\n",
    "        print(f'Class {class_id} IoU: {iou:.4f}')\n",
    "     \n",
    "        \n",
    "    # mIoU 계산\n",
    "    train_mIoU = np.mean(train_class_ious)\n",
    "    \n",
    "\n",
    "    # validation\n",
    "    val_loss = 0\n",
    "    val_class_ious = []  # 클래스별 IoU를 누적할 리스트 초기화\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for images, masks in tqdm(valid_dataloader):\n",
    "            images = images.float().to(device)\n",
    "            masks = masks.long().to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            # validation loss 계산\n",
    "            val_loss += criterion(outputs, masks.squeeze(1)).item()\n",
    "\n",
    "            # validation 클래스별 IoU 계산\n",
    "            outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "            outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "\n",
    "            for class_id in range(num_classes):\n",
    "                iou = calculate_iou_per_class(np.array(masks.cpu()), np.array(outputs), class_id)\n",
    "                val_class_ious.append(iou)\n",
    "                \n",
    "    val_class_ious = np.array(val_class_ious).reshape(num_classes, -1)\n",
    "    val_class_ious = np.mean(val_class_ious, axis=1)\n",
    "    \n",
    "    for class_id, iou in enumerate(val_class_ious):\n",
    "        print(f'Class {class_id} IoU: {iou:.4f}')       \n",
    "   \n",
    "    # mIoU 계산\n",
    "    val_mIoU = np.mean(val_class_ious)\n",
    "    \n",
    "    # 에폭마다 결과 출력\n",
    "    print(f\"\\nEpoch{epoch+1}\")\n",
    "    print(f\"Train Loss: {epoch_loss/len(dataloader)}, Train mIoU Score: {train_mIoU:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss/len(valid_dataloader)}, Validation mIoU Score: {val_mIoU:.4f}\")\n",
    "    print(\"___________________________________________________________________________________________\\n\")\n",
    "    \n",
    "    # log metrics to wandb\n",
    "    wandb.log({\"train score\": train_mIoU, \"train loss\": epoch_loss})\n",
    "    wandb.log({\"val score\": val_mIoU, \"val loss\": val_loss})\n",
    "    \n",
    "    \n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c32eb51c-a3fe-4e11-a616-3a717ba16f7e",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12371c8b-0c78-47df-89ec-2d8b55c8ea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = CustomDataset(csv_file='./test.csv', transform=transform, infer=True)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b431c-ac8e-4c40-9046-4d53e4bab14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     result = []\n",
    "#     for images in tqdm(test_dataloader):\n",
    "#         images = images.float().to(device)\n",
    "#         outputs = model(images)\n",
    "#         outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "#         outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "#         # batch에 존재하는 각 이미지에 대해서 반복\n",
    "#         for pred in outputs:\n",
    "#             pred = pred.astype(np.uint8)\n",
    "#             pred = Image.fromarray(pred) # 이미지로 변환\n",
    "#             pred = pred.resize((960, 540), Image.NEAREST) # 960 x 540 사이즈로 변환\n",
    "#             pred = np.array(pred) # 다시 수치로 변환\n",
    "#             # class 0 ~ 11에 해당하는 경우에 마스크 형성 / 12(배경)는 제외하고 진행\n",
    "#             for class_id in range(12):\n",
    "#                 class_mask = (pred == class_id).astype(np.uint8)\n",
    "#                 if np.sum(class_mask) > 0: # 마스크가 존재하는 경우 encode\n",
    "#                     mask_rle = rle_encode(class_mask)\n",
    "#                     result.append(mask_rle)\n",
    "#                 else: # 마스크가 존재하지 않는 경우 -1\n",
    "#                     result.append(-1)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36c2cbbb-04f1-4f9c-b4df-4b744dfce046",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac2a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit = pd.read_csv('./sample_submission.csv')\n",
    "# submit['mask_rle'] = result\n",
    "# submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da10cb6f-0826-4755-a376-97b695ae8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit.to_csv('./baseline_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seungyoon2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
