{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d73d24e3-5c9e-4ade-9e6e-ca6f46a2d914",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad9b681e-370a-4cfa-a452-dd2d7f0cd77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/MMI24limbyungwan/.conda/envs/byungwan_resn/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# GPU 사용이 가능할 경우, GPU를 사용할 수 있게 함.'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "print(device)\n",
    "\n",
    "print(os.environ.get('CUDA_VISIBLE_DEVICES'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20ff3de5-0d0e-497b-ac75-d5179a3f65d3",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "838e1d83-8670-407b-82f6-bf9652f58639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "# 클래스별 IoU를 계산하기 위한 함수\n",
    "def calculate_iou_per_class(y_true, y_pred, class_id):\n",
    "    intersection = np.sum((y_true == class_id) & (y_pred == class_id))\n",
    "    union = np.sum((y_true == class_id) | (y_pred == class_id))\n",
    "    iou = intersection / union if union > 0 else 0\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5c64ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "\n",
    "class GradReverseFunction(autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, l):\n",
    "        ctx.l = l\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output.neg() * ctx.l, None\n",
    "\n",
    "def grad_reverse(x, l):\n",
    "    return GradReverseFunction.apply(x, l)\n",
    "\n",
    "class GradReverse(nn.Module):\n",
    "    def __init__(self, l):\n",
    "        super(GradReverse, self).__init__()\n",
    "        self.l = nn.Parameter(torch.tensor(l), requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return grad_reverse(x, self.l)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be76a29e-e9c2-411a-a569-04166f074184",
   "metadata": {},
   "source": [
    "## Dataset, Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5acf65a",
   "metadata": {},
   "source": [
    "출력이미지 크기 키우기->ex) resnet 2048->1024->512->256 conv 256->512->1024->2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8496767-2f64-4285-bec4-c6f53a1fd9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        directory_path = \"/mnt/nas27/Dataset/Samsung_DM\"\n",
    "        img_path = self.data.iloc[idx, 1]\n",
    "        img_path = os.path.join(directory_path, img_path[2:])\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "        \n",
    "        mask_path = self.data.iloc[idx, 2]\n",
    "        mask_path = os.path.join(directory_path, mask_path[2:])\n",
    "        mask = cv2.imread(mask_path)\n",
    "        #mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        mask[mask == 255] = 12 #배경을 픽셀값 12로 간주\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "class CustomDataset_target(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        directory_path = \"/mnt/nas27/Dataset/Samsung_DM\"\n",
    "        img_path = self.data.iloc[idx, 1]\n",
    "        img_path = os.path.join(directory_path, img_path[2:])\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "            \n",
    "\n",
    "        return image\n",
    "     \n",
    "\n",
    "transform = A.Compose(\n",
    "    [   \n",
    "        A.Resize(224, 224),\n",
    "        #A.Resize(128, 128),\n",
    "        A.Normalize(),\n",
    "        \n",
    "        # 변형\n",
    "        # A.VerticalFlip(p=0.5),\n",
    "        # A.RandomRotate90(p=0.5),\n",
    "        # A.HueSaturationValue(p=0.2),\n",
    "        \n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a91d6b1",
   "metadata": {},
   "source": [
    "Warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9e62c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class WarmUpLR(_LRScheduler):\n",
    "#     def __init__(self, optimizer, total_iters, last_epoch=-1):\n",
    "#         self.total_iters = total_iters\n",
    "#         super(WarmUpLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "#     def get_lr(self):\n",
    "#         return [base_lr * self.last_epoch / self.total_iters for base_lr in self.base_lrs]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f42501fc-b573-4893-a7c4-5e280dfdaf09",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3574888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Unet의 기본이 되는 conv블럭\n",
    "# class ConvBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(ConvBlock, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "#         self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "        \n",
    "#         self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)  # 여기서 in_channels는 out_channels와 동일해야 합니다.\n",
    "#         self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.relu1(x)\n",
    "        \n",
    "#         x = self.conv2(x)\n",
    "#         x = self.bn2(x)\n",
    "#         x = self.relu2(x)\n",
    "#         return x\n",
    "\n",
    "# #인코더 블럭\n",
    "# class EncoderBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(EncoderBlock,self).__init__()\n",
    "#         self.convblock1 = ConvBlock(in_channels, out_channels)  # 첫 번째 ConvBlock의 in_channels는 입력 이미지의 채널 수와 일치해야 합니다.\n",
    "#         #self.convblock2 = ConvBlock(out_channels, out_channels)  # 두 번째 ConvBlock의 in_channels는 out_channels와 일치해야 합니다.\n",
    "#         self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "#     def forward(self,x):\n",
    "#         x = self.convblock1(x)\n",
    "#         #x = self.convblock2(x)\n",
    "#         p = self.maxpool(x)\n",
    "#         return x , p\n",
    "# #디코더 블럭\n",
    "# #디코더는 업샘플링 이후 스킵연결과 붙어서 convblock을 통과해야함\n",
    "# #skip보다 작은 x x먼저 업샘플링 32 -> 64 , skip과 결합 6464 \n",
    "# class DecoderBlock(nn.Module):\n",
    "#     def __init__(self, channels):\n",
    "#         super(DecoderBlock,self).__init__()\n",
    "#         self.upsample = nn.ConvTranspose2d(channels*2, channels, kernel_size=4, stride=2, padding=1)#x 업샘플링\n",
    "#         self.convblock1 = ConvBlock(channels*2, channels)#차원감소\n",
    "#         #self.convblock2 = ConvBlock(channels, channels)\n",
    "#     def forward(self,x,skip):\n",
    "#         x = self.upsample(x)\n",
    "#         x = torch.cat([x, skip], dim=1)\n",
    "#         x = self.convblock1(x)\n",
    "#         #x = self.convblock2(x)\n",
    "#         return x\n",
    "        \n",
    "# #Unet구조 middle의 xm값의 움직임에 주의\n",
    "# class Unet(nn.Module):\n",
    "#     def __init__(self,n_classes):\n",
    "#         super(Unet,self).__init__()\n",
    "#         self.encoder1 = EncoderBlock(3,64)\n",
    "#         self.encoder2 = EncoderBlock(64,128)\n",
    "#         self.encoder3 = EncoderBlock(128,256)\n",
    "#         self.encoder4 = EncoderBlock(256,512)\n",
    "        \n",
    "#         self.middleconv = ConvBlock(512,1024)\n",
    "        \n",
    "        \n",
    "#         self.decoder4 = DecoderBlock(512)\n",
    "#         self.decoder3 = DecoderBlock(256)\n",
    "#         self.decoder2 = DecoderBlock(128)\n",
    "#         self.decoder1 = DecoderBlock(64)\n",
    "#         self.segmap = nn.Conv2d(64,n_classes, kernel_size=1)\n",
    "        \n",
    "#         ##\n",
    "#         # self.domain_classifier = nn.Sequential(\n",
    "#         #     nn.Conv3d(1024, 64, kernel_size=3, padding=1),\n",
    "#         #     nn.ReLU(),\n",
    "#         #     nn.Conv3d(64, 32, kernel_size=3, padding=1),\n",
    "#         #     nn.ReLU(),\n",
    "#         #     nn.Flatten(),\n",
    "#         #     nn.Linear(32 * 16 * 16 * 16, 1),\n",
    "#         #     nn.Sigmoid()\n",
    "#         # )\n",
    "\n",
    "#         # self.grad_reverse = GradReverse(0.0)\n",
    "#         ##\n",
    "\n",
    "#     def forward(self,x):\n",
    "#         x1,p = self.encoder1(x)#3->64   #P:256,256 x1 :512,512\n",
    "#         x2,p = self.encoder2(p)#64->128 #P:128,128 x2:256,256\n",
    "#         x3,p = self.encoder3(p)#128->256#p:64,64 x3:128,128\n",
    "#         x4,p = self.encoder4(p)#256->512#p:32,32 x4:64,64\n",
    "        \n",
    "#         xm = self.middleconv(p)#512->1024#32,32\n",
    "        \n",
    "#         x = self.decoder4(xm,x4)#뉴런:1024->512->512 #출력tensor:64,64\n",
    "#         x = self.decoder3(x,x3)#뉴런:512->256->256 #출력tensor:128,128\n",
    "#         x = self.decoder2(x,x2)#뉴런:256->128->128 #출력tensor:256,256\n",
    "#         x = self.decoder1(x,x1)#뉴런:128->64->64 #출력tensor:512,512\n",
    "#         x = self.segmap(x)\n",
    "\n",
    "#         # 도메인 분류기에 GradReverse 적용\n",
    "#         #feat = self.grad_reverse(x)\n",
    "#         #domain_output = self.domain_classifier(x)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdb7c3b",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baf22f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unet의 기본이 되는 conv블럭\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,kernel_size = 3):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, padding=1)  # 여기서 in_channels는 out_channels와 동일해야 합니다.\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        return x\n",
    "\n",
    "class IdentityBlock(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, stride=1):\n",
    "        super(IdentityBlock, self).__init__()\n",
    "        \n",
    "        # 1x1 convolution\n",
    "        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(mid_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # 3x3 convolution\n",
    "        self.conv2 = nn.Conv2d(mid_channels, mid_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(mid_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # 1x1 convolution\n",
    "        self.conv3 = nn.Conv2d(mid_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "         \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.relu3(out)\n",
    "        \n",
    "        return out\n",
    "class HeadBlock(IdentityBlock):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, stride=1):\n",
    "        super(HeadBlock, self).__init__(in_channels, mid_channels, out_channels, stride)\n",
    "        \n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = super().forward(x)\n",
    "        \n",
    "        if identity.size() != out.size():\n",
    "            identity = F.interpolate(identity, size=out.size()[2:])\n",
    "        identity = self.shortcut(identity)\n",
    "        \n",
    "        out += identity\n",
    "        out = self.relu3(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "#인코더 블럭\n",
    "class Conv2(nn.Module):\n",
    "    def __init__(self,in_channels, mid_channels, out_channels):\n",
    "        super(Conv2,self).__init__() \n",
    "        self.headblock = HeadBlock(in_channels,mid_channels,out_channels)\n",
    "        self.identityblock1 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.identityblock2 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "    def forward(self,x):\n",
    "        x = self.headblock(x)\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        p = self.maxpool(x)\n",
    "        return x , p\n",
    "class Conv3(nn.Module):\n",
    "    def __init__(self,in_channels, mid_channels, out_channels):\n",
    "        super(Conv3,self).__init__() \n",
    "        self.headblock = HeadBlock(in_channels,mid_channels,out_channels)\n",
    "        self.identityblock1 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.identityblock2 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.identityblock3 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "    def forward(self,x):\n",
    "        x = self.headblock(x)\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        x = self.identityblock3(x)\n",
    "        p = self.maxpool(x)\n",
    "        return x , p\n",
    "class Conv4(nn.Module):\n",
    "    def __init__(self,in_channels, mid_channels, out_channels):\n",
    "        super(Conv4,self).__init__() \n",
    "        self.headblock = HeadBlock(in_channels,mid_channels,out_channels)\n",
    "        self.identityblock1 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.identityblock2 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.identityblock3 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.identityblock4 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.identityblock5 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "    def forward(self,x):\n",
    "        x = self.headblock(x)\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        x = self.identityblock3(x)\n",
    "        x = self.identityblock4(x)\n",
    "        x = self.identityblock5(x)\n",
    "        p = self.maxpool(x)\n",
    "        return x , p\n",
    "class Conv5(nn.Module):\n",
    "    def __init__(self,in_channels, mid_channels, out_channels):\n",
    "        super(Conv5,self).__init__() \n",
    "        self.headblock = HeadBlock(in_channels,mid_channels,out_channels)\n",
    "        self.identityblock1 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.identityblock2 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "    def forward(self,x):\n",
    "        x = self.headblock(x)\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        p = self.maxpool(x)\n",
    "        return x , p\n",
    "#디코더 블럭\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.upsample = nn.ConvTranspose2d(channels*2, channels, kernel_size=4, stride=2, padding=1, output_padding=1) # output_padding 추가\n",
    "        self.convblock1 = ConvBlock(channels*2, channels)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = self.upsample(x)\n",
    "        if x.size(2) != skip.size(2) or x.size(3) != skip.size(3):\n",
    "            x = F.interpolate(x, size=(skip.size(2), skip.size(3)))\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.convblock1(x)\n",
    "        return x\n",
    "\n",
    "#Unet구조 middle의 xm값의 움직임에 주의\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self,n_classes):\n",
    "        super(Unet,self).__init__()\n",
    "        self.fconv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2)\n",
    "        self.fbn1 = nn.BatchNorm2d(64)\n",
    "        self.frelu1 = nn.ReLU()\n",
    "        self.fconv2 = nn.Conv2d(64, 128, kernel_size=1, stride=1)\n",
    "        self.fbn2 = nn.BatchNorm2d(128)\n",
    "        self.frelu2 = nn.ReLU()\n",
    "        self.fmaxpooling = nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "        \n",
    "        self.conv2 = Conv2(128,64,256)\n",
    "        self.conv3 = Conv3(256,128,512)\n",
    "        self.conv4 = Conv4(512,256,1024)\n",
    "        self.conv5 = Conv5(1024,512,2048)\n",
    "        \n",
    "        self.middleconv = ConvBlock(2048,4096)\n",
    "        #self.dropout = nn.Dropout2d(0.2) #\n",
    "           \n",
    "        self.decoder5 = DecoderBlock(2048)\n",
    "        self.decoder4 = DecoderBlock(1024)\n",
    "        self.decoder3 = DecoderBlock(512)\n",
    "        self.decoder2 = DecoderBlock(256)\n",
    "        self.decoder1 = DecoderBlock(128)\n",
    "        \n",
    "        self.segmap = nn.Conv2d(128,n_classes, kernel_size=1)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fconv1(x)#3->64\n",
    "        x = self.fbn1(x)\n",
    "        x = self.frelu1(x)\n",
    "        x = self.fconv2(x)#3->64\n",
    "        x = self.fbn2(x)\n",
    "        x1 = self.frelu2(x)\n",
    "        p = self.fmaxpooling(x)#첫 conv: x0([8, 64, 109, 109]) p([8, 64, 54, 54])\n",
    "        #print(\"첫 conv:\",x0.shape,p.shape)\n",
    "        x2,p = self.conv2(p)#conv2:  x1:([8, 256, 54, 54]) p([8, 256, 26, 26])\n",
    "        #print(\"conv2: \",x1.shape, p.shape)\n",
    "        x3,p = self.conv3(p)#conv3:  x2([8, 512, 26, 26]) p([8, 512, 12, 12])\n",
    "        #print(\"conv3: \",x2.shape, p.shape)\n",
    "        x4,p = self.conv4(p)#conv4:  x3([8, 1024, 12, 12]) p([8, 1024, 5, 5])\n",
    "        #print(\"conv4: \",x3.shape, p.shape)\n",
    "        x5,p = self.conv5(p)#conv5:  x4([8, 2048, 5, 5]) p([8, 2048, 2, 2])\n",
    "        #print(\"conv5: \",x4.shape, p.shape)\n",
    "        xm = self.middleconv(p)#xm([8, 4096, 2, 2])\n",
    "        #xm = self.dropout(xm)\n",
    "        #print(\"mid:\",xm.shape)\n",
    "        x = self.decoder5(xm,x5)#뉴런:2048*2->2048 1\n",
    "        #print(x.shape)\n",
    "        x = self.decoder4(x,x4)#뉴런:1024*2->1024 \n",
    "        #print(x.shape)\n",
    "        x = self.decoder3(x,x3) #14\n",
    "        #print(x.shape)\n",
    "        x = self.decoder2(x,x2)#28\n",
    "        #print(x.shape)\n",
    "        x = self.decoder1(x,x1)#55\n",
    "        \n",
    "        x = F.interpolate(x, size=(224, 224))\n",
    "        x = self.segmap(x)\n",
    "        #print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43f0ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "N_CLASSES = 13\n",
    "# 데이터셋을 불러옵니다.\n",
    "csv_file = os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\", './train_source.csv')\n",
    "data = pd.read_csv(csv_file)\n",
    "\n",
    "# 클래스별 샘플 수를 저장할 리스트를 초기화합니다.\n",
    "class_sample_counts = [0] * N_CLASSES  # num_classes는 클래스의 총 개수입니다.\n",
    "\n",
    "# 데이터셋을 순회하면서 클래스별 샘플 수를 세고 저장합니다.\n",
    "for idx in range(len(data)):\n",
    "    mask_path = os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\", data.iloc[idx, 2][2:])  # 마스크 이미지 경로\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    mask[mask == 255] = 12  # 배경 클래스로 처리\n",
    "\n",
    "    # 각 클래스의 샘플 수를 카운트합니다.\n",
    "    for class_id in range(N_CLASSES):\n",
    "        class_sample_counts[class_id] += (mask == class_id).sum()\n",
    "\n",
    "# 클래스별 가중치를 계산합니다.\n",
    "total_samples = sum(class_sample_counts)\n",
    "class_weights = [total_samples / count for count in class_sample_counts]\n",
    "\n",
    "# 클래스별 가중치를 텐서로 변환합니다.\n",
    "class_weights = torch.tensor(class_weights).to(device)\n",
    "class_weights = class_weights.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12229a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[739351233, 56771156, 901883337, 69484874, 27027133, 9088387, 28767055, 660576317, 1049773711, 5071862, 2069341, 448558171, 602728911]\n",
      "tensor([   6.2232,   81.0473,    5.1017,   66.2180,  170.2419,  506.2671,\n",
      "         159.9452,    6.9654,    4.3830,  907.1918, 2223.4863,   10.2576,\n",
      "           7.6339], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(class_sample_counts)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd34483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "EP = 10\n",
    "BATCH_SIZE = 4\n",
    "ACCMULATION_STEP = 1 \n",
    "N_CLASSES = 13 #IoU 점수측정하기 위한 클래스의 개수\n",
    "# WUP_ITERS = 10  # 웜업을 위한 반복 횟수\n",
    "# model 초기화\n",
    "#model = Unet_resnet18(n_classes = N_CLASSES).to(device)\n",
    "#model = ResNet50(num_classes=N_CLASSES).to(device)\n",
    "model = Unet(n_classes = N_CLASSES).to(device)\n",
    "\n",
    "# loss function과 optimizer 정의\n",
    "\n",
    "#criterion =nn.CrossEntropyLoss()\n",
    "#domain_criterion = nn.BCELoss()\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "optimizer.zero_grad() \n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9, nesterov=True)\n",
    "# Warmup을 위한 스케줄러 설정\n",
    "# scheduler_warmup = WarmUpLR(optimizer, WUP_ITERS)\n",
    "\n",
    "dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./train_source.csv'), transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "valid_dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./val_source.csv'), transform=transform)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "target_dataset = CustomDataset_target(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./train_target.csv'), transform=transform)\n",
    "target_dataloader = DataLoader(target_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "test_dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./test.csv'), transform=transform, infer=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8216c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # 데이터로더에서 배치 하나를 가져옵니다.\n",
    "# dataiter = iter(dataloader)\n",
    "# images, masks = next(dataiter)\n",
    "\n",
    "# # 이미지를 시각화합니다.\n",
    "# for i in range(images.size(0)):\n",
    "#     image = images[i].permute(1, 2, 0).numpy()  # 이미지를 CHW에서 HWC로 변환\n",
    "#     mask = masks[i].numpy()\n",
    "\n",
    "#     plt.figure(figsize=(8, 8))\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.imshow(image)\n",
    "#     plt.title(\"Image\")\n",
    "\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.imshow(mask, cmap='gray')\n",
    "#     plt.title(\"Mask\")\n",
    "\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "697a9e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for images, masks in tqdm(dataloader):\n",
    "#     a = images.float().to(device)\n",
    "#     b = masks.long().to(device)\n",
    "#     break\n",
    "\n",
    "# # PyTorch Tensor를 NumPy 배열로 변환\n",
    "# a_numpy = a[3].cpu().numpy()  # 첫 번째 이미지만 선택하거나 필요한 이미지를 선택하세요.\n",
    "# a_numpy = np.transpose(a_numpy, (1, 2, 0))\n",
    "# b_numpy = b[3].cpu().numpy()\n",
    "# b_numpy = b_numpy*12\n",
    "\n",
    "# # 이미지를 저장\n",
    "# cv2.imwrite('image_source.png', a_numpy)  # 이미지 저장\n",
    "# cv2.imwrite('image_mask.png', b_numpy)   # 마스크 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "313afd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for epoch in range(2):  # 5 에폭 동안 학습합니다.\n",
    "          \n",
    "#     # 클래스별 IoU를 누적할 리스트 초기화\n",
    "#     train_class_ious = []\n",
    "    \n",
    "#     # 학습\n",
    "#     model.train()\n",
    "#     epoch_loss = 0\n",
    "    \n",
    "#     for images, masks in tqdm(dataloader):\n",
    "#         images = images.float().to(device)\n",
    "#         masks = masks.long().to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(images)\n",
    "#         mask_spueeze = masks.squeeze(1)\n",
    "#         loss = criterion(outputs, masks.squeeze(1))\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         epoch_loss += loss.item()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0895765-fba0-4fd9-b955-a6c0e43012e9",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dec3e516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [03:45<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.2304 Class1: 0.2900 Class2: 0.3008 Class3: 0.3263 Class4: 0.3165 Class5: 0.3261 Class6: 0.3358 \n",
      "Class7: 0.3389 Class8: 0.3548 Class9: 0.3390 Class10: 0.3403 Class11: 0.3543 Class12: 0.3400 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:16<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.2820 Class1: 0.2712 Class2: 0.2836 Class3: 0.2932 Class4: 0.2767 Class5: 0.2783 Class6: 0.2922 \n",
      "Class7: 0.2966 Class8: 0.2676 Class9: 0.2912 Class10: 0.2819 Class11: 0.2729 Class12: 0.2728 \n",
      "Epoch1\n",
      "Train Loss: 1.1263339570528388, Train mIoU Score: 0.3225\n",
      "Validation Loss: 1.3095107012324863, Validation mIoU Score: 0.2816\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [03:43<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.3466 Class1: 0.3478 Class2: 0.3603 Class3: 0.3554 Class4: 0.3773 Class5: 0.3691 Class6: 0.3798 \n",
      "Class7: 0.3651 Class8: 0.3677 Class9: 0.3742 Class10: 0.3996 Class11: 0.3883 Class12: 0.3872 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:16<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.3459 Class1: 0.3242 Class2: 0.3423 Class3: 0.3482 Class4: 0.3404 Class5: 0.3284 Class6: 0.3462 \n",
      "Class7: 0.3337 Class8: 0.3166 Class9: 0.3369 Class10: 0.3309 Class11: 0.3129 Class12: 0.3264 \n",
      "Epoch2\n",
      "Train Loss: 0.8507275721414493, Train mIoU Score: 0.3707\n",
      "Validation Loss: 1.2649982856889057, Validation mIoU Score: 0.3333\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [03:44<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.3880 Class1: 0.3762 Class2: 0.3866 Class3: 0.3948 Class4: 0.3926 Class5: 0.3893 Class6: 0.3819 \n",
      "Class7: 0.3755 Class8: 0.3821 Class9: 0.3968 Class10: 0.3706 Class11: 0.3923 Class12: 0.4055 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:16<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.3596 Class1: 0.3421 Class2: 0.3564 Class3: 0.3679 Class4: 0.3558 Class5: 0.3529 Class6: 0.3584 \n",
      "Class7: 0.3531 Class8: 0.3435 Class9: 0.3573 Class10: 0.3520 Class11: 0.3307 Class12: 0.3408 \n",
      "Epoch3\n",
      "Train Loss: 0.7588362684558215, Train mIoU Score: 0.3871\n",
      "Validation Loss: 1.0931008458137512, Validation mIoU Score: 0.3516\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [03:44<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.3998 Class1: 0.4062 Class2: 0.3962 Class3: 0.4021 Class4: 0.4106 Class5: 0.4076 Class6: 0.4079 \n",
      "Class7: 0.3917 Class8: 0.4214 Class9: 0.4151 Class10: 0.3948 Class11: 0.3989 Class12: 0.4175 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:17<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.3292 Class1: 0.3146 Class2: 0.3338 Class3: 0.3419 Class4: 0.3391 Class5: 0.3283 Class6: 0.3277 \n",
      "Class7: 0.3215 Class8: 0.3154 Class9: 0.3423 Class10: 0.3276 Class11: 0.3130 Class12: 0.3171 \n",
      "Epoch4\n",
      "Train Loss: 0.6846252162491254, Train mIoU Score: 0.4054\n",
      "Validation Loss: 1.335362388028039, Validation mIoU Score: 0.3270\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [03:44<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.4080 Class1: 0.4094 Class2: 0.4121 Class3: 0.4185 Class4: 0.4300 Class5: 0.4340 Class6: 0.4275 \n",
      "Class7: 0.4323 Class8: 0.4287 Class9: 0.4131 Class10: 0.4324 Class11: 0.4343 Class12: 0.4297 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:16<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.3546 Class1: 0.3441 Class2: 0.3560 Class3: 0.3597 Class4: 0.3481 Class5: 0.3423 Class6: 0.3569 \n",
      "Class7: 0.3516 Class8: 0.3306 Class9: 0.3527 Class10: 0.3451 Class11: 0.3234 Class12: 0.3276 \n",
      "Epoch5\n",
      "Train Loss: 0.6246638592800807, Train mIoU Score: 0.4238\n",
      "Validation Loss: 1.1616764402287638, Validation mIoU Score: 0.3456\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/549 [00:04<10:08,  1.12s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/MMI24limbyungwan/Design_Project/Design_project/U_net_LBW2.ipynb 셀 22\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/U_net_LBW2.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/U_net_LBW2.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# if (epoch+1) % ACCMULATION_STEP == 0:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/U_net_LBW2.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m#     optimizer.step()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/U_net_LBW2.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m#     optimizer.zero_grad()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/U_net_LBW2.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39m# # Warmup 스케줄러 업데이트\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/U_net_LBW2.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m     \u001b[39m# if epoch < WUP_ITERS:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/U_net_LBW2.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39m#     scheduler_warmup.step()\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/U_net_LBW2.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/U_net_LBW2.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# train 클래스별 IoU 계산\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/U_net_LBW2.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msoftmax(outputs, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcpu()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "torch.cuda.empty_cache()\n",
    "import wandb\n",
    "\n",
    "\n",
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"practice_10_06\",\n",
    "    \n",
    "#     # track hyperparameters and run metadata\n",
    "#     config={\n",
    "#     \"learning_rate\": LR,\n",
    "#     \"architecture\": \"CNN\",\n",
    "#     \"dataset\": \"Samsung\",\n",
    "#     \"epochs\": EP,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "for epoch in range(EP):\n",
    "    # 클래스별 IoU를 누적할 리스트 초기화\n",
    "    train_class_ious = []\n",
    "    # 학습\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for images, masks in tqdm(dataloader):\n",
    "        images = images.float().to(device)\n",
    "        masks = masks.long().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks.squeeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # if (epoch+1) % ACCMULATION_STEP == 0:\n",
    "        #     optimizer.step()\n",
    "        #     optimizer.zero_grad()\n",
    "            # # Warmup 스케줄러 업데이트\n",
    "            # if epoch < WUP_ITERS:\n",
    "            #     scheduler_warmup.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # train 클래스별 IoU 계산\n",
    "        outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "        outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "\n",
    "        for class_id in range(N_CLASSES):\n",
    "            iou = calculate_iou_per_class(np.array(masks.cpu()), np.array(outputs), class_id)\n",
    "            train_class_ious.append(iou)\n",
    "\n",
    "    train_class_ious = np.array(train_class_ious).reshape(N_CLASSES, -1)\n",
    "    train_class_ious = np.mean(train_class_ious, axis=1)\n",
    "    print(\"--IoU Scores Train--\")\n",
    "    for class_id, iou in enumerate(train_class_ious):\n",
    "        print(f'Class{class_id}: {iou:.4f}', end=\" \")\n",
    "        if (class_id+1) % 7 == 0:\n",
    "            print()\n",
    "\n",
    "    # mIoU 계산\n",
    "    train_mIoU = np.mean(train_class_ious)\n",
    "\n",
    "    # validation\n",
    "    val_loss = 0\n",
    "    val_class_ious = []  # 클래스별 IoU를 누적할 리스트 초기화\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for images, masks in tqdm(valid_dataloader):\n",
    "            images = images.float().to(device)\n",
    "            masks = masks.long().to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            # validation loss 계산\n",
    "            val_loss += criterion(outputs, masks.squeeze(1)).item()\n",
    "\n",
    "            # validation 클래스별 IoU 계산\n",
    "            outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "            outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "\n",
    "            for class_id in range(N_CLASSES):\n",
    "                iou = calculate_iou_per_class(np.array(masks.cpu()), np.array(outputs), class_id)\n",
    "                val_class_ious.append(iou)\n",
    "\n",
    "    val_class_ious = np.array(val_class_ious).reshape(N_CLASSES, -1)\n",
    "    val_class_ious = np.mean(val_class_ious, axis=1)\n",
    "    print(\"--IoU Scores Valid--\")\n",
    "    for class_id, iou in enumerate(val_class_ious):\n",
    "        print(f'Class{class_id}: {iou:.4f}', end=\" \")\n",
    "        if (class_id+1) % 7 == 0:\n",
    "            print(\"\")\n",
    "\n",
    "    # mIoU 계산\n",
    "    val_mIoU = np.mean(val_class_ious)\n",
    "\n",
    "    # 에폭마다 결과 출력 \n",
    "    print(f\"\\nEpoch{epoch+1}\")\n",
    "    print(f\"Train Loss: {(epoch_loss/len(dataloader))}, Train mIoU Score: {train_mIoU:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss/len(valid_dataloader)}, Validation mIoU Score: {val_mIoU:.4f}\")\n",
    "    print(\"___________________________________________________________________________________________\\n\")\n",
    "\n",
    "#     # log metrics to wandb\n",
    "#     wandb.log({\"train score\": train_mIoU, \"train loss\": epoch_loss})\n",
    "#     wandb.log({\"val score\": val_mIoU, \"val loss\": val_loss})\n",
    "    \n",
    "    \n",
    "# # [optional] finish the wandb run, necessary in notebooks\n",
    "# wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2ce089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     result = []\n",
    "#     for images in tqdm(valid_dataloader):\n",
    "#         images = images.float().to(device)\n",
    "#         outputs = model(images)\n",
    "#         outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "#         outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "#         for class_id in range(N_CLASSES):\n",
    "#             iou = calculate_iou_per_class(np.array(masks.cpu()), np.array(outputs), class_id)\n",
    "#             result.append(iou)\n",
    "\n",
    "#     result = np.array(result).reshape(N_CLASSES, -1)\n",
    "#     result = np.mean(result, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c03f04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# for epoch in range(EP):\n",
    "#     # 클래스별 IoU를 누적할 리스트 초기화\n",
    "#     train_class_ious = []\n",
    "#     # 학습\n",
    "#     model.train()\n",
    "#     epoch_loss = 0\n",
    "#     for images in tqdm(target_dataloader):\n",
    "#         images = images.float().to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         _, outputs = model(images)\n",
    "#         target_domain = torch.zeros_like(outputs).to(device)\n",
    "#         loss = domain_criterion(outputs, target_domain)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         epoch_loss += loss.item()\n",
    "\n",
    "#         avg_domain_loss = epoch_loss / len(target_dataloader)\n",
    "#     print(f\"Epoch [{epoch + 1}/{EP}] - Domain Loss: {avg_domain_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8aa1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     result = []\n",
    "#     for images in tqdm(valid_dataloader):\n",
    "#         images = images.float().to(device)\n",
    "#         outputs = model(images)\n",
    "#         outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "#         outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "#         for class_id in range(N_CLASSES):\n",
    "#             iou = calculate_iou_per_class(np.array(masks.cpu()), np.array(outputs), class_id)\n",
    "#             result.append(iou)\n",
    "\n",
    "#     result = np.array(result).reshape(N_CLASSES, -1)\n",
    "#     result = np.mean(result, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c32eb51c-a3fe-4e11-a616-3a717ba16f7e",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12371c8b-0c78-47df-89ec-2d8b55c8ea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = CustomDataset(csv_file='./test.csv', transform=transform, infer=True)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b431c-ac8e-4c40-9046-4d53e4bab14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     result = []\n",
    "#     for images in tqdm(test_dataloader):\n",
    "#         images = images.float().to(device)\n",
    "#         outputs = model(images)\n",
    "#         outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "#         outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "#         # batch에 존재하는 각 이미지에 대해서 반복\n",
    "#         for pred in outputs:\n",
    "#             pred = pred.astype(np.uint8)\n",
    "#             pred = Image.fromarray(pred) # 이미지로 변환\n",
    "#             pred = pred.resize((960, 540), Image.NEAREST) # 960 x 540 사이즈로 변환\n",
    "#             pred = np.array(pred) # 다시 수치로 변환\n",
    "#             # class 0 ~ 11에 해당하는 경우에 마스크 형성 / 12(배경)는 제외하고 진행\n",
    "#             for class_id in range(12):\n",
    "#                 class_mask = (pred == class_id).astype(np.uint8)\n",
    "#                 if np.sum(class_mask) > 0: # 마스크가 존재하는 경우 encode\n",
    "#                     mask_rle = rle_encode(class_mask)\n",
    "#                     result.append(mask_rle)\n",
    "#                 else: # 마스크가 존재하지 않는 경우 -1\n",
    "#                     result.append(-1)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36c2cbbb-04f1-4f9c-b4df-4b744dfce046",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac2a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit = pd.read_csv('./sample_submission.csv')\n",
    "# submit['mask_rle'] = result\n",
    "# submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da10cb6f-0826-4755-a376-97b695ae8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit.to_csv('./baseline_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seungyoon2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
