{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d73d24e3-5c9e-4ade-9e6e-ca6f46a2d914",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad9b681e-370a-4cfa-a452-dd2d7f0cd77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/MMI24limbyungwan/.conda/envs/byungwan_resn/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# GPU 사용이 가능할 경우, GPU를 사용할 수 있게 함.'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "print(device)\n",
    "\n",
    "print(os.environ.get('CUDA_VISIBLE_DEVICES'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20ff3de5-0d0e-497b-ac75-d5179a3f65d3",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "838e1d83-8670-407b-82f6-bf9652f58639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "# 클래스별 IoU를 계산하기 위한 함수\n",
    "def calculate_iou_per_class(y_true, y_pred, class_id):\n",
    "    intersection = np.sum((y_true == class_id) & (y_pred == class_id))\n",
    "    union = np.sum((y_true == class_id) | (y_pred == class_id))\n",
    "    iou = intersection / union if union > 0 else 0\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5c64ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "\n",
    "class GradReverseFunction(autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, l):\n",
    "        ctx.l = l\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output.neg() * ctx.l, None\n",
    "\n",
    "def grad_reverse(x, l):\n",
    "    return GradReverseFunction.apply(x, l)\n",
    "\n",
    "class GradReverse(nn.Module):\n",
    "    def __init__(self, l):\n",
    "        super(GradReverse, self).__init__()\n",
    "        self.l = nn.Parameter(torch.tensor(l), requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return grad_reverse(x, self.l)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be76a29e-e9c2-411a-a569-04166f074184",
   "metadata": {},
   "source": [
    "## Dataset, Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5acf65a",
   "metadata": {},
   "source": [
    "출력이미지 크기 키우기->ex) resnet 2048->1024->512->256 conv 256->512->1024->2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8496767-2f64-4285-bec4-c6f53a1fd9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        directory_path = \"/mnt/nas27/Dataset/Samsung_DM\"\n",
    "        img_path = self.data.iloc[idx, 1]\n",
    "        img_path = os.path.join(directory_path, img_path[2:])\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "        \n",
    "        mask_path = self.data.iloc[idx, 2]\n",
    "        mask_path = os.path.join(directory_path, mask_path[2:])\n",
    "        mask = cv2.imread(mask_path)\n",
    "        #mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        mask[mask == 255] = 12 #배경을 픽셀값 12로 간주\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "class CustomDataset_target(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        directory_path = \"/mnt/nas27/Dataset/Samsung_DM\"\n",
    "        img_path = self.data.iloc[idx, 1]\n",
    "        img_path = os.path.join(directory_path, img_path[2:])\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "            \n",
    "\n",
    "        return image\n",
    "     \n",
    "\n",
    "transform = A.Compose(\n",
    "    [   \n",
    "        A.Resize(224, 224),\n",
    "        #A.Resize(128, 128),\n",
    "        A.Normalize(),\n",
    "        \n",
    "        # 변형\n",
    "        # A.VerticalFlip(p=0.5),\n",
    "        # A.RandomRotate90(p=0.5),\n",
    "        # A.HueSaturationValue(p=0.2),\n",
    "        \n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a91d6b1",
   "metadata": {},
   "source": [
    "Warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9e62c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class WarmUpLR(_LRScheduler):\n",
    "#     def __init__(self, optimizer, total_iters, last_epoch=-1):\n",
    "#         self.total_iters = total_iters\n",
    "#         super(WarmUpLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "#     def get_lr(self):\n",
    "#         return [base_lr * self.last_epoch / self.total_iters for base_lr in self.base_lrs]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f42501fc-b573-4893-a7c4-5e280dfdaf09",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3574888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Unet의 기본이 되는 conv블럭\n",
    "# class ConvBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(ConvBlock, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "#         self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "        \n",
    "#         self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)  # 여기서 in_channels는 out_channels와 동일해야 합니다.\n",
    "#         self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.relu1(x)\n",
    "        \n",
    "#         x = self.conv2(x)\n",
    "#         x = self.bn2(x)\n",
    "#         x = self.relu2(x)\n",
    "#         return x\n",
    "\n",
    "# #인코더 블럭\n",
    "# class EncoderBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(EncoderBlock,self).__init__()\n",
    "#         self.convblock1 = ConvBlock(in_channels, out_channels)  # 첫 번째 ConvBlock의 in_channels는 입력 이미지의 채널 수와 일치해야 합니다.\n",
    "#         #self.convblock2 = ConvBlock(out_channels, out_channels)  # 두 번째 ConvBlock의 in_channels는 out_channels와 일치해야 합니다.\n",
    "#         self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "#     def forward(self,x):\n",
    "#         x = self.convblock1(x)\n",
    "#         #x = self.convblock2(x)\n",
    "#         p = self.maxpool(x)\n",
    "#         return x , p\n",
    "# #디코더 블럭\n",
    "# #디코더는 업샘플링 이후 스킵연결과 붙어서 convblock을 통과해야함\n",
    "# #skip보다 작은 x x먼저 업샘플링 32 -> 64 , skip과 결합 6464 \n",
    "# class DecoderBlock(nn.Module):\n",
    "#     def __init__(self, channels):\n",
    "#         super(DecoderBlock,self).__init__()\n",
    "#         self.upsample = nn.ConvTranspose2d(channels*2, channels, kernel_size=4, stride=2, padding=1)#x 업샘플링\n",
    "#         self.convblock1 = ConvBlock(channels*2, channels)#차원감소\n",
    "#         #self.convblock2 = ConvBlock(channels, channels)\n",
    "#     def forward(self,x,skip):\n",
    "#         x = self.upsample(x)\n",
    "#         x = torch.cat([x, skip], dim=1)\n",
    "#         x = self.convblock1(x)\n",
    "#         #x = self.convblock2(x)\n",
    "#         return x\n",
    "        \n",
    "# #Unet구조 middle의 xm값의 움직임에 주의\n",
    "# class Unet(nn.Module):\n",
    "#     def __init__(self,n_classes):\n",
    "#         super(Unet,self).__init__()\n",
    "#         self.encoder1 = EncoderBlock(3,64)\n",
    "#         self.encoder2 = EncoderBlock(64,128)\n",
    "#         self.encoder3 = EncoderBlock(128,256)\n",
    "#         self.encoder4 = EncoderBlock(256,512)\n",
    "        \n",
    "#         self.middleconv = ConvBlock(512,1024)\n",
    "        \n",
    "        \n",
    "#         self.decoder4 = DecoderBlock(512)\n",
    "#         self.decoder3 = DecoderBlock(256)\n",
    "#         self.decoder2 = DecoderBlock(128)\n",
    "#         self.decoder1 = DecoderBlock(64)\n",
    "#         self.segmap = nn.Conv2d(64,n_classes, kernel_size=1)\n",
    "        \n",
    "#         ##\n",
    "#         # self.domain_classifier = nn.Sequential(\n",
    "#         #     nn.Conv3d(1024, 64, kernel_size=3, padding=1),\n",
    "#         #     nn.ReLU(),\n",
    "#         #     nn.Conv3d(64, 32, kernel_size=3, padding=1),\n",
    "#         #     nn.ReLU(),\n",
    "#         #     nn.Flatten(),\n",
    "#         #     nn.Linear(32 * 16 * 16 * 16, 1),\n",
    "#         #     nn.Sigmoid()\n",
    "#         # )\n",
    "\n",
    "#         # self.grad_reverse = GradReverse(0.0)\n",
    "#         ##\n",
    "\n",
    "#     def forward(self,x):\n",
    "#         x1,p = self.encoder1(x)#3->64   #P:256,256 x1 :512,512\n",
    "#         x2,p = self.encoder2(p)#64->128 #P:128,128 x2:256,256\n",
    "#         x3,p = self.encoder3(p)#128->256#p:64,64 x3:128,128\n",
    "#         x4,p = self.encoder4(p)#256->512#p:32,32 x4:64,64\n",
    "        \n",
    "#         xm = self.middleconv(p)#512->1024#32,32\n",
    "        \n",
    "#         x = self.decoder4(xm,x4)#뉴런:1024->512->512 #출력tensor:64,64\n",
    "#         x = self.decoder3(x,x3)#뉴런:512->256->256 #출력tensor:128,128\n",
    "#         x = self.decoder2(x,x2)#뉴런:256->128->128 #출력tensor:256,256\n",
    "#         x = self.decoder1(x,x1)#뉴런:128->64->64 #출력tensor:512,512\n",
    "#         x = self.segmap(x)\n",
    "\n",
    "#         # 도메인 분류기에 GradReverse 적용\n",
    "#         #feat = self.grad_reverse(x)\n",
    "#         #domain_output = self.domain_classifier(x)\n",
    "\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdb7c3b",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baf22f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unet의 기본이 되는 conv블럭\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels,kernel_size = 3):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, padding=1)  # 여기서 in_channels는 out_channels와 동일해야 합니다.\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        return x\n",
    "\n",
    "class IdentityBlock(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, stride=1):\n",
    "        super(IdentityBlock, self).__init__()\n",
    "        \n",
    "        # 1x1 convolution\n",
    "        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(mid_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # 3x3 convolution\n",
    "        self.conv2 = nn.Conv2d(mid_channels, mid_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(mid_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # 1x1 convolution\n",
    "        self.conv3 = nn.Conv2d(mid_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "         \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.relu3(out)\n",
    "        \n",
    "        return out\n",
    "class HeadBlock(IdentityBlock):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, stride=1):\n",
    "        super(HeadBlock, self).__init__(in_channels, mid_channels, out_channels, stride)\n",
    "        \n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = super().forward(x)\n",
    "        \n",
    "        if identity.size() != out.size():\n",
    "            identity = F.interpolate(identity, size=out.size()[2:])\n",
    "        identity = self.shortcut(identity)\n",
    "        \n",
    "        out += identity\n",
    "        out = self.relu3(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "#인코더 블럭\n",
    "class Conv2(nn.Module):\n",
    "    def __init__(self,in_channels, mid_channels, out_channels):\n",
    "        super(Conv2,self).__init__() \n",
    "        self.headblock = HeadBlock(in_channels,mid_channels,out_channels)\n",
    "        self.identityblock1 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.identityblock2 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "    def forward(self,x):\n",
    "        x = self.headblock(x)\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        p = self.maxpool(x)\n",
    "        return x , p\n",
    "class Conv3(nn.Module):\n",
    "    def __init__(self,in_channels, mid_channels, out_channels):\n",
    "        super(Conv3,self).__init__() \n",
    "        self.headblock = HeadBlock(in_channels,mid_channels,out_channels)\n",
    "        self.identityblock1 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.identityblock2 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.identityblock3 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "    def forward(self,x):\n",
    "        x = self.headblock(x)\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        x = self.identityblock3(x)\n",
    "        p = self.maxpool(x)\n",
    "        return x , p\n",
    "class Conv4(nn.Module):\n",
    "    def __init__(self,in_channels, mid_channels, out_channels):\n",
    "        super(Conv4,self).__init__() \n",
    "        self.headblock = HeadBlock(in_channels,mid_channels,out_channels)\n",
    "        self.identityblock1 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.identityblock2 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.identityblock3 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.identityblock4 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.identityblock5 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "    def forward(self,x):\n",
    "        x = self.headblock(x)\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        x = self.identityblock3(x)\n",
    "        x = self.identityblock4(x)\n",
    "        x = self.identityblock5(x)\n",
    "        p = self.maxpool(x)\n",
    "        return x , p\n",
    "class Conv5(nn.Module):\n",
    "    def __init__(self,in_channels, mid_channels, out_channels):\n",
    "        super(Conv5,self).__init__() \n",
    "        self.headblock = HeadBlock(in_channels,mid_channels,out_channels)\n",
    "        self.identityblock1 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.identityblock2 = IdentityBlock(out_channels,mid_channels,out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "    def forward(self,x):\n",
    "        x = self.headblock(x)\n",
    "        x = self.identityblock1(x)\n",
    "        x = self.identityblock2(x)\n",
    "        p = self.maxpool(x)\n",
    "        return x , p\n",
    "#디코더 블럭\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.upsample = nn.ConvTranspose2d(channels*2, channels, kernel_size=4, stride=2, padding=1, output_padding=1) # output_padding 추가\n",
    "        self.convblock1 = ConvBlock(channels*2, channels)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = self.upsample(x)\n",
    "        if x.size(2) != skip.size(2) or x.size(3) != skip.size(3):\n",
    "            x = F.interpolate(x, size=(skip.size(2), skip.size(3)))\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.convblock1(x)\n",
    "        return x\n",
    "\n",
    "#Unet구조 middle의 xm값의 움직임에 주의\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self,n_classes):\n",
    "        super(Unet,self).__init__()\n",
    "        self.fconv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2)\n",
    "        self.fbn1 = nn.BatchNorm2d(64)\n",
    "        self.frelu1 = nn.ReLU()\n",
    "        self.fconv2 = nn.Conv2d(64, 128, kernel_size=1, stride=1)\n",
    "        self.fbn2 = nn.BatchNorm2d(128)\n",
    "        self.frelu2 = nn.ReLU()\n",
    "        self.fmaxpooling = nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "        \n",
    "        self.conv2 = Conv2(128,64,256)\n",
    "        self.conv3 = Conv3(256,128,512)\n",
    "        self.conv4 = Conv4(512,256,1024)\n",
    "        self.conv5 = Conv5(1024,512,2048)\n",
    "        \n",
    "        self.middleconv = ConvBlock(2048,4096)\n",
    "        #self.dropout = nn.Dropout2d(0.2) #\n",
    "           \n",
    "        self.decoder5 = DecoderBlock(2048)\n",
    "        self.decoder4 = DecoderBlock(1024)\n",
    "        self.decoder3 = DecoderBlock(512)\n",
    "        self.decoder2 = DecoderBlock(256)\n",
    "        self.decoder1 = DecoderBlock(128)\n",
    "        \n",
    "        self.segmap = nn.Conv2d(128,n_classes, kernel_size=1)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fconv1(x)#3->64\n",
    "        x = self.fbn1(x)\n",
    "        x = self.frelu1(x)\n",
    "        x = self.fconv2(x)#3->64\n",
    "        x = self.fbn2(x)\n",
    "        x1 = self.frelu2(x)\n",
    "        p = self.fmaxpooling(x)#첫 conv: x0([8, 64, 109, 109]) p([8, 64, 54, 54])\n",
    "        #print(\"첫 conv:\",x0.shape,p.shape)\n",
    "        x2,p = self.conv2(p)#conv2:  x1:([8, 256, 54, 54]) p([8, 256, 26, 26])\n",
    "        #print(\"conv2: \",x1.shape, p.shape)\n",
    "        x3,p = self.conv3(p)#conv3:  x2([8, 512, 26, 26]) p([8, 512, 12, 12])\n",
    "        #print(\"conv3: \",x2.shape, p.shape)\n",
    "        x4,p = self.conv4(p)#conv4:  x3([8, 1024, 12, 12]) p([8, 1024, 5, 5])\n",
    "        #print(\"conv4: \",x3.shape, p.shape)\n",
    "        x5,p = self.conv5(p)#conv5:  x4([8, 2048, 5, 5]) p([8, 2048, 2, 2])\n",
    "        #print(\"conv5: \",x4.shape, p.shape)\n",
    "        xm = self.middleconv(p)#xm([8, 4096, 2, 2])\n",
    "        #xm = self.dropout(xm)\n",
    "        #print(\"mid:\",xm.shape)\n",
    "        x = self.decoder5(xm,x5)#뉴런:2048*2->2048 1\n",
    "        #print(x.shape)\n",
    "        x = self.decoder4(x,x4)#뉴런:1024*2->1024 \n",
    "        #print(x.shape)\n",
    "        x = self.decoder3(x,x3) #14\n",
    "        #print(x.shape)\n",
    "        x = self.decoder2(x,x2)#28\n",
    "        #print(x.shape)\n",
    "        x = self.decoder1(x,x1)#55\n",
    "        \n",
    "        x = F.interpolate(x, size=(224, 224))\n",
    "        x = self.segmap(x)\n",
    "        #print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43f0ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "N_CLASSES = 13\n",
    "# 데이터셋을 불러옵니다.\n",
    "csv_file = os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\", './train_source.csv')\n",
    "data = pd.read_csv(csv_file)\n",
    "\n",
    "# 클래스별 샘플 수를 저장할 리스트를 초기화합니다.\n",
    "class_sample_counts = [0] * N_CLASSES  # num_classes는 클래스의 총 개수입니다.\n",
    "\n",
    "# 데이터셋을 순회하면서 클래스별 샘플 수를 세고 저장합니다.\n",
    "for idx in range(len(data)):\n",
    "    mask_path = os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\", data.iloc[idx, 2][2:])  # 마스크 이미지 경로\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    mask[mask == 255] = 12  # 배경 클래스로 처리\n",
    "\n",
    "    # 각 클래스의 샘플 수를 카운트합니다.\n",
    "    for class_id in range(N_CLASSES):\n",
    "        class_sample_counts[class_id] += (mask == class_id).sum()\n",
    "\n",
    "# 클래스별 가중치를 계산합니다.\n",
    "total_samples = sum(class_sample_counts)\n",
    "class_weights = [total_samples / count for count in class_sample_counts]\n",
    "\n",
    "# 클래스별 가중치를 텐서로 변환합니다.\n",
    "class_weights = torch.tensor(class_weights).to(device)\n",
    "class_weights = class_weights.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12229a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[739351233, 56771156, 901883337, 69484874, 27027133, 9088387, 28767055, 660576317, 1049773711, 5071862, 2069341, 448558171, 602728911]\n",
      "tensor([   6.2232,   81.0473,    5.1017,   66.2180,  170.2419,  506.2671,\n",
      "         159.9452,    6.9654,    4.3830,  907.1918, 2223.4863,   10.2576,\n",
      "           7.6339], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(class_sample_counts)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd34483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "EP = 20\n",
    "BATCH_SIZE = 4\n",
    "ACCMULATION_STEP = 1 \n",
    "N_CLASSES = 13 #IoU 점수측정하기 위한 클래스의 개수\n",
    "# WUP_ITERS = 10  # 웜업을 위한 반복 횟수\n",
    "# model 초기화\n",
    "#model = Unet_resnet18(n_classes = N_CLASSES).to(device)\n",
    "#model = ResNet50(num_classes=N_CLASSES).to(device)\n",
    "model = Unet(n_classes = N_CLASSES).to(device)\n",
    "\n",
    "# loss function과 optimizer 정의\n",
    "\n",
    "#criterion =nn.CrossEntropyLoss()\n",
    "#domain_criterion = nn.BCELoss()\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "optimizer.zero_grad() \n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9, nesterov=True)\n",
    "# Warmup을 위한 스케줄러 설정\n",
    "# scheduler_warmup = WarmUpLR(optimizer, WUP_ITERS)\n",
    "\n",
    "dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./train_source.csv'), transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "valid_dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./val_source.csv'), transform=transform)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "target_dataset = CustomDataset_target(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./train_target.csv'), transform=transform)\n",
    "target_dataloader = DataLoader(target_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "test_dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./test.csv'), transform=transform, infer=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8216c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # 데이터로더에서 배치 하나를 가져옵니다.\n",
    "# dataiter = iter(dataloader)\n",
    "# images, masks = next(dataiter)\n",
    "\n",
    "# # 이미지를 시각화합니다.\n",
    "# for i in range(images.size(0)):\n",
    "#     image = images[i].permute(1, 2, 0).numpy()  # 이미지를 CHW에서 HWC로 변환\n",
    "#     mask = masks[i].numpy()\n",
    "\n",
    "#     plt.figure(figsize=(8, 8))\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.imshow(image)\n",
    "#     plt.title(\"Image\")\n",
    "\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.imshow(mask, cmap='gray')\n",
    "#     plt.title(\"Mask\")\n",
    "\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "697a9e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for images, masks in tqdm(dataloader):\n",
    "#     a = images.float().to(device)\n",
    "#     b = masks.long().to(device)\n",
    "#     break\n",
    "\n",
    "# # PyTorch Tensor를 NumPy 배열로 변환\n",
    "# a_numpy = a[3].cpu().numpy()  # 첫 번째 이미지만 선택하거나 필요한 이미지를 선택하세요.\n",
    "# a_numpy = np.transpose(a_numpy, (1, 2, 0))\n",
    "# b_numpy = b[3].cpu().numpy()\n",
    "# b_numpy = b_numpy*12\n",
    "\n",
    "# # 이미지를 저장\n",
    "# cv2.imwrite('image_source.png', a_numpy)  # 이미지 저장\n",
    "# cv2.imwrite('image_mask.png', b_numpy)   # 마스크 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "313afd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for epoch in range(2):  # 5 에폭 동안 학습합니다.\n",
    "          \n",
    "#     # 클래스별 IoU를 누적할 리스트 초기화\n",
    "#     train_class_ious = []\n",
    "    \n",
    "#     # 학습\n",
    "#     model.train()\n",
    "#     epoch_loss = 0\n",
    "    \n",
    "#     for images, masks in tqdm(dataloader):\n",
    "#         images = images.float().to(device)\n",
    "#         masks = masks.long().to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(images)\n",
    "#         mask_spueeze = masks.squeeze(1)\n",
    "#         loss = criterion(outputs, masks.squeeze(1))\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         epoch_loss += loss.item()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0895765-fba0-4fd9-b955-a6c0e43012e9",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dec3e516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpook0612\u001b[0m (\u001b[33mlimbw\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/MMI24limbyungwan/Design_project/wandb/run-20231006_165917-1njpqmvv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/limbw/practice_10_06/runs/1njpqmvv' target=\"_blank\">fearless-water-1</a></strong> to <a href='https://wandb.ai/limbw/practice_10_06' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/limbw/practice_10_06' target=\"_blank\">https://wandb.ai/limbw/practice_10_06</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/limbw/practice_10_06/runs/1njpqmvv' target=\"_blank\">https://wandb.ai/limbw/practice_10_06/runs/1njpqmvv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [03:42<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.2024 Class1: 0.2830 Class2: 0.3089 Class3: 0.3080 Class4: 0.3305 Class5: 0.3376 Class6: 0.3359 \n",
      "Class7: 0.3411 Class8: 0.3276 Class9: 0.3408 Class10: 0.3446 Class11: 0.3489 Class12: 0.3640 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:16<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.2804 Class1: 0.2844 Class2: 0.2833 Class3: 0.2808 Class4: 0.2755 Class5: 0.2677 Class6: 0.2862 \n",
      "Class7: 0.2766 Class8: 0.2697 Class9: 0.2820 Class10: 0.2819 Class11: 0.2619 Class12: 0.2751 \n",
      "Epoch1\n",
      "Train Loss: 1.1225906774428807, Train mIoU Score: 0.3210\n",
      "Validation Loss: 1.2620958135678217, Validation mIoU Score: 0.2773\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [03:42<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.3572 Class1: 0.3718 Class2: 0.3642 Class3: 0.3712 Class4: 0.3724 Class5: 0.3691 Class6: 0.3695 \n",
      "Class7: 0.3783 Class8: 0.3838 Class9: 0.3746 Class10: 0.3752 Class11: 0.3732 Class12: 0.3736 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:16<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.3002 Class1: 0.2986 Class2: 0.3046 Class3: 0.3161 Class4: 0.3043 Class5: 0.2988 Class6: 0.3088 \n",
      "Class7: 0.3076 Class8: 0.2900 Class9: 0.3063 Class10: 0.2983 Class11: 0.2887 Class12: 0.2962 \n",
      "Epoch2\n",
      "Train Loss: 0.8431655659810224, Train mIoU Score: 0.3718\n",
      "Validation Loss: 1.342952525513804, Validation mIoU Score: 0.3014\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [03:42<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.3885 Class1: 0.3913 Class2: 0.3835 Class3: 0.3719 Class4: 0.3967 Class5: 0.3944 Class6: 0.3878 \n",
      "Class7: 0.3997 Class8: 0.3947 Class9: 0.4212 Class10: 0.4087 Class11: 0.4001 Class12: 0.4031 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:16<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.3660 Class1: 0.3498 Class2: 0.3620 Class3: 0.3677 Class4: 0.3541 Class5: 0.3572 Class6: 0.3678 \n",
      "Class7: 0.3600 Class8: 0.3384 Class9: 0.3599 Class10: 0.3593 Class11: 0.3410 Class12: 0.3511 \n",
      "Epoch3\n",
      "Train Loss: 0.7422768920931443, Train mIoU Score: 0.3955\n",
      "Validation Loss: 1.174119079979057, Validation mIoU Score: 0.3565\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [03:41<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.3995 Class1: 0.4023 Class2: 0.4099 Class3: 0.4079 Class4: 0.4083 Class5: 0.4128 Class6: 0.3858 \n",
      "Class7: 0.4117 Class8: 0.4025 Class9: 0.4122 Class10: 0.3950 Class11: 0.4018 Class12: 0.4157 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:16<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.3333 Class1: 0.3107 Class2: 0.3274 Class3: 0.3367 Class4: 0.3294 Class5: 0.3311 Class6: 0.3336 \n",
      "Class7: 0.3320 Class8: 0.3156 Class9: 0.3341 Class10: 0.3212 Class11: 0.3133 Class12: 0.3114 \n",
      "Epoch4\n",
      "Train Loss: 0.6946422148271988, Train mIoU Score: 0.4050\n",
      "Validation Loss: 1.2189647056098678, Validation mIoU Score: 0.3254\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [03:42<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.3990 Class1: 0.4061 Class2: 0.4278 Class3: 0.4233 Class4: 0.4311 Class5: 0.4264 Class6: 0.4168 \n",
      "Class7: 0.4140 Class8: 0.4297 Class9: 0.4178 Class10: 0.4297 Class11: 0.4248 Class12: 0.4189 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:16<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.3736 Class1: 0.3582 Class2: 0.3757 Class3: 0.3854 Class4: 0.3711 Class5: 0.3654 Class6: 0.3711 \n",
      "Class7: 0.3650 Class8: 0.3510 Class9: 0.3764 Class10: 0.3654 Class11: 0.3462 Class12: 0.3567 \n",
      "Epoch5\n",
      "Train Loss: 0.6364559523611989, Train mIoU Score: 0.4204\n",
      "Validation Loss: 1.0231809840243087, Validation mIoU Score: 0.3662\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [03:42<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.4200 Class1: 0.4242 Class2: 0.4376 Class3: 0.4331 Class4: 0.4362 Class5: 0.4312 Class6: 0.4384 \n",
      "Class7: 0.4348 Class8: 0.4419 Class9: 0.4182 Class10: 0.4444 Class11: 0.4312 Class12: 0.4323 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:16<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.3846 Class1: 0.3683 Class2: 0.3869 Class3: 0.3948 Class4: 0.3810 Class5: 0.3867 Class6: 0.3876 \n",
      "Class7: 0.3820 Class8: 0.3677 Class9: 0.3835 Class10: 0.3873 Class11: 0.3599 Class12: 0.3681 \n",
      "Epoch6\n",
      "Train Loss: 0.5867061603590439, Train mIoU Score: 0.4326\n",
      "Validation Loss: 1.0719981320902832, Validation mIoU Score: 0.3799\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [03:42<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.4364 Class1: 0.4495 Class2: 0.4415 Class3: 0.4252 Class4: 0.4240 Class5: 0.4258 Class6: 0.4497 \n",
      "Class7: 0.4350 Class8: 0.4428 Class9: 0.4412 Class10: 0.4403 Class11: 0.4614 Class12: 0.4559 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:16<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.3581 Class1: 0.3339 Class2: 0.3471 Class3: 0.3542 Class4: 0.3521 Class5: 0.3473 Class6: 0.3455 \n",
      "Class7: 0.3458 Class8: 0.3313 Class9: 0.3491 Class10: 0.3413 Class11: 0.3332 Class12: 0.3311 \n",
      "Epoch7\n",
      "Train Loss: 0.5616764754111215, Train mIoU Score: 0.4407\n",
      "Validation Loss: 1.1619216218972817, Validation mIoU Score: 0.3438\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [03:42<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.4675 Class1: 0.4483 Class2: 0.4485 Class3: 0.4317 Class4: 0.4598 Class5: 0.4570 Class6: 0.4596 \n",
      "Class7: 0.4507 Class8: 0.4511 Class9: 0.4628 Class10: 0.4563 Class11: 0.4489 Class12: 0.4528 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:16<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.3356 Class1: 0.3230 Class2: 0.3378 Class3: 0.3401 Class4: 0.3358 Class5: 0.3355 Class6: 0.3259 \n",
      "Class7: 0.3332 Class8: 0.3197 Class9: 0.3335 Class10: 0.3256 Class11: 0.3210 Class12: 0.3165 \n",
      "Epoch8\n",
      "Train Loss: 0.5121110281169089, Train mIoU Score: 0.4535\n",
      "Validation Loss: 1.4132694729372985, Validation mIoU Score: 0.3295\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [03:41<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.4492 Class1: 0.4611 Class2: 0.4572 Class3: 0.4736 Class4: 0.4622 Class5: 0.3932 Class6: 0.4266 \n",
      "Class7: 0.4501 Class8: 0.4543 Class9: 0.4585 Class10: 0.4604 Class11: 0.4622 Class12: 0.4583 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:16<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.3681 Class1: 0.3478 Class2: 0.3691 Class3: 0.3769 Class4: 0.3592 Class5: 0.3549 Class6: 0.3607 \n",
      "Class7: 0.3607 Class8: 0.3400 Class9: 0.3635 Class10: 0.3617 Class11: 0.3399 Class12: 0.3417 \n",
      "Epoch9\n",
      "Train Loss: 0.523337991918371, Train mIoU Score: 0.4513\n",
      "Validation Loss: 1.1878875804762554, Validation mIoU Score: 0.3572\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [03:42<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.4691 Class1: 0.4729 Class2: 0.4738 Class3: 0.4672 Class4: 0.4715 Class5: 0.4742 Class6: 0.4648 \n",
      "Class7: 0.4544 Class8: 0.4758 Class9: 0.4419 Class10: 0.4655 Class11: 0.4690 Class12: 0.4576 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:17<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.3727 Class1: 0.3487 Class2: 0.3601 Class3: 0.3667 Class4: 0.3592 Class5: 0.3613 Class6: 0.3598 \n",
      "Class7: 0.3588 Class8: 0.3425 Class9: 0.3602 Class10: 0.3574 Class11: 0.3454 Class12: 0.3401 \n",
      "Epoch10\n",
      "Train Loss: 0.47301234497615763, Train mIoU Score: 0.4660\n",
      "Validation Loss: 1.1552728949449, Validation mIoU Score: 0.3564\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [03:41<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.4667 Class1: 0.4624 Class2: 0.4789 Class3: 0.4508 Class4: 0.4711 Class5: 0.4682 Class6: 0.4876 \n",
      "Class7: 0.4355 Class8: 0.4560 Class9: 0.4579 Class10: 0.4631 Class11: 0.4687 Class12: 0.4861 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:16<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.4071 Class1: 0.3805 Class2: 0.4107 Class3: 0.4133 Class4: 0.4061 Class5: 0.4037 Class6: 0.4104 \n",
      "Class7: 0.3983 Class8: 0.3813 Class9: 0.4086 Class10: 0.4001 Class11: 0.3783 Class12: 0.3789 \n",
      "Epoch11\n",
      "Train Loss: 0.4660596917561495, Train mIoU Score: 0.4656\n",
      "Validation Loss: 1.0527057632421837, Validation mIoU Score: 0.3982\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [03:41<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.4883 Class1: 0.4814 Class2: 0.4845 Class3: 0.4800 Class4: 0.4575 Class5: 0.4787 Class6: 0.4757 \n",
      "Class7: 0.4566 Class8: 0.4562 Class9: 0.4677 Class10: 0.4764 Class11: 0.4801 Class12: 0.4877 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:16<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.3741 Class1: 0.3611 Class2: 0.3757 Class3: 0.3807 Class4: 0.3747 Class5: 0.3663 Class6: 0.3708 \n",
      "Class7: 0.3787 Class8: 0.3566 Class9: 0.3772 Class10: 0.3642 Class11: 0.3539 Class12: 0.3468 \n",
      "Epoch12\n",
      "Train Loss: 0.44565503049526495, Train mIoU Score: 0.4747\n",
      "Validation Loss: 1.11174327109614, Validation mIoU Score: 0.3678\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [03:42<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.4824 Class1: 0.4760 Class2: 0.4819 Class3: 0.4682 Class4: 0.4776 Class5: 0.4881 Class6: 0.4842 \n",
      "Class7: 0.4772 Class8: 0.4926 Class9: 0.4713 Class10: 0.4843 Class11: 0.4876 Class12: 0.4880 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:16<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.4008 Class1: 0.3741 Class2: 0.3949 Class3: 0.3969 Class4: 0.3912 Class5: 0.3879 Class6: 0.3912 \n",
      "Class7: 0.3967 Class8: 0.3758 Class9: 0.3931 Class10: 0.3786 Class11: 0.3650 Class12: 0.3633 \n",
      "Epoch13\n",
      "Train Loss: 0.41862622367554025, Train mIoU Score: 0.4815\n",
      "Validation Loss: 0.9440273354705583, Validation mIoU Score: 0.3854\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [03:42<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.5049 Class1: 0.4838 Class2: 0.4772 Class3: 0.4950 Class4: 0.4953 Class5: 0.4936 Class6: 0.4807 \n",
      "Class7: 0.4850 Class8: 0.4626 Class9: 0.4994 Class10: 0.4879 Class11: 0.4889 Class12: 0.4941 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:16<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.4183 Class1: 0.3941 Class2: 0.4240 Class3: 0.4144 Class4: 0.4096 Class5: 0.4082 Class6: 0.4075 \n",
      "Class7: 0.4018 Class8: 0.3897 Class9: 0.4092 Class10: 0.4089 Class11: 0.3795 Class12: 0.3797 \n",
      "Epoch14\n",
      "Train Loss: 0.40640063798275583, Train mIoU Score: 0.4883\n",
      "Validation Loss: 1.0045410152683911, Validation mIoU Score: 0.4035\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [03:42<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.4846 Class1: 0.4902 Class2: 0.5064 Class3: 0.4812 Class4: 0.4950 Class5: 0.4988 Class6: 0.5087 \n",
      "Class7: 0.5073 Class8: 0.4817 Class9: 0.4469 Class10: 0.4794 Class11: 0.4832 Class12: 0.4824 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:16<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.3904 Class1: 0.3645 Class2: 0.3789 Class3: 0.3890 Class4: 0.3775 Class5: 0.3792 Class6: 0.3808 \n",
      "Class7: 0.3758 Class8: 0.3669 Class9: 0.3791 Class10: 0.3778 Class11: 0.3616 Class12: 0.3550 \n",
      "Epoch15\n",
      "Train Loss: 0.40243692576668083, Train mIoU Score: 0.4881\n",
      "Validation Loss: 1.208683170314528, Validation mIoU Score: 0.3751\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [03:41<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.4916 Class1: 0.4847 Class2: 0.5064 Class3: 0.4957 Class4: 0.5115 Class5: 0.4873 Class6: 0.4350 \n",
      "Class7: 0.4368 Class8: 0.4899 Class9: 0.4829 Class10: 0.4726 Class11: 0.4848 Class12: 0.4948 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:16<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.4094 Class1: 0.3787 Class2: 0.4060 Class3: 0.4057 Class4: 0.3948 Class5: 0.3958 Class6: 0.4017 \n",
      "Class7: 0.4002 Class8: 0.3925 Class9: 0.3973 Class10: 0.3915 Class11: 0.3764 Class12: 0.3742 \n",
      "Epoch16\n",
      "Train Loss: 0.4250159104556551, Train mIoU Score: 0.4826\n",
      "Validation Loss: 0.9346973888384991, Validation mIoU Score: 0.3942\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [03:42<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.5071 Class1: 0.5067 Class2: 0.4910 Class3: 0.5007 Class4: 0.5235 Class5: 0.4925 Class6: 0.5052 \n",
      "Class7: 0.4986 Class8: 0.5100 Class9: 0.4977 Class10: 0.4991 Class11: 0.4909 Class12: 0.4825 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:16<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.4072 Class1: 0.3789 Class2: 0.4120 Class3: 0.4058 Class4: 0.3987 Class5: 0.3945 Class6: 0.3907 \n",
      "Class7: 0.3939 Class8: 0.3902 Class9: 0.3902 Class10: 0.4019 Class11: 0.3760 Class12: 0.3800 \n",
      "Epoch17\n",
      "Train Loss: 0.36374337186795985, Train mIoU Score: 0.5004\n",
      "Validation Loss: 1.02081977072944, Validation mIoU Score: 0.3939\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [03:41<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.5129 Class1: 0.5154 Class2: 0.5009 Class3: 0.5127 Class4: 0.5086 Class5: 0.5149 Class6: 0.5172 \n",
      "Class7: 0.5038 Class8: 0.5115 Class9: 0.5214 Class10: 0.5072 Class11: 0.5100 Class12: 0.5141 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:16<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.4229 Class1: 0.4048 Class2: 0.4197 Class3: 0.4188 Class4: 0.4115 Class5: 0.4028 Class6: 0.4108 \n",
      "Class7: 0.4090 Class8: 0.3961 Class9: 0.4101 Class10: 0.4040 Class11: 0.3840 Class12: 0.3902 \n",
      "Epoch18\n",
      "Train Loss: 0.3355366071933823, Train mIoU Score: 0.5116\n",
      "Validation Loss: 0.9243277036226712, Validation mIoU Score: 0.4065\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [03:41<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.5216 Class1: 0.5142 Class2: 0.5160 Class3: 0.5102 Class4: 0.5189 Class5: 0.5212 Class6: 0.5186 \n",
      "Class7: 0.5162 Class8: 0.4973 Class9: 0.5032 Class10: 0.5193 Class11: 0.5189 Class12: 0.5178 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:16<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.4164 Class1: 0.3939 Class2: 0.4085 Class3: 0.4145 Class4: 0.4012 Class5: 0.4024 Class6: 0.4107 \n",
      "Class7: 0.4012 Class8: 0.3910 Class9: 0.4058 Class10: 0.3987 Class11: 0.3839 Class12: 0.3857 \n",
      "Epoch19\n",
      "Train Loss: 0.32331891926531364, Train mIoU Score: 0.5149\n",
      "Validation Loss: 1.0186036641781147, Validation mIoU Score: 0.4011\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 549/549 [03:41<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.5297 Class1: 0.5144 Class2: 0.5055 Class3: 0.5164 Class4: 0.5042 Class5: 0.5259 Class6: 0.5301 \n",
      "Class7: 0.5191 Class8: 0.5186 Class9: 0.5166 Class10: 0.5096 Class11: 0.4891 Class12: 0.4441 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:16<00:00,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.3247 Class1: 0.3213 Class2: 0.3374 Class3: 0.3396 Class4: 0.3250 Class5: 0.3245 Class6: 0.3268 \n",
      "Class7: 0.3240 Class8: 0.3150 Class9: 0.3310 Class10: 0.3213 Class11: 0.3057 Class12: 0.3189 \n",
      "Epoch20\n",
      "Train Loss: 0.3486968608393261, Train mIoU Score: 0.5095\n",
      "Validation Loss: 1.3049740735282245, Validation mIoU Score: 0.3242\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train loss</td><td>█▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train score</td><td>▁▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val loss</td><td>▆▇▅▅▂▃▄█▅▄▃▄▁▂▅▁▂▁▂▆</td></tr><tr><td>val score</td><td>▁▂▅▄▆▇▅▄▅▅█▆▇█▆▇▇██▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train loss</td><td>191.43458</td></tr><tr><td>train score</td><td>0.50949</td></tr><tr><td>val loss</td><td>152.68197</td></tr><tr><td>val score</td><td>0.32424</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fearless-water-1</strong> at: <a href='https://wandb.ai/limbw/practice_10_06/runs/1njpqmvv' target=\"_blank\">https://wandb.ai/limbw/practice_10_06/runs/1njpqmvv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231006_165917-1njpqmvv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "torch.cuda.empty_cache()\n",
    "import wandb\n",
    "\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"practice_10_06\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": LR,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"Samsung\",\n",
    "    \"epochs\": EP,\n",
    "    }\n",
    ")\n",
    "\n",
    "for epoch in range(EP):\n",
    "    # 클래스별 IoU를 누적할 리스트 초기화\n",
    "    train_class_ious = []\n",
    "    # 학습\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for images, masks in tqdm(dataloader):\n",
    "        images = images.float().to(device)\n",
    "        masks = masks.long().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks.squeeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # if (epoch+1) % ACCMULATION_STEP == 0:\n",
    "        #     optimizer.step()\n",
    "        #     optimizer.zero_grad()\n",
    "            # # Warmup 스케줄러 업데이트\n",
    "            # if epoch < WUP_ITERS:\n",
    "            #     scheduler_warmup.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # train 클래스별 IoU 계산\n",
    "        outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "        outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "\n",
    "        for class_id in range(N_CLASSES):\n",
    "            iou = calculate_iou_per_class(np.array(masks.cpu()), np.array(outputs), class_id)\n",
    "            train_class_ious.append(iou)\n",
    "\n",
    "    train_class_ious = np.array(train_class_ious).reshape(N_CLASSES, -1)\n",
    "    train_class_ious = np.mean(train_class_ious, axis=1)\n",
    "    print(\"--IoU Scores Train--\")\n",
    "    for class_id, iou in enumerate(train_class_ious):\n",
    "        print(f'Class{class_id}: {iou:.4f}', end=\" \")\n",
    "        if (class_id+1) % 7 == 0:\n",
    "            print()\n",
    "\n",
    "    # mIoU 계산\n",
    "    train_mIoU = np.mean(train_class_ious)\n",
    "\n",
    "    # validation\n",
    "    val_loss = 0\n",
    "    val_class_ious = []  # 클래스별 IoU를 누적할 리스트 초기화\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for images, masks in tqdm(valid_dataloader):\n",
    "            images = images.float().to(device)\n",
    "            masks = masks.long().to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            # validation loss 계산\n",
    "            val_loss += criterion(outputs, masks.squeeze(1)).item()\n",
    "\n",
    "            # validation 클래스별 IoU 계산\n",
    "            outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "            outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "\n",
    "            for class_id in range(N_CLASSES):\n",
    "                iou = calculate_iou_per_class(np.array(masks.cpu()), np.array(outputs), class_id)\n",
    "                val_class_ious.append(iou)\n",
    "\n",
    "    val_class_ious = np.array(val_class_ious).reshape(N_CLASSES, -1)\n",
    "    val_class_ious = np.mean(val_class_ious, axis=1)\n",
    "    print(\"--IoU Scores Valid--\")\n",
    "    for class_id, iou in enumerate(val_class_ious):\n",
    "        print(f'Class{class_id}: {iou:.4f}', end=\" \")\n",
    "        if (class_id+1) % 7 == 0:\n",
    "            print(\"\")\n",
    "\n",
    "    # mIoU 계산\n",
    "    val_mIoU = np.mean(val_class_ious)\n",
    "\n",
    "    # 에폭마다 결과 출력 \n",
    "    print(f\"\\nEpoch{epoch+1}\")\n",
    "    print(f\"Train Loss: {(epoch_loss/len(dataloader))}, Train mIoU Score: {train_mIoU:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss/len(valid_dataloader)}, Validation mIoU Score: {val_mIoU:.4f}\")\n",
    "    print(\"___________________________________________________________________________________________\\n\")\n",
    "\n",
    "    # log metrics to wandb\n",
    "    wandb.log({\"train score\": train_mIoU, \"train loss\": epoch_loss})\n",
    "    wandb.log({\"val score\": val_mIoU, \"val loss\": val_loss})\n",
    "    \n",
    "    \n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c2ce089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     result = []\n",
    "#     for images in tqdm(valid_dataloader):\n",
    "#         images = images.float().to(device)\n",
    "#         outputs = model(images)\n",
    "#         outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "#         outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "#         for class_id in range(N_CLASSES):\n",
    "#             iou = calculate_iou_per_class(np.array(masks.cpu()), np.array(outputs), class_id)\n",
    "#             result.append(iou)\n",
    "\n",
    "#     result = np.array(result).reshape(N_CLASSES, -1)\n",
    "#     result = np.mean(result, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c03f04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# for epoch in range(EP):\n",
    "#     # 클래스별 IoU를 누적할 리스트 초기화\n",
    "#     train_class_ious = []\n",
    "#     # 학습\n",
    "#     model.train()\n",
    "#     epoch_loss = 0\n",
    "#     for images in tqdm(target_dataloader):\n",
    "#         images = images.float().to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         _, outputs = model(images)\n",
    "#         target_domain = torch.zeros_like(outputs).to(device)\n",
    "#         loss = domain_criterion(outputs, target_domain)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         epoch_loss += loss.item()\n",
    "\n",
    "#         avg_domain_loss = epoch_loss / len(target_dataloader)\n",
    "#     print(f\"Epoch [{epoch + 1}/{EP}] - Domain Loss: {avg_domain_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c8aa1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     result = []\n",
    "#     for images in tqdm(valid_dataloader):\n",
    "#         images = images.float().to(device)\n",
    "#         outputs = model(images)\n",
    "#         outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "#         outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "#         for class_id in range(N_CLASSES):\n",
    "#             iou = calculate_iou_per_class(np.array(masks.cpu()), np.array(outputs), class_id)\n",
    "#             result.append(iou)\n",
    "\n",
    "#     result = np.array(result).reshape(N_CLASSES, -1)\n",
    "#     result = np.mean(result, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c32eb51c-a3fe-4e11-a616-3a717ba16f7e",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12371c8b-0c78-47df-89ec-2d8b55c8ea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = CustomDataset(csv_file='./test.csv', transform=transform, infer=True)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "355b431c-ac8e-4c40-9046-4d53e4bab14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     result = []\n",
    "#     for images in tqdm(test_dataloader):\n",
    "#         images = images.float().to(device)\n",
    "#         outputs = model(images)\n",
    "#         outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "#         outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "#         # batch에 존재하는 각 이미지에 대해서 반복\n",
    "#         for pred in outputs:\n",
    "#             pred = pred.astype(np.uint8)\n",
    "#             pred = Image.fromarray(pred) # 이미지로 변환\n",
    "#             pred = pred.resize((960, 540), Image.NEAREST) # 960 x 540 사이즈로 변환\n",
    "#             pred = np.array(pred) # 다시 수치로 변환\n",
    "#             # class 0 ~ 11에 해당하는 경우에 마스크 형성 / 12(배경)는 제외하고 진행\n",
    "#             for class_id in range(12):\n",
    "#                 class_mask = (pred == class_id).astype(np.uint8)\n",
    "#                 if np.sum(class_mask) > 0: # 마스크가 존재하는 경우 encode\n",
    "#                     mask_rle = rle_encode(class_mask)\n",
    "#                     result.append(mask_rle)\n",
    "#                 else: # 마스크가 존재하지 않는 경우 -1\n",
    "#                     result.append(-1)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36c2cbbb-04f1-4f9c-b4df-4b744dfce046",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35ac2a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit = pd.read_csv('./sample_submission.csv')\n",
    "# submit['mask_rle'] = result\n",
    "# submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da10cb6f-0826-4755-a376-97b695ae8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit.to_csv('./baseline_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seungyoon2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
