{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d73d24e3-5c9e-4ade-9e6e-ca6f46a2d914",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad9b681e-370a-4cfa-a452-dd2d7f0cd77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/MMI24limbyungwan/.conda/envs/byungwan_resn/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# GPU 사용이 가능할 경우, GPU를 사용할 수 있게 함.'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "print(device)\n",
    "\n",
    "print(os.environ.get('CUDA_VISIBLE_DEVICES'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20ff3de5-0d0e-497b-ac75-d5179a3f65d3",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "838e1d83-8670-407b-82f6-bf9652f58639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "# 클래스별 IoU를 계산하기 위한 함수\n",
    "def calculate_iou_per_class(y_true, y_pred, class_id):\n",
    "    intersection = np.sum((y_true == class_id) & (y_pred == class_id))\n",
    "    union = np.sum((y_true == class_id) | (y_pred == class_id))\n",
    "    iou = intersection / union if union > 0 else 0\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5c64ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "\n",
    "class GradReverseFunction(autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, l):\n",
    "        ctx.l = l\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output.neg() * ctx.l, None\n",
    "\n",
    "def grad_reverse(x, l):\n",
    "    return GradReverseFunction.apply(x, l)\n",
    "\n",
    "class GradReverse(nn.Module):\n",
    "    def __init__(self, l):\n",
    "        super(GradReverse, self).__init__()\n",
    "        self.l = nn.Parameter(torch.tensor(l), requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return grad_reverse(x, self.l)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be76a29e-e9c2-411a-a569-04166f074184",
   "metadata": {},
   "source": [
    "## Dataset, Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5acf65a",
   "metadata": {},
   "source": [
    "출력이미지 크기 키우기->ex) resnet 2048->1024->512->256 conv 256->512->1024->2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8496767-2f64-4285-bec4-c6f53a1fd9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        directory_path = \"/mnt/nas27/Dataset/Samsung_DM\"\n",
    "        img_path = self.data.iloc[idx, 1]\n",
    "        img_path = os.path.join(directory_path, img_path[2:])\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "        \n",
    "        mask_path = self.data.iloc[idx, 2]\n",
    "        mask_path = os.path.join(directory_path, mask_path[2:])\n",
    "        mask = cv2.imread(mask_path)\n",
    "        #mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        mask[mask == 255] = 12 #배경을 픽셀값 12로 간주\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "class CustomDataset_target(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        directory_path = \"/mnt/nas27/Dataset/Samsung_DM\"\n",
    "        img_path = self.data.iloc[idx, 1]\n",
    "        img_path = os.path.join(directory_path, img_path[2:])\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "            \n",
    "\n",
    "        return image\n",
    "     \n",
    "\n",
    "transform = A.Compose(\n",
    "    [   \n",
    "        #A.Resize(224, 224),\n",
    "        A.Resize(128, 128),\n",
    "        A.Normalize(),\n",
    "        \n",
    "        # 변형\n",
    "        # A.VerticalFlip(p=0.5),\n",
    "        # A.RandomRotate90(p=0.5),\n",
    "        # A.HueSaturationValue(p=0.2),\n",
    "        \n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a91d6b1",
   "metadata": {},
   "source": [
    "Warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9e62c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class WarmUpLR(_LRScheduler):\n",
    "#     def __init__(self, optimizer, total_iters, last_epoch=-1):\n",
    "#         self.total_iters = total_iters\n",
    "#         super(WarmUpLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "#     def get_lr(self):\n",
    "#         return [base_lr * self.last_epoch / self.total_iters for base_lr in self.base_lrs]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f42501fc-b573-4893-a7c4-5e280dfdaf09",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3574888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unet의 기본이 되는 conv블럭\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)  # 여기서 in_channels는 out_channels와 동일해야 합니다.\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        return x\n",
    "\n",
    "#인코더 블럭\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(EncoderBlock,self).__init__()\n",
    "        self.convblock1 = ConvBlock(in_channels, out_channels)  # 첫 번째 ConvBlock의 in_channels는 입력 이미지의 채널 수와 일치해야 합니다.\n",
    "        #self.convblock2 = ConvBlock(out_channels, out_channels)  # 두 번째 ConvBlock의 in_channels는 out_channels와 일치해야 합니다.\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.convblock1(x)\n",
    "        #x = self.convblock2(x)\n",
    "        p = self.maxpool(x)\n",
    "        return x , p\n",
    "#디코더 블럭\n",
    "#디코더는 업샘플링 이후 스킵연결과 붙어서 convblock을 통과해야함\n",
    "#skip보다 작은 x x먼저 업샘플링 32 -> 64 , skip과 결합 6464 \n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(DecoderBlock,self).__init__()\n",
    "        self.upsample = nn.ConvTranspose2d(channels*2, channels, kernel_size=4, stride=2, padding=1)#x 업샘플링\n",
    "        self.convblock1 = ConvBlock(channels*2, channels)#차원감소\n",
    "        #self.convblock2 = ConvBlock(channels, channels)\n",
    "    def forward(self,x,skip):\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.convblock1(x)\n",
    "        #x = self.convblock2(x)\n",
    "        return x\n",
    "        \n",
    "#Unet구조 middle의 xm값의 움직임에 주의\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self,n_classes):\n",
    "        super(Unet,self).__init__()\n",
    "        self.encoder1 = EncoderBlock(3,64)\n",
    "        self.encoder2 = EncoderBlock(64,128)\n",
    "        self.encoder3 = EncoderBlock(128,256)\n",
    "        self.encoder4 = EncoderBlock(256,512)\n",
    "        \n",
    "        self.middleconv = ConvBlock(512,1024)\n",
    "        \n",
    "        \n",
    "        self.decoder4 = DecoderBlock(512)\n",
    "        self.decoder3 = DecoderBlock(256)\n",
    "        self.decoder2 = DecoderBlock(128)\n",
    "        self.decoder1 = DecoderBlock(64)\n",
    "        self.segmap = nn.Conv2d(64,n_classes, kernel_size=1)\n",
    "        \n",
    "        ##\n",
    "        # self.domain_classifier = nn.Sequential(\n",
    "        #     nn.Conv3d(1024, 64, kernel_size=3, padding=1),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Conv3d(64, 32, kernel_size=3, padding=1),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Flatten(),\n",
    "        #     nn.Linear(32 * 16 * 16 * 16, 1),\n",
    "        #     nn.Sigmoid()\n",
    "        # )\n",
    "\n",
    "        # self.grad_reverse = GradReverse(0.0)\n",
    "        ##\n",
    "\n",
    "    def forward(self,x):\n",
    "        x1,p = self.encoder1(x)#3->64   #P:256,256 x1 :512,512\n",
    "        x2,p = self.encoder2(p)#64->128 #P:128,128 x2:256,256\n",
    "        x3,p = self.encoder3(p)#128->256#p:64,64 x3:128,128\n",
    "        x4,p = self.encoder4(p)#256->512#p:32,32 x4:64,64\n",
    "        \n",
    "        xm = self.middleconv(p)#512->1024#32,32\n",
    "        \n",
    "        x = self.decoder4(xm,x4)#뉴런:1024->512->512 #출력tensor:64,64\n",
    "        x = self.decoder3(x,x3)#뉴런:512->256->256 #출력tensor:128,128\n",
    "        x = self.decoder2(x,x2)#뉴런:256->128->128 #출력tensor:256,256\n",
    "        x = self.decoder1(x,x1)#뉴런:128->64->64 #출력tensor:512,512\n",
    "        x = self.segmap(x)\n",
    "\n",
    "        # 도메인 분류기에 GradReverse 적용\n",
    "        #feat = self.grad_reverse(x)\n",
    "        #domain_output = self.domain_classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdb7c3b",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baf22f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# import torchvision.models as models\n",
    "\n",
    "# class UNetWithResnet50Encoder(nn.Module):\n",
    "#     def __init__(self, n_classes):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         # ResNet50 백본을 불러옵니다.\n",
    "#         self.resnet = models.resnet50(pretrained=True)\n",
    "        \n",
    "#         # 인코더 부분\n",
    "#         self.encoder0 = nn.Sequential(\n",
    "#             self.resnet.conv1,\n",
    "#             self.resnet.bn1,\n",
    "#             self.resnet.relu,\n",
    "#             self.resnet.maxpool\n",
    "#         )\n",
    "#         self.encoder1 = self.resnet.layer1\n",
    "#         self.encoder2 = self.resnet.layer2\n",
    "#         self.encoder3 = self.resnet.layer3\n",
    "#         self.encoder4 = self.resnet.layer4\n",
    "        \n",
    "#         # 중간 컨볼루션\n",
    "#         self.middle_conv = nn.Sequential(\n",
    "#             nn.Conv2d(2048, 1024, kernel_size=3, padding=1),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "        \n",
    "#         # 디코더 부분\n",
    "#         self.decoder3 = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(1024+1024, 512, kernel_size=2, stride=2),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "#         self.decoder2 = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(512+512, 256, kernel_size=2, stride=2),\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "#         # 디코더 부분\n",
    "#         self.decoder1 = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(256+256, 128, kernel_size=2, stride=2),  # 출력 채널 수를 128로 변경\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "#         self.decoder0 = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(128+64, n_classes, kernel_size=2, stride=2),  # 입력 채널 수를 192로 변경\n",
    "#             nn.ReLU()\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         # 인코더 부분\n",
    "#         x0 = self.encoder0(x)\n",
    "#         x1 = self.encoder1(x0)\n",
    "#         x2 = self.encoder2(x1)\n",
    "#         x3 = self.encoder3(x2)\n",
    "#         x4 = self.encoder4(x3)\n",
    "        \n",
    "#         # 중간 컨볼루션 후 업샘플링\n",
    "#         middle = self.middle_conv(x4)\n",
    "#         middle_upsampled = nn.functional.interpolate(middle, scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "#         # 디코더 부분 (skip connection 추가)\n",
    "#         d3 = self.decoder3(torch.cat([middle_upsampled, x3], dim=1))\n",
    "#         d2 = self.decoder2(torch.cat([d3, x2], dim=1))\n",
    "#         d1 = self.decoder1(torch.cat([d2, x1], dim=1))\n",
    "#         out = self.decoder0(torch.cat([d1, x0], dim=1))\n",
    "        \n",
    "#         return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd34483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "EP = 5\n",
    "BATCH_SIZE = 64\n",
    "ACCMULATION_STEP = 1 \n",
    "N_CLASSES = 13 #IoU 점수측정하기 위한 클래스의 개수\n",
    "# WUP_ITERS = 10  # 웜업을 위한 반복 횟수\n",
    "# model 초기화\n",
    "#model = Unet_resnet18(n_classes = N_CLASSES).to(device)\n",
    "#model = ResNet50(num_classes=N_CLASSES).to(device)\n",
    "model = Unet(n_classes = N_CLASSES).to(device)\n",
    "\n",
    "# loss function과 optimizer 정의\n",
    "\n",
    "criterion =nn.CrossEntropyLoss()\n",
    "domain_criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "optimizer.zero_grad() \n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9, nesterov=True)\n",
    "# Warmup을 위한 스케줄러 설정\n",
    "# scheduler_warmup = WarmUpLR(optimizer, WUP_ITERS)\n",
    "\n",
    "dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./train_source.csv'), transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "valid_dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./val_source.csv'), transform=transform)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "target_dataset = CustomDataset_target(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./train_target.csv'), transform=transform)\n",
    "target_dataloader = DataLoader(target_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "test_dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./test.csv'), transform=transform, infer=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b305ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # 데이터셋을 불러옵니다.\n",
    "# csv_file = os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\", './train_source.csv')\n",
    "# data = pd.read_csv(csv_file)\n",
    "\n",
    "# # 클래스별 샘플 수를 저장할 리스트를 초기화합니다.\n",
    "# class_sample_counts = [0] * N_CLASSES  # num_classes는 클래스의 총 개수입니다.\n",
    "\n",
    "# # 데이터셋을 순회하면서 클래스별 샘플 수를 세고 저장합니다.\n",
    "# for idx in range(len(data)):\n",
    "#     mask_path = os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\", data.iloc[idx, 2][2:])  # 마스크 이미지 경로\n",
    "#     mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "#     mask[mask == 255] = 12  # 배경 클래스로 처리\n",
    "\n",
    "#     # 각 클래스의 샘플 수를 카운트합니다.\n",
    "#     for class_id in range(N_CLASSES):\n",
    "#         class_sample_counts[class_id] += (mask == class_id).sum()\n",
    "\n",
    "# # 클래스별 가중치를 계산합니다.\n",
    "# total_samples = sum(class_sample_counts)\n",
    "# class_weights = [total_samples / count for count in class_sample_counts]\n",
    "\n",
    "# # 클래스별 가중치를 텐서로 변환합니다.\n",
    "# class_weights = torch.tensor(class_weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f17dba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(class_sample_counts)\n",
    "# print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8216c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # 데이터로더에서 배치 하나를 가져옵니다.\n",
    "# dataiter = iter(dataloader)\n",
    "# images, masks = next(dataiter)\n",
    "\n",
    "# # 이미지를 시각화합니다.\n",
    "# for i in range(images.size(0)):\n",
    "#     image = images[i].permute(1, 2, 0).numpy()  # 이미지를 CHW에서 HWC로 변환\n",
    "#     mask = masks[i].numpy()\n",
    "\n",
    "#     plt.figure(figsize=(8, 8))\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.imshow(image)\n",
    "#     plt.title(\"Image\")\n",
    "\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.imshow(mask, cmap='gray')\n",
    "#     plt.title(\"Mask\")\n",
    "\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "697a9e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for images, masks in tqdm(dataloader):\n",
    "#     a = images.float().to(device)\n",
    "#     b = masks.long().to(device)\n",
    "#     break\n",
    "\n",
    "# # PyTorch Tensor를 NumPy 배열로 변환\n",
    "# a_numpy = a[3].cpu().numpy()  # 첫 번째 이미지만 선택하거나 필요한 이미지를 선택하세요.\n",
    "# a_numpy = np.transpose(a_numpy, (1, 2, 0))\n",
    "# b_numpy = b[3].cpu().numpy()\n",
    "# b_numpy = b_numpy*12\n",
    "\n",
    "# # 이미지를 저장\n",
    "# cv2.imwrite('image_source.png', a_numpy)  # 이미지 저장\n",
    "# cv2.imwrite('image_mask.png', b_numpy)   # 마스크 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "313afd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for epoch in range(2):  # 5 에폭 동안 학습합니다.\n",
    "          \n",
    "#     # 클래스별 IoU를 누적할 리스트 초기화\n",
    "#     train_class_ious = []\n",
    "    \n",
    "#     # 학습\n",
    "#     model.train()\n",
    "#     epoch_loss = 0\n",
    "    \n",
    "#     for images, masks in tqdm(dataloader):\n",
    "#         images = images.float().to(device)\n",
    "#         masks = masks.long().to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(images)\n",
    "#         mask_spueeze = masks.squeeze(1)\n",
    "#         loss = criterion(outputs, masks.squeeze(1))\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         epoch_loss += loss.item()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0895765-fba0-4fd9-b955-a6c0e43012e9",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dec3e516",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [02:20<00:00,  4.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.0919 Class1: 0.1953 Class2: 0.2588 Class3: 0.2539 Class4: 0.2671 Class5: 0.3098 Class6: 0.2792 \n",
      "Class7: 0.2973 Class8: 0.3514 Class9: 0.2943 Class10: 0.3301 Class11: 0.3522 Class12: 0.3387 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:30<00:00,  3.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.2100 Class1: 0.3960 Class2: 0.1967 Class3: 0.2884 Class4: 0.4174 Class5: 0.2735 Class6: 0.2752 \n",
      "Class7: 0.2285 Class8: 0.2304 Class9: 0.4168 Class10: 0.2455 Class11: 0.2834 Class12: 0.3153 \n",
      "Epoch1\n",
      "Train Loss: 1.1496937922069004, Train mIoU Score: 0.2785\n",
      "Validation Loss: 0.9325250685214996, Validation mIoU Score: 0.2905\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [02:00<00:00,  3.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.3349 Class1: 0.3334 Class2: 0.3635 Class3: 0.3202 Class4: 0.3398 Class5: 0.3738 Class6: 0.3326 \n",
      "Class7: 0.3451 Class8: 0.4009 Class9: 0.3274 Class10: 0.3527 Class11: 0.3792 Class12: 0.3678 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:24<00:00,  3.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.2096 Class1: 0.4105 Class2: 0.1666 Class3: 0.3302 Class4: 0.4321 Class5: 0.2306 Class6: 0.3139 \n",
      "Class7: 0.1982 Class8: 0.2690 Class9: 0.4354 Class10: 0.2218 Class11: 0.3274 Class12: 0.3184 \n",
      "Epoch2\n",
      "Train Loss: 0.5872848442622594, Train mIoU Score: 0.3516\n",
      "Validation Loss: 0.8319521546363831, Validation mIoU Score: 0.2972\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [02:16<00:00,  3.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.3530 Class1: 0.3603 Class2: 0.3838 Class3: 0.3360 Class4: 0.3627 Class5: 0.3906 Class6: 0.3512 \n",
      "Class7: 0.3870 Class8: 0.4249 Class9: 0.3828 Class10: 0.3882 Class11: 0.4303 Class12: 0.3925 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:33<00:00,  4.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.2625 Class1: 0.4658 Class2: 0.2133 Class3: 0.3709 Class4: 0.4845 Class5: 0.3010 Class6: 0.3618 \n",
      "Class7: 0.2447 Class8: 0.3052 Class9: 0.4970 Class10: 0.2803 Class11: 0.3739 Class12: 0.3800 \n",
      "Epoch3\n",
      "Train Loss: 0.4564221177782331, Train mIoU Score: 0.3803\n",
      "Validation Loss: 0.5285428613424301, Validation mIoU Score: 0.3493\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [02:24<00:00,  4.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.4049 Class1: 0.4071 Class2: 0.4243 Class3: 0.3877 Class4: 0.4170 Class5: 0.4360 Class6: 0.3935 \n",
      "Class7: 0.4225 Class8: 0.4634 Class9: 0.4129 Class10: 0.4515 Class11: 0.4668 Class12: 0.4268 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:23<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.2615 Class1: 0.3927 Class2: 0.2104 Class3: 0.3339 Class4: 0.4309 Class5: 0.2779 Class6: 0.3187 \n",
      "Class7: 0.2011 Class8: 0.2966 Class9: 0.4364 Class10: 0.2497 Class11: 0.3480 Class12: 0.3574 \n",
      "Epoch4\n",
      "Train Loss: 0.3920575669833592, Train mIoU Score: 0.4242\n",
      "Validation Loss: 0.824469156563282, Validation mIoU Score: 0.3166\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [02:23<00:00,  4.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Train--\n",
      "Class0: 0.4640 Class1: 0.4520 Class2: 0.4653 Class3: 0.4362 Class4: 0.4554 Class5: 0.4798 Class6: 0.4417 \n",
      "Class7: 0.4778 Class8: 0.5077 Class9: 0.4431 Class10: 0.4922 Class11: 0.4966 Class12: 0.4487 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:28<00:00,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IoU Scores Valid--\n",
      "Class0: 0.3095 Class1: 0.4807 Class2: 0.2571 Class3: 0.3852 Class4: 0.5061 Class5: 0.3378 Class6: 0.3876 \n",
      "Class7: 0.2689 Class8: 0.3391 Class9: 0.4990 Class10: 0.2983 Class11: 0.4052 Class12: 0.4349 \n",
      "Epoch5\n",
      "Train Loss: 0.35549231001308984, Train mIoU Score: 0.4662\n",
      "Validation Loss: 0.5135640799999237, Validation mIoU Score: 0.3776\n",
      "___________________________________________________________________________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for epoch in range(EP):\n",
    "    # 클래스별 IoU를 누적할 리스트 초기화\n",
    "    train_class_ious = []\n",
    "    # 학습\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for images, masks in tqdm(dataloader):\n",
    "        images = images.float().to(device)\n",
    "        masks = masks.long().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks.squeeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # if (epoch+1) % ACCMULATION_STEP == 0:\n",
    "        #     optimizer.step()\n",
    "        #     optimizer.zero_grad()\n",
    "            # # Warmup 스케줄러 업데이트\n",
    "            # if epoch < WUP_ITERS:\n",
    "            #     scheduler_warmup.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # train 클래스별 IoU 계산\n",
    "        outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "        outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "\n",
    "        for class_id in range(N_CLASSES):\n",
    "            iou = calculate_iou_per_class(np.array(masks.cpu()), np.array(outputs), class_id)\n",
    "            train_class_ious.append(iou)\n",
    "\n",
    "    train_class_ious = np.array(train_class_ious).reshape(N_CLASSES, -1)\n",
    "    train_class_ious = np.mean(train_class_ious, axis=1)\n",
    "    print(\"--IoU Scores Train--\")\n",
    "    for class_id, iou in enumerate(train_class_ious):\n",
    "        print(f'Class{class_id}: {iou:.4f}', end=\" \")\n",
    "        if (class_id+1) % 7 == 0:\n",
    "            print()\n",
    "\n",
    "    # mIoU 계산\n",
    "    train_mIoU = np.mean(train_class_ious)\n",
    "\n",
    "    # validation\n",
    "    val_loss = 0\n",
    "    val_class_ious = []  # 클래스별 IoU를 누적할 리스트 초기화\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for images, masks in tqdm(valid_dataloader):\n",
    "            images = images.float().to(device)\n",
    "            masks = masks.long().to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            # validation loss 계산\n",
    "            val_loss += criterion(outputs, masks.squeeze(1)).item()\n",
    "\n",
    "            # validation 클래스별 IoU 계산\n",
    "            outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "            outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "\n",
    "            for class_id in range(N_CLASSES):\n",
    "                iou = calculate_iou_per_class(np.array(masks.cpu()), np.array(outputs), class_id)\n",
    "                val_class_ious.append(iou)\n",
    "\n",
    "    val_class_ious = np.array(val_class_ious).reshape(N_CLASSES, -1)\n",
    "    val_class_ious = np.mean(val_class_ious, axis=1)\n",
    "    print(\"--IoU Scores Valid--\")\n",
    "    for class_id, iou in enumerate(val_class_ious):\n",
    "        print(f'Class{class_id}: {iou:.4f}', end=\" \")\n",
    "        if (class_id+1) % 7 == 0:\n",
    "            print(\"\")\n",
    "\n",
    "    # mIoU 계산\n",
    "    val_mIoU = np.mean(val_class_ious)\n",
    "\n",
    "    # 에폭마다 결과 출력 \n",
    "    print(f\"\\nEpoch{epoch+1}\")\n",
    "    print(f\"Train Loss: {(epoch_loss/len(dataloader))}, Train mIoU Score: {train_mIoU:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss/len(valid_dataloader)}, Validation mIoU Score: {val_mIoU:.4f}\")\n",
    "    print(\"___________________________________________________________________________________________\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c2ce089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     result = []\n",
    "#     for images in tqdm(valid_dataloader):\n",
    "#         images = images.float().to(device)\n",
    "#         outputs = model(images)\n",
    "#         outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "#         outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "#         for class_id in range(N_CLASSES):\n",
    "#             iou = calculate_iou_per_class(np.array(masks.cpu()), np.array(outputs), class_id)\n",
    "#             result.append(iou)\n",
    "\n",
    "#     result = np.array(result).reshape(N_CLASSES, -1)\n",
    "#     result = np.mean(result, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c03f04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# for epoch in range(EP):\n",
    "#     # 클래스별 IoU를 누적할 리스트 초기화\n",
    "#     train_class_ious = []\n",
    "#     # 학습\n",
    "#     model.train()\n",
    "#     epoch_loss = 0\n",
    "#     for images in tqdm(target_dataloader):\n",
    "#         images = images.float().to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         _, outputs = model(images)\n",
    "#         target_domain = torch.zeros_like(outputs).to(device)\n",
    "#         loss = domain_criterion(outputs, target_domain)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         epoch_loss += loss.item()\n",
    "\n",
    "#         avg_domain_loss = epoch_loss / len(target_dataloader)\n",
    "#     print(f\"Epoch [{epoch + 1}/{EP}] - Domain Loss: {avg_domain_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c8aa1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     result = []\n",
    "#     for images in tqdm(valid_dataloader):\n",
    "#         images = images.float().to(device)\n",
    "#         outputs = model(images)\n",
    "#         outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "#         outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "#         for class_id in range(N_CLASSES):\n",
    "#             iou = calculate_iou_per_class(np.array(masks.cpu()), np.array(outputs), class_id)\n",
    "#             result.append(iou)\n",
    "\n",
    "#     result = np.array(result).reshape(N_CLASSES, -1)\n",
    "#     result = np.mean(result, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c32eb51c-a3fe-4e11-a616-3a717ba16f7e",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12371c8b-0c78-47df-89ec-2d8b55c8ea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = CustomDataset(csv_file='./test.csv', transform=transform, infer=True)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "355b431c-ac8e-4c40-9046-4d53e4bab14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     result = []\n",
    "#     for images in tqdm(test_dataloader):\n",
    "#         images = images.float().to(device)\n",
    "#         outputs = model(images)\n",
    "#         outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "#         outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "#         # batch에 존재하는 각 이미지에 대해서 반복\n",
    "#         for pred in outputs:\n",
    "#             pred = pred.astype(np.uint8)\n",
    "#             pred = Image.fromarray(pred) # 이미지로 변환\n",
    "#             pred = pred.resize((960, 540), Image.NEAREST) # 960 x 540 사이즈로 변환\n",
    "#             pred = np.array(pred) # 다시 수치로 변환\n",
    "#             # class 0 ~ 11에 해당하는 경우에 마스크 형성 / 12(배경)는 제외하고 진행\n",
    "#             for class_id in range(12):\n",
    "#                 class_mask = (pred == class_id).astype(np.uint8)\n",
    "#                 if np.sum(class_mask) > 0: # 마스크가 존재하는 경우 encode\n",
    "#                     mask_rle = rle_encode(class_mask)\n",
    "#                     result.append(mask_rle)\n",
    "#                 else: # 마스크가 존재하지 않는 경우 -1\n",
    "#                     result.append(-1)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36c2cbbb-04f1-4f9c-b4df-4b744dfce046",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35ac2a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit = pd.read_csv('./sample_submission.csv')\n",
    "# submit['mask_rle'] = result\n",
    "# submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da10cb6f-0826-4755-a376-97b695ae8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit.to_csv('./baseline_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seungyoon2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
