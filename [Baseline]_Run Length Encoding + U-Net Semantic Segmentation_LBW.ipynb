{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d73d24e3-5c9e-4ade-9e6e-ca6f46a2d914",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3db653c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "print(os.environ.get('CUDA_VISIBLE_DEVICES'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad9b681e-370a-4cfa-a452-dd2d7f0cd77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/MMI24limbyungwan/.conda/envs/byungwan_resn/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "\n",
    "# CUDA 장치 사용 가능 여부 확인\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20ff3de5-0d0e-497b-ac75-d5179a3f65d3",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "838e1d83-8670-407b-82f6-bf9652f58639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be76a29e-e9c2-411a-a569-04166f074184",
   "metadata": {},
   "source": [
    "## Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8496767-2f64-4285-bec4-c6f53a1fd9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        directory_path = \"/mnt/nas27/Dataset/Samsung_DM\"\n",
    "        img_path = self.data.iloc[idx, 1]\n",
    "        img_path = os.path.join(directory_path, img_path[2:])\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "        \n",
    "        mask_path = self.data.iloc[idx, 2]\n",
    "        mask_path = os.path.join(directory_path, mask_path[2:])\n",
    "        mask = cv2.imread(mask_path)\n",
    "        #mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        mask[mask == 255] = 12 #배경을 픽셀값 12로 간주\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc955893-22fd-4320-88be-7aa0d790cbd9",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b708503-2ff9-4584-9d73-40990b3572f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose(\n",
    "    [   \n",
    "        #A.Resize(224, 224),\n",
    "        A.Resize(256, 256),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./train_source.csv'), transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "valid_dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./val_source.csv'), transform=transform)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f42501fc-b573-4893-a7c4-5e280dfdaf09",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65960bfb-803a-4c40-b713-6f647779e4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net의 기본 구성 요소인 Double Convolution Block을 정의합니다.\n",
    "def double_conv(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "# 간단한 U-Net 모델 정의\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.dconv_down1 = double_conv(3, 64)\n",
    "        self.dconv_down2 = double_conv(64, 128)\n",
    "        self.dconv_down3 = double_conv(128, 256)\n",
    "        self.dconv_down4 = double_conv(256, 512)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.dconv_up3 = double_conv(256 + 512, 256)\n",
    "        self.dconv_up2 = double_conv(128 + 256, 128)\n",
    "        self.dconv_up1 = double_conv(128 + 64, 64)\n",
    "\n",
    "        self.conv_last = nn.Conv2d(64, 13, 1) # 12개 class + 1 background\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "\n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)   \n",
    "\n",
    "        x = self.dconv_down4(x)\n",
    "\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "\n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv2], dim=1)\n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv1], dim=1)\n",
    "\n",
    "        x = self.dconv_up1(x)\n",
    "\n",
    "        out = self.conv_last(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0895765-fba0-4fd9-b955-a6c0e43012e9",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63efb381-98c6-4d9b-a3b6-bd11c7fa8c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model 초기화\n",
    "# model = UNet().to(device)\n",
    "\n",
    "# # loss function과 optimizer 정의\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# # training loop\n",
    "# for epoch in tqdm(range(20)):  # 20 에폭 동안 학습합니다.\n",
    "#     model.train()\n",
    "#     epoch_loss = 0\n",
    "#     for images, masks in tqdm(dataloader):\n",
    "#         images = images.float().to(device)\n",
    "#         masks = masks.long().to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(images)\n",
    "#         loss = criterion(outputs, masks.squeeze(1))\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         epoch_loss += loss.item()\n",
    "\n",
    "#     print(f'Epoch {epoch+1}, Loss: {epoch_loss/len(dataloader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4c8bbb",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "574ecd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_dataset = CustomDataset(csv_file='./val_source.csv', transform=transform, infer=True)\n",
    "# valid_dataloader = DataLoader(valid_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "# # 클래스(레이블) 수\n",
    "# num_classes = 12\n",
    "\n",
    "# # 클래스별 IoU를 계산하기 위한 함수\n",
    "# def calculate_iou_per_class(y_true, y_pred, class_id):\n",
    "#     intersection = np.sum((y_true == class_id) & (y_pred == class_id))\n",
    "#     union = np.sum((y_true == class_id) | (y_pred == class_id))\n",
    "#     iou = intersection / union if union > 0 else 0\n",
    "#     return iou\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     result = []\n",
    "#     valid_true = []\n",
    "#     for images, masks in tqdm(valid_dataloader):\n",
    "#         images = images.float().to(device)\n",
    "#         outputs = model(images)\n",
    "#         outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "#         outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "#         # 클래스별 IoU를 계산하고 기록\n",
    "#         class_ious = []\n",
    "#         for class_id in range(num_classes):\n",
    "#             iou = calculate_iou_per_class(masks, np.array(outputs), class_id)\n",
    "#             class_ious.append(iou)\n",
    "#         # batch에 존재하는 각 이미지에 대해서 반복\n",
    "#         for pred in outputs:\n",
    "#             pred = pred.astype(np.uint8)\n",
    "#             pred = Image.fromarray(pred) # 이미지로 변환\n",
    "#             pred = pred.resize((960, 540), Image.NEAREST) # 960 x 540 사이즈로 변환\n",
    "#             pred = np.array(pred) # 다시 수치로 변환\n",
    "#             # class 0 ~ 11에 해당하는 경우에 마스크 형성 / 12(배경)는 제외하고 진행\n",
    "#             for class_id in range(12):\n",
    "#                 class_mask = (pred == class_id).astype(np.uint8)\n",
    "#                 if np.sum(class_mask) > 0: # 마스크가 존재하는 경우 encode\n",
    "#                     mask_rle = rle_encode(class_mask)\n",
    "#                     result.append(mask_rle)\n",
    "#                 else: # 마스크가 존재하지 않는 경우 -1\n",
    "#                     result.append(-1)\n",
    "#         # Validation 데이터셋의 정답 이미지를 로드하여 mIoU 계산\n",
    "\n",
    "\n",
    "# # 클래스별 IoU 출력\n",
    "# for class_id, iou in enumerate(class_ious):\n",
    "#     print(f'Class {class_id} IoU: {iou:.4f}')\n",
    "\n",
    "# # mIoU 계산\n",
    "# mIoU = np.mean(class_ious)\n",
    "# print(f\"mIoU Score: {mIoU:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75d5112b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [02:19<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 IoU: 0.0158\n",
      "Class 1 IoU: 0.0161\n",
      "Class 2 IoU: 0.0127\n",
      "Class 3 IoU: 0.0217\n",
      "Class 4 IoU: 0.0121\n",
      "Class 5 IoU: 0.0231\n",
      "Class 6 IoU: 0.0276\n",
      "Class 7 IoU: 0.0171\n",
      "Class 8 IoU: 0.0190\n",
      "Class 9 IoU: 0.0173\n",
      "Class 10 IoU: 0.0168\n",
      "Class 11 IoU: 0.0207\n",
      "Class 12 IoU: 0.0219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:28<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 IoU: 0.0278\n",
      "Class 1 IoU: 0.0311\n",
      "Class 2 IoU: 0.0285\n",
      "Class 3 IoU: 0.0278\n",
      "Class 4 IoU: 0.0454\n",
      "Class 5 IoU: 0.0281\n",
      "Class 6 IoU: 0.0395\n",
      "Class 7 IoU: 0.0296\n",
      "Class 8 IoU: 0.0239\n",
      "Class 9 IoU: 0.0296\n",
      "Class 10 IoU: 0.0469\n",
      "Class 11 IoU: 0.0275\n",
      "Class 12 IoU: 0.0339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [02:19<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 IoU: 0.0273\n",
      "Class 1 IoU: 0.0332\n",
      "Class 2 IoU: 0.0381\n",
      "Class 3 IoU: 0.0480\n",
      "Class 4 IoU: 0.0426\n",
      "Class 5 IoU: 0.0496\n",
      "Class 6 IoU: 0.0505\n",
      "Class 7 IoU: 0.0505\n",
      "Class 8 IoU: 0.0577\n",
      "Class 9 IoU: 0.0644\n",
      "Class 10 IoU: 0.0559\n",
      "Class 11 IoU: 0.0605\n",
      "Class 12 IoU: 0.0670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:28<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 IoU: 0.0566\n",
      "Class 1 IoU: 0.0612\n",
      "Class 2 IoU: 0.0572\n",
      "Class 3 IoU: 0.0567\n",
      "Class 4 IoU: 0.0750\n",
      "Class 5 IoU: 0.0561\n",
      "Class 6 IoU: 0.0943\n",
      "Class 7 IoU: 0.0594\n",
      "Class 8 IoU: 0.0527\n",
      "Class 9 IoU: 0.0587\n",
      "Class 10 IoU: 0.0772\n",
      "Class 11 IoU: 0.0561\n",
      "Class 12 IoU: 0.0880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [02:22<00:00,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 IoU: 0.0588\n",
      "Class 1 IoU: 0.0583\n",
      "Class 2 IoU: 0.0609\n",
      "Class 3 IoU: 0.0701\n",
      "Class 4 IoU: 0.0570\n",
      "Class 5 IoU: 0.0633\n",
      "Class 6 IoU: 0.0700\n",
      "Class 7 IoU: 0.0595\n",
      "Class 8 IoU: 0.0635\n",
      "Class 9 IoU: 0.0697\n",
      "Class 10 IoU: 0.0655\n",
      "Class 11 IoU: 0.0616\n",
      "Class 12 IoU: 0.0560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:33<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 IoU: 0.0565\n",
      "Class 1 IoU: 0.0448\n",
      "Class 2 IoU: 0.0443\n",
      "Class 3 IoU: 0.0461\n",
      "Class 4 IoU: 0.0454\n",
      "Class 5 IoU: 0.0445\n",
      "Class 6 IoU: 0.0903\n",
      "Class 7 IoU: 0.0447\n",
      "Class 8 IoU: 0.0466\n",
      "Class 9 IoU: 0.0456\n",
      "Class 10 IoU: 0.0455\n",
      "Class 11 IoU: 0.0453\n",
      "Class 12 IoU: 0.0782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [01:51<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 IoU: 0.0523\n",
      "Class 1 IoU: 0.0525\n",
      "Class 2 IoU: 0.0589\n",
      "Class 3 IoU: 0.0678\n",
      "Class 4 IoU: 0.0534\n",
      "Class 5 IoU: 0.0583\n",
      "Class 6 IoU: 0.0634\n",
      "Class 7 IoU: 0.0582\n",
      "Class 8 IoU: 0.0579\n",
      "Class 9 IoU: 0.0652\n",
      "Class 10 IoU: 0.0601\n",
      "Class 11 IoU: 0.0626\n",
      "Class 12 IoU: 0.0695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:32<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 IoU: 0.0577\n",
      "Class 1 IoU: 0.0619\n",
      "Class 2 IoU: 0.0582\n",
      "Class 3 IoU: 0.0578\n",
      "Class 4 IoU: 0.0761\n",
      "Class 5 IoU: 0.0572\n",
      "Class 6 IoU: 0.0968\n",
      "Class 7 IoU: 0.0602\n",
      "Class 8 IoU: 0.0536\n",
      "Class 9 IoU: 0.0597\n",
      "Class 10 IoU: 0.0783\n",
      "Class 11 IoU: 0.0572\n",
      "Class 12 IoU: 0.0905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 8/69 [00:24<03:09,  3.10s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/MMI24limbyungwan/Design_Project/Design_project/[Baseline]_Run Length Encoding + U-Net Semantic Segmentation_LBW.ipynb 셀 16\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/%5BBaseline%5D_Run%20Length%20Encoding%20%2B%20U-Net%20Semantic%20Segmentation_LBW.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/%5BBaseline%5D_Run%20Length%20Encoding%20%2B%20U-Net%20Semantic%20Segmentation_LBW.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m epoch_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/%5BBaseline%5D_Run%20Length%20Encoding%20%2B%20U-Net%20Semantic%20Segmentation_LBW.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mfor\u001b[39;00m images, masks \u001b[39min\u001b[39;00m tqdm(dataloader):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/%5BBaseline%5D_Run%20Length%20Encoding%20%2B%20U-Net%20Semantic%20Segmentation_LBW.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m     images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/%5BBaseline%5D_Run%20Length%20Encoding%20%2B%20U-Net%20Semantic%20Segmentation_LBW.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m     masks \u001b[39m=\u001b[39m masks\u001b[39m.\u001b[39mlong()\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.conda/envs/byungwan_resn/lib/python3.8/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/byungwan_resn/lib/python3.8/site-packages/torch/utils/data/dataloader.py:517\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    516\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 517\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    518\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    519\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    520\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    521\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/byungwan_resn/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1182\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1181\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1182\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1183\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1184\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1185\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/byungwan_resn/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1148\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1147\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1148\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1149\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1150\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.conda/envs/byungwan_resn/lib/python3.8/site-packages/torch/utils/data/dataloader.py:986\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m    974\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m    975\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m    984\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 986\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    987\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m    988\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    989\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/byungwan_resn/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    106\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 107\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    108\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    109\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/.conda/envs/byungwan_resn/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m~/.conda/envs/byungwan_resn/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    425\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/.conda/envs/byungwan_resn/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/.conda/envs/byungwan_resn/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# # start a new wandb run to track this script\n",
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"Design_PJ\",\n",
    "    \n",
    "#     # track hyperparameters and run metadata\n",
    "#     config={\n",
    "#     \"learning_rate\": 0.005,\n",
    "#     \"architecture\": \"CNN\",\n",
    "#     \"dataset\": \"CIFAR-100\",\n",
    "#     \"epochs\": 15,\n",
    "#     }\n",
    "# )\n",
    "# model 초기화\n",
    "model = UNet().to(device)\n",
    "\n",
    "# loss function과 optimizer 정의\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "# 클래스(레이블) 수\n",
    "num_classes = 13\n",
    "\n",
    "# 클래스별 IoU를 계산하기 위한 함수\n",
    "def calculate_iou_per_class(y_true, y_pred, class_id):\n",
    "    intersection = np.sum((y_true == class_id) & (y_pred == class_id))\n",
    "    union = np.sum((y_true == class_id) | (y_pred == class_id))\n",
    "    iou = intersection / union if union > 0 else 0\n",
    "    return iou\n",
    "\n",
    "\n",
    "# training loop\n",
    "for epoch in range(5):  # 5 에폭 동안 학습합니다.\n",
    "          \n",
    "    # 클래스별 IoU를 누적할 리스트 초기화\n",
    "    class_ious = []\n",
    "    train_class_ious = []\n",
    "    # 학습\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for images, masks in tqdm(dataloader):\n",
    "        images = images.float().to(device)\n",
    "        masks = masks.long().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks.squeeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # validation 클래스별 IoU 계산\n",
    "        outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "        outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "\n",
    "        for class_id in range(num_classes):\n",
    "            iou = calculate_iou_per_class(np.array(masks.cpu()), np.array(outputs), class_id)\n",
    "            class_ious.append(iou)\n",
    "            train_class_ious.append(iou)\n",
    "\n",
    "    # mIoU 계산\n",
    "    train_mIoU = np.mean(class_ious)\n",
    "    train_class_ious = np.array(train_class_ious).reshape(num_classes, -1)\n",
    "    train_class_ious = np.mean(train_class_ious, axis=1)\n",
    "    #mIoU = np.mean(class_ious)\n",
    "    #print(f\"Epoch {epoch+1}, Train Loss: {epoch_loss/len(dataloader)}, train mIoU Score: {mIoU:.4f}\")\n",
    "    for class_id, iou in enumerate(train_class_ious):\n",
    "        print(f'Class {class_id} IoU: {iou:.4f}')\n",
    "\n",
    "    # validation\n",
    "    val_loss = 0\n",
    "    class_ious = []  # 클래스별 IoU를 누적할 리스트 초기화\n",
    "    val_class_ious = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for images, masks in tqdm(valid_dataloader):\n",
    "            images = images.float().to(device)\n",
    "            masks = masks.long().to(device)\n",
    "            outputs = model(images)\n",
    "            # validation loss 계산\n",
    "            val_loss += criterion(outputs, masks.squeeze(1)).item()\n",
    "\n",
    "            # validation 클래스별 IoU 계산\n",
    "            outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "            outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "\n",
    "            for class_id in range(num_classes):\n",
    "                iou = calculate_iou_per_class(np.array(masks.cpu()), np.array(outputs), class_id)\n",
    "                class_ious.append(iou)\n",
    "                val_class_ious.append(iou)\n",
    "\n",
    "    val_class_ious = np.array(val_class_ious).reshape(num_classes, -1)\n",
    "    val_class_ious = np.mean(val_class_ious, axis=1)\n",
    "    for class_id, iou in enumerate(val_class_ious):\n",
    "        print(f'Class {class_id} IoU: {iou:.4f}')\n",
    "\n",
    "                \n",
    "    # for class_id, iou in enumerate(class_ious):\n",
    "    # print(f'Class {class_id} IoU: {iou:.4f}')           \n",
    "   \n",
    "    # mIoU 계산\n",
    "    val_mIoU = np.mean(class_ious)\n",
    "\n",
    "#     # log metrics to wandb\n",
    "#     wandb.log({\"Loss1\": (epoch_loss/len(dataloader))})\n",
    "#     wandb.log({\"Train Score\": train_mIoU})\n",
    "#     wandb.log({\"Loss2\": (val_loss/len(valid_dataloader))})\n",
    "#     wandb.log({\"Validation Score\": val_mIoU})\n",
    "    \n",
    "# # [optional] finish the wandb run, necessary in notebooks\n",
    "# wandb.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c32eb51c-a3fe-4e11-a616-3a717ba16f7e",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12371c8b-0c78-47df-89ec-2d8b55c8ea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test_dataset = CustomDataset(csv_file='./test.csv', transform=transform, infer=True)\n",
    "# test_dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./val_source.csv'), transform=transform, infer=True)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cc3501",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 클래스(레이블) 수\n",
    "# num_classes = 12\n",
    "\n",
    "# # training loop\n",
    "# for epoch in range(1):  # 5 에폭 동안 학습합니다.\n",
    "          \n",
    "#     # 클래스별 IoU를 누적할 리스트 초기화\n",
    "#     class_ious = []\n",
    "    \n",
    "#     # validation\n",
    "#     val_loss = 0\n",
    "#     class_ious = []  # 클래스별 IoU를 누적할 리스트 초기화\n",
    "#     with torch.no_grad():\n",
    "#         model.eval()\n",
    "#         for images, masks in tqdm(valid_dataloader):\n",
    "#             images = images.float().to(device)\n",
    "#             masks = masks.long().to(device)\n",
    "#             outputs = model(images)\n",
    "\n",
    "#             # validation loss 계산\n",
    "#             val_loss += criterion(outputs, masks.squeeze(1)).item()\n",
    "\n",
    "#             # validation 클래스별 IoU 계산\n",
    "#             outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "#             outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "\n",
    "#             for class_id in range(num_classes):\n",
    "#                 iou = calculate_iou_per_class(np.array(masks.cpu()), np.array(outputs), class_id)\n",
    "#                 class_ious.append(iou)\n",
    "                \n",
    "#     for class_id, iou in enumerate(class_ious):\n",
    "#         print(f'Class {class_id} IoU: {iou:.4f}')           \n",
    "   \n",
    "#     # mIoU 계산\n",
    "#     val_mIoU = np.mean(class_ious)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b431c-ac8e-4c40-9046-4d53e4bab14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,224,224) (16,224,224) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/MMI24limbyungwan/Design_Project/Design_project/[Baseline]_Run Length Encoding + U-Net Semantic Segmentation_LBW.ipynb 셀 19\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/%5BBaseline%5D_Run%20Length%20Encoding%20%2B%20U-Net%20Semantic%20Segmentation_LBW.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# batch에 존재하는 각 이미지에 대해서 반복\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/%5BBaseline%5D_Run%20Length%20Encoding%20%2B%20U-Net%20Semantic%20Segmentation_LBW.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m class_id \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_classes):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/%5BBaseline%5D_Run%20Length%20Encoding%20%2B%20U-Net%20Semantic%20Segmentation_LBW.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     iou \u001b[39m=\u001b[39m calculate_iou_per_class(np\u001b[39m.\u001b[39;49marray(masks\u001b[39m.\u001b[39;49mcpu()), np\u001b[39m.\u001b[39;49marray(outputs), class_id)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/%5BBaseline%5D_Run%20Length%20Encoding%20%2B%20U-Net%20Semantic%20Segmentation_LBW.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     class_ious\u001b[39m.\u001b[39mappend(iou)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/%5BBaseline%5D_Run%20Length%20Encoding%20%2B%20U-Net%20Semantic%20Segmentation_LBW.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m class_id, iou \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(class_ious):\n",
      "\u001b[1;32m/home/MMI24limbyungwan/Design_Project/Design_project/[Baseline]_Run Length Encoding + U-Net Semantic Segmentation_LBW.ipynb 셀 19\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/%5BBaseline%5D_Run%20Length%20Encoding%20%2B%20U-Net%20Semantic%20Segmentation_LBW.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalculate_iou_per_class\u001b[39m(y_true, y_pred, class_id):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/%5BBaseline%5D_Run%20Length%20Encoding%20%2B%20U-Net%20Semantic%20Segmentation_LBW.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     intersection \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum((y_true \u001b[39m==\u001b[39;49m class_id) \u001b[39m&\u001b[39;49m (y_pred \u001b[39m==\u001b[39;49m class_id))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/%5BBaseline%5D_Run%20Length%20Encoding%20%2B%20U-Net%20Semantic%20Segmentation_LBW.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     union \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum((y_true \u001b[39m==\u001b[39m class_id) \u001b[39m|\u001b[39m (y_pred \u001b[39m==\u001b[39m class_id))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/%5BBaseline%5D_Run%20Length%20Encoding%20%2B%20U-Net%20Semantic%20Segmentation_LBW.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     iou \u001b[39m=\u001b[39m intersection \u001b[39m/\u001b[39m union \u001b[39mif\u001b[39;00m union \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,224,224) (16,224,224) "
     ]
    }
   ],
   "source": [
    "# with torch.no_grad():\n",
    "#     model.eval()\n",
    "#     result = []\n",
    "#     for images in tqdm(test_dataloader):\n",
    "#         images = images.float().to(device)\n",
    "#         outputs = model(images)\n",
    "#         outputs = torch.softmax(outputs, dim=1).cpu()\n",
    "#         outputs = torch.argmax(outputs, dim=1).numpy()\n",
    "#         # batch에 존재하는 각 이미지에 대해서 반복\n",
    "#         for pred in outputs:\n",
    "#             pred = pred.astype(np.uint8)\n",
    "#             pred = Image.fromarray(pred) # 이미지로 변환\n",
    "#             pred = pred.resize((960, 540), Image.NEAREST) # 960 x 540 사이즈로 변환\n",
    "#             pred = np.array(pred) # 다시 수치로 변환\n",
    "#             # class 0 ~ 11에 해당하는 경우에 마스크 형성 / 12(배경)는 제외하고 진행\n",
    "#             for class_id in range(12):\n",
    "#                 class_mask = (pred == class_id).astype(np.uint8)\n",
    "#                 if np.sum(class_mask) > 0: # 마스크가 존재하는 경우 encode\n",
    "#                     mask_rle = rle_encode(class_mask)\n",
    "#                     result.append(mask_rle)\n",
    "#                 else: # 마스크가 존재하지 않는 경우 -1\n",
    "#                     result.append(-1)\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36c2cbbb-04f1-4f9c-b4df-4b744dfce046",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac2a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>mask_rle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000_class_0</td>\n",
       "      <td>477314 4 478274 4 479242 5 479255 9 480202 5 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0000_class_1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0000_class_2</td>\n",
       "      <td>1 167 601 527 1561 531 2521 531 3481 531 4441 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0000_class_3</td>\n",
       "      <td>462824 13 463784 13 464744 13 465704 17 466664...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0000_class_4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22771</th>\n",
       "      <td>TEST_1897_class_7</td>\n",
       "      <td>944 17 1904 17 2860 4 3820 4 4780 4 5757 4 671...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22772</th>\n",
       "      <td>TEST_1897_class_8</td>\n",
       "      <td>112 528 682 120 1072 528 1642 120 2037 518 260...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22773</th>\n",
       "      <td>TEST_1897_class_9</td>\n",
       "      <td>209002 9 209962 9 220021 4 220981 4 221937 4 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22774</th>\n",
       "      <td>TEST_1897_class_10</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22775</th>\n",
       "      <td>TEST_1897_class_11</td>\n",
       "      <td>194110 25 194140 8 194478 13 195070 25 195100 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22776 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                           mask_rle\n",
       "0       TEST_0000_class_0  477314 4 478274 4 479242 5 479255 9 480202 5 4...\n",
       "1       TEST_0000_class_1                                                 -1\n",
       "2       TEST_0000_class_2  1 167 601 527 1561 531 2521 531 3481 531 4441 ...\n",
       "3       TEST_0000_class_3  462824 13 463784 13 464744 13 465704 17 466664...\n",
       "4       TEST_0000_class_4                                                 -1\n",
       "...                   ...                                                ...\n",
       "22771   TEST_1897_class_7  944 17 1904 17 2860 4 3820 4 4780 4 5757 4 671...\n",
       "22772   TEST_1897_class_8  112 528 682 120 1072 528 1642 120 2037 518 260...\n",
       "22773   TEST_1897_class_9  209002 9 209962 9 220021 4 220981 4 221937 4 2...\n",
       "22774  TEST_1897_class_10                                                 -1\n",
       "22775  TEST_1897_class_11  194110 25 194140 8 194478 13 195070 25 195100 ...\n",
       "\n",
       "[22776 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submit = pd.read_csv('./sample_submission.csv')\n",
    "# submit['mask_rle'] = result\n",
    "# submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da10cb6f-0826-4755-a376-97b695ae8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit.to_csv('C:\\Workspace\\Design_project\\submission/baseline_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seungyoon2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
