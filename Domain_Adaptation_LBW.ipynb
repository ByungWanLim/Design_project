{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/MMI24limbyungwan/.conda/envs/byungwan_resn/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# GPU 사용이 가능할 경우, GPU를 사용할 수 있게 함.'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "print(device)\n",
    "\n",
    "print(os.environ.get('CUDA_VISIBLE_DEVICES'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "# 클래스별 IoU를 계산하기 위한 함수\n",
    "def calculate_iou_per_class(y_true, y_pred, class_id):\n",
    "    intersection = np.sum((y_true == class_id) & (y_pred == class_id))\n",
    "    union = np.sum((y_true == class_id) | (y_pred == class_id))\n",
    "    iou = intersection / union if union > 0 else 0\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        directory_path = \"/mnt/nas27/Dataset/Samsung_DM\"\n",
    "        img_path = self.data.iloc[idx, 1]\n",
    "        img_path = os.path.join(directory_path, img_path[2:])\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "        \n",
    "        mask_path = self.data.iloc[idx, 2]\n",
    "        mask_path = os.path.join(directory_path, mask_path[2:])\n",
    "        mask = cv2.imread(mask_path)\n",
    "        #mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        mask[mask == 255] = 12 #배경을 픽셀값 12로 간주\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "class CustomDataset_target(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, infer=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        directory_path = \"/mnt/nas27/Dataset/Samsung_DM\"\n",
    "        img_path = self.data.iloc[idx, 1]\n",
    "        img_path = os.path.join(directory_path, img_path[2:])\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image=image)['image']\n",
    "            return image\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "            \n",
    "\n",
    "        return image\n",
    "     \n",
    "\n",
    "transform = A.Compose(\n",
    "    [   \n",
    "        A.Resize(224, 224),\n",
    "        #A.Resize(128, 128),\n",
    "        A.Normalize(),\n",
    "        \n",
    "        # 변형\n",
    "        # A.VerticalFlip(p=0.5),\n",
    "        # A.RandomRotate90(p=0.5),\n",
    "        # A.HueSaturationValue(p=0.2),\n",
    "        \n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unet의 기본이 되는 conv블럭\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)  # 여기서 in_channels는 out_channels와 동일해야 합니다.\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        return x\n",
    "\n",
    "#인코더 블럭\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(EncoderBlock,self).__init__()\n",
    "        self.convblock1 = ConvBlock(in_channels, out_channels)  # 첫 번째 ConvBlock의 in_channels는 입력 이미지의 채널 수와 일치해야 합니다.\n",
    "        #self.convblock2 = ConvBlock(out_channels, out_channels)  # 두 번째 ConvBlock의 in_channels는 out_channels와 일치해야 합니다.\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.convblock1(x)\n",
    "        #x = self.convblock2(x)\n",
    "        p = self.maxpool(x)\n",
    "        return x , p\n",
    "#디코더 블럭\n",
    "#디코더는 업샘플링 이후 스킵연결과 붙어서 convblock을 통과해야함\n",
    "#skip보다 작은 x x먼저 업샘플링 32 -> 64 , skip과 결합 6464 \n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(DecoderBlock,self).__init__()\n",
    "        self.upsample = nn.ConvTranspose2d(channels*2, channels, kernel_size=4, stride=2, padding=1)#x 업샘플링\n",
    "        self.convblock1 = ConvBlock(channels*2, channels)#차원감소\n",
    "        #self.convblock2 = ConvBlock(channels, channels)\n",
    "    def forward(self,x,skip):\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.convblock1(x)\n",
    "        #x = self.convblock2(x)\n",
    "        return x\n",
    "\n",
    "###########################################\n",
    "class GradReverse(torch.autograd.Function):\n",
    "    def forward(self, x):\n",
    "        return x.view_as(x)\n",
    "\n",
    "    def backward(self, grad_output): # 역전파 시에 gradient에 음수를 취함\n",
    "        return (grad_output * -1)\n",
    "\n",
    "class domain_classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(domain_classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(512*512*49, 10)\n",
    "        self.fc2 = nn.Linear(10, 1) # source = 0, target = 1 회귀 가정\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 512*512*49)\n",
    "        x = GradReverse.apply(x) # gradient reverse\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "###########################################\n",
    "\n",
    "\n",
    "#Unet구조 middle의 xm값의 움직임에 주의\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self,n_classes):\n",
    "        super(Unet,self).__init__()\n",
    "        self.encoder1 = EncoderBlock(3,64)\n",
    "        self.encoder2 = EncoderBlock(64,128)\n",
    "        self.encoder3 = EncoderBlock(128,256)\n",
    "        self.encoder4 = EncoderBlock(256,512)\n",
    "        \n",
    "        self.middleconv = ConvBlock(512,1024)\n",
    "        \n",
    "        \n",
    "        self.decoder4 = DecoderBlock(512)\n",
    "        self.decoder3 = DecoderBlock(256)\n",
    "        self.decoder2 = DecoderBlock(128)\n",
    "        self.decoder1 = DecoderBlock(64)\n",
    "        self.segmap = nn.Conv2d(64,n_classes, kernel_size=1)\n",
    "        \n",
    "        self.domain_classifier = domain_classifier()\n",
    "                                        \n",
    "\n",
    "    def forward(self,x):\n",
    "        x1,p = self.encoder1(x)#3->64   #P:256,256 x1 :512,512\n",
    "        x2,p = self.encoder2(p)#64->128 #P:128,128 x2:256,256\n",
    "        x3,p = self.encoder3(p)#128->256#p:64,64 x3:128,128\n",
    "        x4,p = self.encoder4(p)#256->512#p:32,32 x4:64,64\n",
    "        \n",
    "        xm = self.middleconv(p)#512->1024#32,32\n",
    "        \n",
    "        x = self.decoder4(xm,x4)#뉴런:1024->512->512 #출력tensor:64,64\n",
    "        x = self.decoder3(x,x3)#뉴런:512->256->256 #출력tensor:128,128\n",
    "        x = self.decoder2(x,x2)#뉴런:256->128->128 #출력tensor:256,256\n",
    "        x = self.decoder1(x,x1)#뉴런:128->64->64 #출력tensor:512,512\n",
    "\n",
    "        x_c = self.segmap(x)\n",
    "        x_d = self.domain_classifier(x)\n",
    "\n",
    "        return x_c, x_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   6.2232,   81.0473,    5.1017,   66.2180,  170.2419,  506.2671,\n",
      "         159.9452,    6.9654,    4.3830,  907.1918, 2223.4863,   10.2576,\n",
      "           7.6339], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# 저장된 class_weights를 불러옵니다.\n",
    "class_weights_path = 'CLASS_WEIGHTS.pkl'\n",
    "\n",
    "with open(class_weights_path, 'rb') as file:\n",
    "    CLASS_WEIGHTS = pickle.load(file)\n",
    "\n",
    "print(CLASS_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function과 optimizer 정의\n",
    "\n",
    "class DANN_Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DANN_Loss, self).__init__()\n",
    "\n",
    "        self.CE = nn.CrossEntropyLoss(weight=CLASS_WEIGHTS) # 0~9 class 분류용\n",
    "        self.BCE = nn.BCELoss() # 도메인 분류용\n",
    "        \n",
    "    # result : DANN_CNN에서 반환된 값\n",
    "    # label : 숫자 0 ~ 9에 대한 라벨\n",
    "    # domain_num : 0(source) or 1(target)\n",
    "    def forward(self, result, label, domain_num, alpha = 1):\n",
    "        label_logits, domain_logits = result # DANN_CNN의 결과\n",
    "\n",
    "        batch_size = domain_logits.shape[0]\n",
    "\n",
    "        domain_target = torch.FloatTensor([domain_num] * batch_size).unsqueeze(1).to(device)\n",
    "\n",
    "        domain_loss = self.BCE(domain_logits, domain_target) # domain 분류 loss\n",
    "        target_loss = 0.5\n",
    "        if len(label) != 1:\n",
    "            target_loss = self.CE(label_logits, label) # class 분류 loss\n",
    "\n",
    "        loss = target_loss + alpha * domain_loss\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, grad_output, label, domain_num, alpha = 1):\n",
    "        label_logits, domain_logits = self.saved_tensors  # Forward pass에서 저장된 텐서 가져옴\n",
    "\n",
    "        # 역전파 계산\n",
    "        domain_loss_gradient = grad_output\n",
    "        target_loss_gradient = alpha * grad_output  # 'alpha'를 곱해서 도메인 분류 손실에 대한 그라디언트로 변환\n",
    "        batch_size = domain_logits.shape[0]\n",
    "\n",
    "        domain_target = torch.FloatTensor([domain_num] * batch_size).unsqueeze(1).to(device)\n",
    "        # 'BCE' 도메인 분류 손실의 역전파\n",
    "        domain_loss = self.BCE(domain_logits, domain_target) # domain 분류 loss\n",
    "        domain_loss.backward(domain_loss_gradient, retain_graph=True)\n",
    "\n",
    "        # 'CE' 클래스 분류 손실의 역전파\n",
    "        if len(label) != 1:\n",
    "            target_loss = self.CE(label_logits, label) # class 분류 loss\n",
    "            target_loss.backward(target_loss_gradient)\n",
    "\n",
    "loss_fn = DANN_Loss().to(device)\n",
    "\n",
    "#criterion =nn.CrossEntropyLoss()\n",
    "#domain_criterion = nn.BCELoss()\n",
    "#criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "EP = 20\n",
    "BATCH_SIZE = 8\n",
    "ACCMULATION_STEP = 1 \n",
    "N_CLASSES = 13 #IoU 점수측정하기 위한 클래스의 개수\n",
    "ALPHA = 0.5\n",
    "# WUP_ITERS = 10  # 웜업을 위한 반복 횟수\n",
    "# model 초기화\n",
    "#model = Unet_resnet18(n_classes = N_CLASSES).to(device)\n",
    "#model = ResNet50(num_classes=N_CLASSES).to(device)\n",
    "model = Unet(n_classes = N_CLASSES).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "optimizer.zero_grad() \n",
    "\n",
    "# Warmup을 위한 스케줄러 설정\n",
    "# scheduler_warmup = WarmUpLR(optimizer, WUP_ITERS)\n",
    "\n",
    "\n",
    "dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./train_source.csv'), transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "valid_dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./val_source.csv'), transform=transform)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "target_dataset = CustomDataset_target(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./train_target.csv'), transform=transform)\n",
    "target_dataloader = DataLoader(target_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "test_dataset = CustomDataset(csv_file=os.path.join(\"/mnt/nas27/Dataset/Samsung_DM\",'./test.csv'), transform=transform, infer=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/275 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "You must implement the backward function for custom autograd.Function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Adaptation_LBW.ipynb 셀 10\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Adaptation_LBW.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m     epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Adaptation_LBW.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Adaptation_LBW.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Adaptation_LBW.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Adaptation_LBW.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m     \u001b[39m#scheduler.step()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Adaptation_LBW.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.239.13.23/home/MMI24limbyungwan/Design_Project/Design_project/Domain_Adaptation_LBW.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# 에폭마다 결과 출력 \u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/byungwan_resn/lib/python3.8/site-packages/torch/tensor.py:245\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    237\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    238\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    239\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    244\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 245\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/.conda/envs/byungwan_resn/lib/python3.8/site-packages/torch/autograd/__init__.py:145\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> 145\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    146\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    147\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.conda/envs/byungwan_resn/lib/python3.8/site-packages/torch/autograd/function.py:89\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs):\n\u001b[1;32m     88\u001b[0m     \u001b[39m# _forward_cls is defined by derived class\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_cls\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/.conda/envs/byungwan_resn/lib/python3.8/site-packages/torch/autograd/function.py:201\u001b[0m, in \u001b[0;36mFunction.backward\u001b[0;34m(ctx, *grad_outputs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    183\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackward\u001b[39m(ctx: Any, \u001b[39m*\u001b[39mgrad_outputs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    184\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Defines a formula for differentiating the operation.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \n\u001b[1;32m    186\u001b[0m \u001b[39m    This function is to be overridden by all subclasses.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m    output.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou must implement the backward function for custom\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    202\u001b[0m                               \u001b[39m\"\u001b[39m\u001b[39m autograd.Function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: You must implement the backward function for custom autograd.Function."
     ]
    }
   ],
   "source": [
    "import random\n",
    "torch.cuda.empty_cache()\n",
    "import wandb\n",
    "\n",
    "\n",
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"practice_10_06\",\n",
    "    \n",
    "#     # track hyperparameters and run metadata\n",
    "#     config={\n",
    "#     \"learning_rate\": LR,\n",
    "#     \"architecture\": \"CNN\",\n",
    "#     \"dataset\": \"Samsung\",\n",
    "#     \"epochs\": EP,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "for epoch in range(EP):\n",
    "    # 클래스별 IoU를 누적할 리스트 초기화\n",
    "    train_class_ious = []\n",
    "    # 학습\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for step in tqdm(range(len(dataloader))):\n",
    "        source_data = iter(dataloader).next()\n",
    "        target_data = iter(target_dataloader).next()\n",
    "\n",
    "        source_images = source_data[0].float().to(device)\n",
    "        source_masks = source_data[1].long().to(device)\n",
    "        target_images = target_data.float().to(device)\n",
    "        #target_masks = target_data[1].long().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        source_outputs = model(source_images)\n",
    "        target_outputs = model(target_images)\n",
    "\n",
    "        source_loss = loss_fn(source_outputs, source_masks, 0, alpha = ALPHA)\n",
    "        #target_loss = loss_fn(target_outputs, target_masks, 1, alpha = ALPHA)\n",
    "        target_loss = loss_fn(target_outputs, [0], 1, alpha = ALPHA)\n",
    "\n",
    "        loss = source_loss + target_loss\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "\n",
    "    # 에폭마다 결과 출력 \n",
    "    print(f\"\\nEpoch{epoch+1}\")\n",
    "    print(f\"Train Loss: {(epoch_loss/len(dataloader))}\")\n",
    "    print(\"___________________________________________________________________________________________\\n\")\n",
    "\n",
    "#     # log metrics to wandb\n",
    "#     wandb.log({\"train score\": train_mIoU, \"train loss\": epoch_loss})\n",
    "#     wandb.log({\"val score\": val_mIoU, \"val loss\": val_loss})\n",
    "    \n",
    "    \n",
    "# # [optional] finish the wandb run, necessary in notebooks\n",
    "# wandb.finish()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byungwan_resn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
